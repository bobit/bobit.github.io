{"meta":{"title":"Bobit-你好世界","subtitle":"做一个有心人，总结经验和教训。#副标题","description":"你好世界，Hello World！","author":"Bobit","url":"https://bobit.github.io"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2018-12-27T13:51:25.005Z","updated":"2018-12-17T16:03:47.973Z","comments":false,"path":"/404.html","permalink":"https://bobit.github.io//404.html","excerpt":"","text":"12345678910111213141516171819202122232425/** * 佛祖也没找到页面，请去看看其他的文章吧 * * _______________ * _ooOoo_ / | * o8888888o / 404 Not Found | * 88&quot; . &quot;88 / ________________| * (| -_- |) /_/ * O\\ = /O * ____/`---&apos;\\____ * .&apos; \\\\| |// `. * / \\\\||| : |||// \\ * / _||||| -:- |||||- \\ * | | \\\\\\ - /// | | * | \\_| &apos;&apos;\\---/&apos;&apos; | | * \\ .-\\__ `-` ___/-. / * ___`. .&apos; /--.--\\ `. . __ * .&quot;&quot; &apos;&lt; `.___\\_&lt;|&gt;_/___.&apos; &gt;&apos;&quot;&quot;. * | | : `- \\`.;`\\ _ /`;.`/ - ` : | | * \\ \\ `-. \\_ __\\ /__ _/ .-` / / * ======`-.____`-.___\\_____/___.-`____.-&apos;====== * `=---=&apos; * ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ * */"},{"title":"关于","date":"2018-12-27T13:51:25.013Z","updated":"2018-12-17T13:17:36.731Z","comments":false,"path":"about/index.html","permalink":"https://bobit.github.io/about/index.html","excerpt":"","text":"做一个工作和生活中的有心人，及时总结经验和教训。"},{"title":"书单","date":"2018-12-27T13:51:25.025Z","updated":"2018-12-17T06:54:46.294Z","comments":false,"path":"books/index.html","permalink":"https://bobit.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-12-27T13:51:25.037Z","updated":"2018-12-17T12:16:12.492Z","comments":false,"path":"categories/index.html","permalink":"https://bobit.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-12-27T13:51:25.056Z","updated":"2018-12-17T06:54:46.296Z","comments":true,"path":"links/index.html","permalink":"https://bobit.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2018-12-27T13:51:25.078Z","updated":"2018-12-17T06:54:46.297Z","comments":false,"path":"repository/index.html","permalink":"https://bobit.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-12-27T13:51:25.093Z","updated":"2018-12-17T12:17:33.598Z","comments":false,"path":"tags/index.html","permalink":"https://bobit.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2018-12-27T14:29:41.868Z","updated":"2018-12-27T14:12:59.555Z","comments":true,"path":"gitbooks/SUMMARY.html","permalink":"https://bobit.github.io/gitbooks/SUMMARY.html","excerpt":"","text":"Summary 算法"},{"title":"","date":"2018-12-27T14:54:22.297Z","updated":"2018-12-27T14:54:22.297Z","comments":true,"path":"gitbooks/README.html","permalink":"https://bobit.github.io/gitbooks/README.html","excerpt":"","text":"个人点滴记忆 涉及编程语言、设计模式、架构、安全、大数据、分布式、人工智能、区块链、工具等等，持续更新中… 目录 算法 Spring SpringMVC SpringBoot SpringCloud Linux Python Vue RDB &amp; NoSQLDB ** MyBatis Tools Java Spring SpringMVC SpringBoot SpringCloud Linux Python Vue node 基础 node api 查询 vue 基础 vue api 查询 nuxt 基础 https://zh.nuxtjs.org/guide/installation nuxt api 查询 https://zh.nuxtjs.org/api element 组件 http://element-cn.eleme.io/#/zh-CN/component/installation iView组件 https://www.iviewui.com/docs/guide/install RDB &amp; NoSQLDB MyBatis Tools"}],"posts":[{"title":"Netty入门","slug":"分布式/Netty/Netty入门","date":"2017-12-13T14:29:17.000Z","updated":"2018-12-27T15:12:05.175Z","comments":true,"path":"posts/21d654b6.html","link":"","permalink":"https://bobit.github.io/posts/21d654b6.html","excerpt":"","text":"简介 Netty 是一个异步和事件驱动的网络框架，用以快速开发高性能、高可靠性的网络服务器和客户端程序。也就是说，Netty 是一个基于 NIO 的客户、服务器端编程框架，使用 Netty 可以确保你快速和简单地开发出一个网络应用，例如实现了某种协议的客户，服务端应用。Netty 相当简化和流线化了网络应用的编程开发过程，例如，TCP 和 UDP 的 socket 服务开发。 特性 （摘自《Netty in Action》） 1）设计 统一的API，适用于不同的协议（阻塞和非阻塞） 基于灵活、可扩展的事件驱动模型 高度可定制的线程模型 可靠的无连接数据Socket支持（UDP） 2）性能 更好的吞吐量，低延迟 更省资源 尽量减少不必要的内存拷贝 3）安全 完整的SSL/TLS和STARTTLS的支持 能在Applet与Android的限制环境运行良好 4）健壮性 不再因过快、过慢或超负载连接导致OutOfMemoryError 不再有在高速网络环境下NIO读写频率不一致的问题 5）易用 完善的JavaDoc，用户指南和样例 简洁简单 仅信赖于JDK1.5 应用 Netty是一个高性能 事件驱动的异步的非堵塞的IO(NIO)框架，用于建立TCP等底层的连接，基于Netty可以建立高性能的Http服务器。支持HTTP、 WebSocket 、Protobuf、 Binary TCP 和UDP，Netty已经被很多高性能项目作为其Socket底层基础，其竞争对手是：Apache MINA和 Grizzly。 互联网行业 随着网站规模的不断扩大，系统并发访问量也越来越高，传统基于 Tomcat 等 Web 容器的垂直架构已经无法满足需求，需要拆分应用进行服务化，以提高开发和维护效率。从组网情况看，垂直的架构拆分之后，系统采用分布式部署，各个节点之间需要远程服务调用，高性能的 RPC 框架必不可少，Netty 作为异步高性能的通信框架，往往作为基础通信组件被这些 RPC 框架使用。 典型的应用有： 阿里分布式服务框架 Dubbo 的 RPC 框架使用 Dubbo 协议进行节点间通信，Dubbo 协议默认使用 Netty 作为基础通信组件，用于实现各进程节点之间的内部通信。其中，服务提供者和服务消费者之间，服务提供者、服务消费者和性能统计节点之间使用 Netty 进行异步/同步通信。 除了 Dubbo 之外，淘宝的消息中间件 RocketMQ 的消息生产者和消息消费者之间，也采用 Netty 进行高性能、异步通信。 除了阿里系和淘宝系之外，很多其它的大型互联网公司或者电商内部也已经大量使用 Netty 构建高性能、分布式的网络服务器。 游戏行业 无论是手游服务端、还是大型的网络游戏，Java 语言得到了越来越广泛的应用。Netty 作为高性能的基础通信组件，它本身提供了 TCP/UDP 和 HTTP 协议栈，非常方便定制和开发私有协议栈。账号登陆服务器、地图服务器之间可以方便的通过 Netty 进行高性能的通信。 大数据领域 经典的 Hadoop 的高性能通信和序列化组件 Avro 的 RPC 框架，默认采用 Netty 进行跨节点通信，它的 Netty Service 基于 Netty 框架二次封装实现。 大数据计算往往采用多个计算节点和一个/N个汇总节点进行分布式部署，各节点之间存在海量的数据交换。由于 Netty 的综合性能是目前各个成熟 NIO 框架中最高的，因此，往往会被选中用作大数据各节点间的通信。 企业软件 企业和 IT 集成需要 ESB，Netty 对多协议支持、私有协议定制的简洁性和高性能是 ESB RPC 框架的首选通信组件。事实上，很多企业总线厂商会选择 Netty 作为基础通信组件，用于企业的 IT 集成。 通信行业 Netty 的异步高性能、高可靠性和高成熟度的优点，使它在通信行业得到了大量的应用。 核心组件 Channel ChannelFuture EventLoop ChannelHandler ChannelPipeline Channel Channel 是 Netty 网络操作抽象类，它除了包括基本的 I/O 操作，如 bind、connect、read、write 之外，还包括了 Netty 框架相关的一些功能，如获取该 Channe l的 EventLoop。 在传统的网络编程中，作为核心类的 Socket ，它对程序员来说并不是那么友好，直接使用其成本还是稍微高了点。而Netty 的 Channel 则提供的一系列的 API ，它大大降低了直接与 Socket 进行操作的复杂性。而相对于原生 NIO 的 Channel，Netty 的 Channel 具有如下优势（摘自《Netty权威指南（第二版）》）： 在 Channel 接口层，采用 Facade 模式进行统一封装，将网络 I/O 操作、网络 I/O 相关联的其他操作封装起来，统一对外提供。 Channel 接口的定义尽量大而全，为 SocketChannel 和 ServerSocketChannel 提供统一的视图，由不同子类实现不同的功能，公共功能在抽象父类中实现，最大程度地实现功能和接口的重用。 具体实现采用聚合而非包含的方式，将相关的功能类聚合在 Channel 中，有 Channel 统一负责和调度，功能实现更加灵活。 EventLoop Netty 基于事件驱动模型，使用不同的事件来通知我们状态的改变或者操作状态的改变。它定义了在整个连接的生命周期里当有事件发生的时候处理的核心抽象。 Channel 为Netty 网络操作抽象类，EventLoop 主要是为Channel 处理 I/O 操作，两者配合参与 I/O 操作。 下图是Channel、EventLoop、Thread、EventLoopGroup之间的关系（摘自《Netty In Action》）： 一个 EventLoopGroup 包含一个或多个 EventLoop。 一个 EventLoop 在它的生命周期内只能与一个Thread绑定。 所有有 EnventLoop 处理的 I/O 事件都将在它专有的 Thread 上被处理。 一个 Channel 在它的生命周期内只能注册与一个 EventLoop。 一个 EventLoop 可被分配至一个或多个 Channel 。 当一个连接到达时，Netty 就会注册一个 Channel，然后从 EventLoopGroup 中分配一个 EventLoop 绑定到这个Channel上，在该Channel的整个生命周期中都是有这个绑定的 EventLoop 来服务的。 ChannelFuture Netty 为异步非阻塞，即所有的 I/O 操作都为异步的，因此，我们不能立刻得知消息是否已经被处理了。Netty 提供了 ChannelFuture 接口，通过该接口的 addListener() 方法注册一个 ChannelFutureListener，当操作执行成功或者失败时，监听就会自动触发返回结果。 ChannelHandler ChannelHandler 为 Netty 中最核心的组件，它充当了所有处理入站和出站数据的应用程序逻辑的容器。ChannelHandler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。 ChannelHandler 有两个核心子类 ChannelInboundHandler 和 ChannelOutboundHandler，其中 ChannelInboundHandler 用于接收、处理入站数据和事件，而 ChannelOutboundHandler 则相反。 ChannelPipeline ChannelPipeline 为 ChannelHandler 链提供了一个容器并定义了用于沿着链传播入站和出站事件流的 API。一个数据或者事件可能会被多个 Handler 处理，在这个过程中，数据或者事件经流 ChannelPipeline，由 ChannelHandler 处理。在这个处理过程中，一个 ChannelHandler 接收数据后处理完成后交给下一个 ChannelHandler，或者什么都不做直接交给下一个 ChannelHandler。 当一个数据流进入 ChannlePipeline 时，它会从 ChannelPipeline 头部开始传给第一个 ChannelInboundHandler ，当第一个处理完后再传给下一个，一直传递到管道的尾部。与之相对应的是，当数据被写出时，它会从管道的尾部开始，先经过管道尾部的 “最后” 一个ChannelOutboundHandler，当它处理完成后会传递给前一个 ChannelOutboundHandler 。 当 ChannelHandler 被添加到 ChannelPipeline 时，它将会被分配一个 ChannelHandlerContext，它代表了 ChannelHandler 和 ChannelPipeline 之间的绑定。其中 ChannelHandler 添加到 ChannelPipeline 过程如下： 一个 ChannelInitializer 的实现被注册到了 ServerBootStrap中 当 ChannelInitializer.initChannel() 方法被调用时，ChannelInitializer 将在 ChannelPipeline 中安装一组自定义的 ChannelHandler ChannelInitializer 将它自己从 ChannelPipeline 中移除","categories":[{"name":"分布式","slug":"分布式","permalink":"https://bobit.github.io/categories/分布式/"},{"name":"Netty","slug":"分布式/Netty","permalink":"https://bobit.github.io/categories/分布式/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://bobit.github.io/tags/Netty/"}]},{"title":"互联网常用名词大全","slug":"English/互联网常用术语大全","date":"2017-11-13T14:29:17.000Z","updated":"2018-12-24T05:54:17.678Z","comments":true,"path":"posts/9253509e.html","link":"","permalink":"https://bobit.github.io/posts/9253509e.html","excerpt":"","text":"DevOps Development和Operations的组合词 PaaS（Platform-as-a-Service） 平台即服务 TL（Team Leader） PM（Project Manager） PMO（Project Management Officer） 一般称为项目管理办公室、项目管理中心或者项目管理部 IaaS（Infrastructure-as-a-Service） 基础设施即服务 SaaS（Software-as-a-Service(） 软件即服务 PV（page view） 页面浏览量，用户每一次对网站中的每个页面访问均被记录1次。用户对同一页面的多次刷新，访问量累计。 单台服务器每天PV计算 公式1：每天总PV = QPS * 3600 * 6 公式2：每天总PV = QPS * 3600 * 8 UV（Unique Visitor） 独立访客 通过客户端的cookies实现。访问您网站的一台电脑客户端为一个访客。00:00-24:00内相同的客户端只被计算一次 。即同一页面，客户端多次点击只计算一次，访问量不累计。 服务器数量： 机器：峰值时间每秒QPS / 单台机器的QPS = 需要的机器 机器：ceil( 每天总PV / 单台服务器每天总PV ) IP（Internet Protocol） 本意本是指网络协议，在数据统计这块指通过ip的访问量。即同一页面，客户端使用同一个IP访问多次只计算一次，访问量不累计。 UV、IP的区别 比如你是ADSL拨号上网，拨一次号自动分配一个IP，进入了网站，就算一个IP；断线了而没清理Cookies，又拨号一次自动分配一个IP，又进入了同一个网站，又统计到一个IP，这时统计数据里IP就显示统计了2次。UV没有变，是1次。 同一个局域网内2个人，在2台电脑上访问同一个网站，他们的公网IP是相同的。IP就是1，但UV是2。 TPS（Transactions Per Second） 每秒处理的事务数目。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数，最终利用这些信息作出的评估分。 QPS（Queries Per Second） 每秒能处理查询数目，也即是最大吞吐能力。是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。 QPS统计方式 [一般使用 http_load 进行统计] QPS = 总请求数 / ( 进程总数 * 请求时间 ) QPS: 单个进程每秒请求服务器的成功次数 峰值QPS: 原理：每天80%的访问集中在20%的时间里，这20%时间叫做峰值时间 公式：( 总PV数 * 80% ) / ( 每天秒数 * 20% ) = 峰值时间每秒请求数(QPS) RPS（Requests Per Second） 每秒能处理的请求数目。等效于QPS DSL（Domain Specific Language） 即领域特定语言，或者直接翻译成“特定领域的语言”，再直接点，其实就是这个语言不通用，只能用于特定的某个领域，俗称“小语言”。因此DSL也是语言。 FAQ（Frequently Asked Questions） 中文意思就是“经常问到的问题”，或者更通俗地叫做“常见问题解答”。FAQ是当前网络上提供在线帮助的主要手段，通过事先组织好一些可能的常问问答对，发布在网页上为用户提供咨询服务。 DCL（double check lock） 双重检查锁定，已被广泛当做多线程环境下延迟初始化的一种高效手段。遗憾的是，在Java中，如果没有额外的同步，它并不可靠。 RAID（Redundant Array of Independent Disks） 独立冗余磁盘阵列 Apache 英 [əˈpætʃi] 美 [ə’pætʃɪ] Hadoop [hædu:p] 哈杜噗，没有官方的发音，通常都读作[h∧du:p] SOA（service-oriented architecture） 面向服务的体系结构是一个组件模型，它将应用程序的不同功能单元（称为服务）通过这些服务之间定义良好的接口和契约联系起来。Martin Fowler提出SOA歧义Service Oriented Ambiguity，认为&quot;什么是SOA&quot;是不可能回答，因为不同的人意味着不同的事情，SOA意味服务接口，意味流程整合，意味资源再利用，意味着管制。 ASO（App store Optimization） 是“应用商店优化”的简称。就是提升你APP在各类APP应用商店/市场排行榜和搜索结果排名的过程。 B2B：商家到商家 阿里巴巴 B2C：商家到用户 京东 C2C：用户到用户 淘宝 B2B2C：商家到商家到用户 天猫 O2O：线上到线下 百度外卖、美团、饿了么 CMS 内容管理系统,实现菜单，链接，图片，导航栏等的可配置化系统。 CRM 客户关系管理系统，一套为各种角色提供各种功能的系统。包括不同角色的权限等。这个系统主要是为了客户提供功能的系统。 WMS 仓库管理系统 通过入库业务、出库业务、仓库调拨、库存调拨和虚仓管理等功能，对批次管理、物料对应、库存盘点、质检管理、虚仓管理和即时库存管理等功能综合运用的管理系统，有效控制并跟踪仓库业务的物流和成本管理全过程，实现或完善的企业仓储信息管理。","categories":[{"name":"English","slug":"English","permalink":"https://bobit.github.io/categories/English/"}],"tags":[{"name":"英语","slug":"英语","permalink":"https://bobit.github.io/tags/英语/"},{"name":"互联网","slug":"互联网","permalink":"https://bobit.github.io/tags/互联网/"}]},{"title":"高并发高负载类网站中数据库的设计","slug":"并发编程/高并发高负载类网站中数据库的设计","date":"2017-11-13T14:28:17.000Z","updated":"2018-12-21T12:56:51.686Z","comments":true,"path":"posts/48156525.html","link":"","permalink":"https://bobit.github.io/posts/48156525.html","excerpt":"","text":"高并发高负载类网站中数据库的设计方法总结 关注点之数据库 首先是数据库,这是大多数应用所面临的首个SPOF。尤其是Web2.0的应用，数据库的响应是首先要解决的。 一般来说MySQL是最常用的，可能最初是一个mysql主机，当数据增加到100万以上，那么，MySQL的效能急剧下降。常用的优化措施是M-S（主-从）方式进行同步复制，将查询和操作和分别在不同的服务器上进行操作。我推荐的是M-M-Slaves方式，2个主Mysql，多个Slaves，需要注意的是，虽然有2个Master，但是同时只有1个是Active，我们可以在一定时候切换。之所以用2个M，是保证M不会又成为系统的SPOF。 Slaves可以进一步负载均衡，可以结合LVS,从而将select操作适当的平衡到不同的slaves上。 以上架构可以抗衡到一定量的负载，但是随着用户进一步增加，你的用户表数据超过1千万，这时那个M变成了SPOF。你不能任意扩充Slaves，否则复制同步的开销将直线上升，怎么办？我的方法是表分区，从业务层面上进行分区。最简单的，以用户数据为例。根据一定的切分方式，比如id，切分到不同的数据库集群去。 全局数据库用于meta数据的查询。缺点是每次查询，会增加一次，比如你要查一个用户nightsailer,你首先要到全局数据库群找到nightsailer对应的cluster id，然后再到指定的cluster找到nightsailer的实际数据。 每个cluster可以用m-m方式，或者m-m-slaves方式。这是一个可以扩展的结构，随着负载的增加，你可以简单的增加新的mysql cluster进去。 需要注意的是： 1、禁用全部auto_increment的字段 2、id需要采用通用的算法集中分配 3、要具有比较好的方法来监控mysql主机的负载和服务的运行状态。如果你有30台以上的mysql数据库在跑就明白我的意思了。 4、不要使用持久性链接（不要用pconnect）,相反，使用sqlrelay这种第三方的数据库链接池，或者干脆自己做，因为php4中mysql的链接池经常出问题。 系统架构之HTML静态化 其实大家都知道，效率最高、消耗最小的就是纯静态化 http://www.ablanxue.com/shtml/201207/776.shtml的html页面，所以我们尽可能使我们的网站上的页面采用静态页面来实现，这个最简单的方法其实也是 最有效的方法。但是对于大量内容并且频繁更新的网站，我们无法全部手动去挨个实现，于是出现了我们常见的信息发布系统CMS，像我们常访问的各个门户站点 的新闻频道，甚至他们的其他频道，都是通过信息发布系统来管理和实现的，信息发布系统可以实现最简单的信息录入自动生成静态页面，还能具备频道管理、权限 管理、自动抓取等功能，对于一个大型网站来说，拥有一套高效、可管理的CMS是必不可少的。 除了门户和信息发布类型的网站，对于交互性要求很高的社区类型网站来说，尽可能的静态化也是提高性能的必要手段，将社区内的帖子、文章进行实时的静态化，有更新的时候再重新静态化也是大量使用的策略，像Mop的大杂烩就是使用了这样的策略，网易社区等也是如此。 同时，html静态化也是某些缓存策略使用的手段，对于系统中频繁使用数据库查询但是内容更新很小的应用，可以考虑使用html静态化来实现，比如论坛 中论坛的公用设置信息，这些信息目前的主流论坛都可以进行后台管理并且存储再数据库中，这些信息其实大量被前台程序调用，但是更新频率很小，可以考虑将这 部分内容进行后台更新的时候进行静态化，这样避免了大量的数据库访问请求高并发。 网站HTML静态化解决方案 当一个Servlet资源请求到达WEB服务器之后我们会填充指定的JSP页面来响应请求: HTTP请求—Web服务器—Servlet–业务逻辑处理–访问数据–填充JSP–响应请求 HTML静态化之后: HTTP请求—Web服务器—Servlet–HTML–响应请求 静态访求如下 Servlet: 123456789101112131415161718public void doGet(HttpServletRequest request, HttpServletResponse response)​ throws ServletException, IOException &#123;​ if(request.getParameter(&quot;chapterId&quot;) != null)&#123;​ String chapterFileName = &quot;bookChapterRead_&quot;+request.getParameter(&quot;chapterId&quot;)+&quot;.html&quot;;​ String chapterFilePath = getServletContext().getRealPath(&quot;/&quot;) + chapterFileName;​ File chapterFile = new File(chapterFilePath);​ if(chapterFile.exists())&#123;response.sendRedirect(chapterFileName);return;&#125;//如果有这个文件就告诉浏览器转向 ​ INovelChapterBiz novelChapterBiz = new NovelChapterBizImpl();​ NovelChapter novelChapter = novelChapterBiz.searchNovelChapterById(Integer.parseInt(request.getParameter(&quot;chapterId&quot;)));//章节信息 ​ int lastPageId = novelChapterBiz.searchLastCHapterId(novelChapter.getNovelId().getId(), novelChapter.getId());​ int nextPageId = novelChapterBiz.searchNextChapterId(novelChapter.getNovelId().getId(), novelChapter.getId());​ request.setAttribute(&quot;novelChapter&quot;, novelChapter);​ request.setAttribute(&quot;lastPageId&quot;, lastPageId);​ request.setAttribute(&quot;nextPageId&quot;, nextPageId);​ new CreateStaticHTMLPage().createStaticHTMLPage(request, response, getServletContext(), ​ chapterFileName, chapterFilePath, &quot;/bookRead.jsp&quot;);​ &#125;&#125; 生成HTML静态页面的类: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.jb.y2t034.thefifth.web.servlet;import java.io.ByteArrayOutputStream;import java.io.FileOutputStream;import java.io.IOException;import java.io.OutputStreamWriter;import java.io.PrintWriter;import javax.servlet.RequestDispatcher;import javax.servlet.ServletContext;import javax.servlet.ServletException;import javax.servlet.ServletOutputStream;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpServletResponseWrapper;/*** 创建HTML静态页面* 功能：创建HTML静态页面* 时间：2009年1011日* 地点：home* @author mavk * */ public class CreateStaticHTMLPage &#123; /** * 生成静态HTML页面的方法 * @param request 请求对象 * @param response 响应对象 * @param servletContext Servlet上下文 * @param fileName 文件名称 * @param fileFullPath 文件完整路径 * @param jspPath 需要生成静态文件的JSP路径(相对即可) * @throws IOException * @throws ServletException */ public void createStaticHTMLPage(HttpServletRequest request, HttpServletResponse response,ServletContext servletContext,String fileName,String fileFullPath,String jspPath) throws ServletException, IOException&#123; response.setContentType(&quot;text/html;charset=gb2312&quot;);//设置HTML结果流编码(即HTML文件编码) RequestDispatcher rd = servletContext.getRequestDispatcher(jspPath);//得到JSP资源 final ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();//用于从ServletOutputStream中接收资源 final ServletOutputStream servletOuputStream = new ServletOutputStream()&#123;//用于从HttpServletResponse中接收资源 public void write(byte[] b, int off,int len)&#123; byteArrayOutputStream.write(b, off, len); &#125; public void write(int b)&#123; byteArrayOutputStream.write(b); &#125; &#125;; final PrintWriter printWriter = new PrintWriter(new OutputStreamWriter(byteArrayOutputStream));//把转换字节流转换成字符流 HttpServletResponse httpServletResponse = new HttpServletResponseWrapper(response)&#123;//用于从response获取结果流资源(重写了两个方法) public ServletOutputStream getOutputStream()&#123; return servletOuputStream; &#125; public PrintWriter getWriter()&#123; return printWriter; &#125; &#125;; rd.include(request, httpServletResponse);//发送结果流 printWriter.flush();//刷新缓冲区，把缓冲区的数据输出 FileOutputStream fileOutputStream = new FileOutputStream(fileFullPath); byteArrayOutputStream.writeTo(fileOutputStream);//把byteArrayOuputStream中的资源全部写入到fileOuputStream中 fileOutputStream.close();//关闭输出流，并释放相关资源 response.sendRedirect(fileName);//发送指定文件流到客户端 &#125; &#125; 关注点之缓存、负载均衡、存储 缓存是另一个大问题，我一般用memcached来做缓存集群，一般来说部署10台左右就差不多（10g内存池）。需要注意一点，千万不能用使用 swap，最好关闭linux的swap。 负载均衡/加速 可能上面说缓存的时候，有人第一想的是页面静态化，所谓的静态html，我认为这是常识，不属于要点了。页面的静态化随之带来的是静态服务的 负载均衡和加速。我认为Lighttped+Squid是最好的方式了。 LVS &lt;-------&gt;lighttped====&gt;squid(s) ====lighttpd 上面是我经常用的。注意，我没有用apache，除非特定的需求，否则我不部署apache，因为我一般用php-fastcgi配合lighttpd, 性能比apache+mod_php要强很多。 squid的使用可以解决文件的同步等等问题，但是需要注意，你要很好的监控缓存的命中率，尽可能的提高的90%以上。 squid和lighttped也有很多的话题要讨论，这里不赘述。 存储 存储也是一个大问题，一种是小文件的存储，比如图片这类。另一种是大文件的存储，比如搜索引擎的索引，一般单文件都超过2g以上。 小文件的存储最简单的方法是结合lighttpd来进行分布。或者干脆使用Redhat的GFS，优点是应用透明，缺点是费用较高。我是指 你购买盘阵的问题。我的项目中，存储量是2-10Tb，我采用了分布式存储。这里要解决文件的复制和冗余。 这样每个文件有不同的冗余，这方面可以参考google的gfs的论文。 大文件的存储，可以参考nutch的方案，现在已经独立为hadoop子项目。(你可以google it) 其他： 此外，passport等也是考虑的，不过都属于比较简单的了。 系统架构之图片服务器分离 大家知道，对于Web 服务器来说，不管是Apache、IIS还是其他容器，图片是最消耗资源的，于是我们有必要将图片与页面进行分离，这是基本上大型网站都会采用的策略，他 们都有独立的图片服务器，甚至很多台图片服务器。这样的架构可以降低提供页面访问请求的服务器系统压力，并且可以保证系统不会因为图片问题而崩溃，在应用 服务器和图片服务器上，可以进行不同的配置优化，比如apache在配置ContentType的时候可以尽量少支持，尽可能少的LoadModule， 保证更高的系统消耗和执行效率。 利用Apache实现图片服务器的分离 缘由： 起步阶段的应用，都可能部署在一台服务器上（费用上的原因） 第一个优先分离的，肯定是数据库和应用服务器。 第二个分离的，会是什么呢？各有各的考虑，我所在的项目组重点考虑的节约带宽，服务器性能再好，带宽再高，并发来了，也容易撑不住。因此，我这篇文章的重点在这里。这里重点是介绍实践，不一定符合所有情况，供看者参考吧， 环境介绍： WEB应用服务器：4CPU双核2G, 内存4G 部署：Win2003/Apache Http Server 2.1/Tomcat6 数据库服务器：4CPU双核2G, 内存4G 部署：Win2003/MSSQL2000 步骤： 步骤一：增加2台配置为：2CPU双核2G，内存2G普通服务器，做资源服务器 部署：Tomcat6，跑了一个图片上传的简单应用，（记得指定web.xml的），并指定域名为res1.***.com,res2.***.com，采用ajp协议 步骤二：修改Apache httpd.conf配置 原来应用的文件上传功能网址为： 1、/fileupload.html 2、/otherupload.html 在httpd.conf中增加如下配置 1234567891011&lt;VirtualHost *:80&gt; ServerAdmin webmaster@***.com ProxyPass /fileupload.html balancer://rescluster/fileupload lbmethod=byrequests stickysession=JSESSIONID nofailover=Off timeout=5 maxattempts=3 ProxyPass /otherupload.html balancer://rescluster/otherupload.html lbmethod=byrequests stickysession=JSESSIONID nofailover=Off timeout=5 maxattempts=3 #&lt;!--负载均衡--&gt; &lt;Proxy balancer://rescluster/&gt; ​ BalancerMember ajp://res1.***.com:8009 smax=5 max=500 ttl=120 retry=300 loadfactor=100 route=tomcat1 ​ BalancerMember ajp://res2.***.com:8009 smax=5 max=500 ttl=120 retry=300 loadfactor=100 route=tomcat2 &lt;/Proxy&gt; &lt;/VirtualHost&gt; 步骤三，修改业务逻辑： 所有上传文件在数据库中均采用全url的方式保存，例如产品图片路径存成：http://res1.***.com/upload/20090101/product120302005.jpg 现在，你可以高枕无忧了，带宽不够时，增加个几十台图片服务器，只需要稍微修改一下apache的配置文件，即可。 系统架构之数据库集群和库表散列 大型网站都有复杂的应用，这些应用必须使用数据库，那么在面对大量访问的时候，数据库的瓶颈很快就能显现出来，这时一台数据库将很快无法满足应用，于是我们需要使用数据库集群或者库表散列。 在数据库集群方面，很多数据库都有自己的解决方案，Oracle、Sybase等都有很好的方案，常用的MySQL提供的Master/Slave也是类似的方案，您使用了什么样的DB，就参考相应的解决方案来实施即可。 上面提到的数据库集群由于在架构、成本、扩张性方面都会受到所采用DB类型的限制，于是我们需要从应用程序的角度来考虑改善系统架构，库表散列是常用并 且最有效的解决方案。我们在应用程序中安装业务和应用或者功能模块将数据库进行分离，不同的模块对应不同的数据库或者表，再按照一定的策略对某个页面或者 功能进行更小的数据库散列，比如用户表，按照用户ID进行表散列，这样就能够低成本的提升系统的性能并且有很好的扩展性。sohu的论坛就是采用了这样的 架构，将论坛的用户、设置、帖子等信息进行数据库分离，然后对帖子、用户按照板块和ID进行散列数据库和表，最终可以在配置文件中进行简单的配置便能让系 统随时增加一台低成本的数据库进来补充系统性能。 集群软件的分类： 一般来讲，集群软件根据侧重的方向和试图解决的问题，分为三大类：高性能集群（High performance cluster，HPC）、负载均衡集群（Load balance cluster， LBC），高可用性集群（High availability cluster，HAC）。 高性能集群（High performance cluster，HPC），它是利用一个集群中的多台机器共同完成同一件任务，使得完成任务的速度和可靠性都远远高于单机运行的效果。弥补了单机性能上的不足。该集群在天气预报、环境监控等数据量大，计算复杂的环境中应用比较多； 负载均衡集群（Load balance cluster， LBC），它是利用一个集群中的多台单机，完成许多并行的小的工作。一般情况下，如果一个应用使用的人多了，那么用户请求的响应时间就会增大，机器的性能也会受到影响，如果使用负载均衡集群，那么集群中任意一台机器都能响应用户的请求，这样集群就会在用户发出服务请求之后，选择当时负载最小，能够提供最好的服务的这台机器来接受请求并相应，这样就可用用集群来增加系统的可用性和稳定性。这类集群在网站中使用较多； 高可用性集群（High availability cluster，HAC），它是利用集群中系统 的冗余，当系统中某台机器发生损坏的时候，其他后备的机器可以迅速的接替它来启动服务，等待故障机的维修和返回。最大限度的保证集群中服务的可用性。这类系统一般在银行，电信服务这类对系统可靠性有高的要求的领域有着广泛的应用。 2 数据库集群的现状 数据库集群是将计算机集群技术引入到数据库中来实现的，尽管各厂商宣称自己的架构如何的完美，但是始终不能改变Oracle当先，大家追逐的事实，在集群的解决方案上Oracle RAC还是领先于包括微软在内的其它数据库厂商，它能满足客户高可用性、高性能、数据库负载均衡和方便扩展的需求。 Oracle’s Real Application Cluster (RAC) Microsoft SQL Cluster Server (MSCS) IBM’s DB2 UDB High Availability Cluster(UDB) Sybase ASE High Availability Cluster (ASE) MySQL High Availability Cluster (MySQL CS) 基于IO的第三方HA(高可用性)集群 当前主要的数据库集群技术有以上六大类，有数据库厂商自己开发的；也有第三方的集群公司开发的；还有数据库厂商与第三方集群公司合作开发的，各类集群实现的功能及架构也不尽相同。 RAC（Real Application Cluster，真正应用集群）是Oracle9i数据库中采用的一项新技术，也是Oracle数据库支持网格计算环境的核心技术。它的出现解决了传统数据库应用中面临的一个重要问题：高性能、高可伸缩性与低价格之间的矛盾。在很长一段时间里，甲骨文都以其实时应用集群技术(Real Application Cluster，RAC)统治着集群数据库市场 系统架构之缓存 缓存一词搞技术的都接触过，很多地方用到缓存。网站架构和网站开发中的缓存也是非常重要。这里先讲述最基本的两种缓存。高级和分布式的缓存在后面讲述。 架构方面的缓存，对Apache比较熟悉的人都能知道Apache提供了自己的缓存模块，也可以使用外加的Squid模块进行缓存，这两种方式均可以有效的提高Apache的访问响应能力。 网站程序开发方面的缓存，Linux上提供的Memory Cache是常用的缓存接口，可以在web开发中使用，比如用Java开发的时候就可以调用MemoryCache对一些数据进行缓存和通讯共享，一些大 型社区使用了这样的架构。另外，在使用web语言开发的时候，各种语言基本都有自己的缓存模块和方法，PHP有Pear的Cache模块，Java就更多了，.net不是很熟悉，相信也肯定有。","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://bobit.github.io/categories/并发编程/"}],"tags":[{"name":"高并发","slug":"高并发","permalink":"https://bobit.github.io/tags/高并发/"},{"name":"高负载","slug":"高负载","permalink":"https://bobit.github.io/tags/高负载/"}]},{"title":"高并发系统的开发注意事项","slug":"并发编程/高并发系统的开发注意事项","date":"2017-11-13T14:27:17.000Z","updated":"2018-12-21T12:56:55.823Z","comments":true,"path":"posts/396258dc.html","link":"","permalink":"https://bobit.github.io/posts/396258dc.html","excerpt":"","text":"对于高并发并没有什么通用解决方案,必须根据业务场景进行分析,不同的业务场景对于架构的取舍是不一样的.但万变不离其宗,掌握这些处理高并发的分析方法还是很有必要的. 负载均衡 任务服务器hibernate+tomcat+数据库 商用服务器经常因为一些商业的原因被很多为生活苦苦奋斗的hack们扫荡。对于一个要支持高并发的系统来说，在开发阶段有几个事情需要我们注意： 如果你用hibernate，注意你的主键获取不要用increment了，那玩意在并发的时候给你带来主键约束错误，还是考虑使用sequence之类的主键策略吧 定时任务的考虑，并不是所有的定时任务都需要考虑并发的情况。但是例如定时些数据库的时候，如果你做负载均衡了，每个服务器都会写，是否造成重复写脏数据就需要看业务逻辑而定了。例如：你要定时给某个邮箱发送邮件，负载的时候，每个机器都会做相同的操作，定时任务会造成多个机器都发送邮件。（你可以考虑将某些定时任务移动到存储过程或者使用单独的定时服务器来做。） 使用二级缓存的时候注意，负载均衡的时候，你的二级缓存对数据的处理是否还符合业务逻辑？ 常见的负载均衡：就是多个服务器执行相同的代码，我们通过tomcat将请求均衡的分布在某个服务器上。如果你使用increment策略，在开发组内多个成员在各自的开发机器上进行数据添加的时候，经常会出现主键约束错误 定时任务：有些定时任务在多台机器做负载均衡的时候不适合使用，你可以考虑将任务使用一个链接请求处理，然后在做一个单独的请求链接的项目，定时请求链接。这样做的好处是：即利用了系统的负载均衡，同时还利用了系统本身的业务逻辑。 业务逻辑 在高并发的情况下如何找到业务繁忙的热点并进行优化,完全只能凭经验. 从处理技巧上,至少你可以知道处理高并发的业务逻辑是: ​ 前端:异步请求+资源静态化+cdn ​ 后端:请求队列+轮询分发+负载均衡+共享缓存 ​ 数据层:redis缓存+数据分表+写队列 ​ 存储:raid阵列+热备 ​ 网络:dns轮询+DDOS攻击防护 多学习 如何学习高并发的工具? 处理高并发的开源轮子其实很多.很多高并发的架构分享都会提及使用的工具,自己多留心,再看看手册,有条件自己搭起来跑一跑。redis,nginx/Tengine,keeplive,DRBD,heartbeat这些小工具还是可以在虚拟机上面多开几台跑起来的.至于大业务场景,除了进大公司没有别的办法,因为有些工具运行的配置要求太高,必须多台服务器配合才能完成. 如何模拟高并发场景? 并不是只有实际生产环境才能测试高并发,其实模拟高并发的轮子也很多,最常用的apache benchmark,winrunner,loadrunner,这些教程很多,用来模拟基本的高并发业务绰绰有余,自己安装试用版,学学如何用,模拟些常用的业务。如果有精力,业内很喜欢用perl,python,C来写一些针对热点业务的负载脚本.这需要有http协议等网络封包的理论基础. 一些建议 处理高并发要学习的东西实在太多.要在没有实际工作经验的情况下逐一了解太难,也很难深入.对于高并发的学习,我建议除了多阅读高并发架构的文档学习基本的方法论以外,自己要去深入学习网络基础,数据结构和算法.这些都是处理高并发热点的理论基础. 高并发量网站解决方案 一个小型的网站 可以使用最简单的html静态页面就实现了，配合一些图片达到美化效果，所有的页面均存放在一个目录下，这样的网站对系统架构、性能的要求都很简单。随着互联网业务的不断丰富，网站相关的技术经过这些年的发展，已经细分到很细的方方面面，尤其对于大型网站来说，所采用的技术更是涉及面非常 广，从硬件到软件、编程语言、数据库、WebServer、防火墙等各个领域都有了很高的要求，已经不是原来简单的html静态网站所能比拟的。 大型网站 比如门户网站，在面对大量用户访问、高并发请求方面，基本的解决方案集中在这样几个环节：使用高性能的服务器、高性能的数据库、高效率的编程语言、还有高性能的Web容器。这几个解决思路在一定程度上意味着更大的投入。 HTML静态化 其实大家都知道，效率最高、消耗最小的就是纯静态化的html页面，所以我们尽可能使我们的网站上的页面采用静态页面来实现，这个最简单的方法其实也是 最有效的方法。但是对于大量内容并且频繁更新的网站，我们无法全部手动去挨个实现，于是出现了我们常见的信息发布系统CMS，像我们常访问的各个门户站点 的新闻频道，甚至他们的其他频道，都是通过信息发布系统来管理和实现的，信息发布系统可以实现最简单的信息录入自动生成静态页面，还能具备频道管理、权限 管理、自动抓取等功能，对于一个大型网站来说，拥有一套高效、可管理的CMS是必不可少的。 除了门户和信息发布类型的网站，对于交互性要求很高的社区类型网站来说，尽可能的静态化也是提高性能的必要手段，将社区内的帖子、文章进行实时的静态化、有更新的时候再重新静态化也是大量使用的策略，像Mop的大杂烩就是使用了这样的策略，网易社区等也是如此。 同时，html静态化也是某些缓存策略使用的手段，对于系统中频繁使用数据库查询但是内容更新很小的应用，可以考虑使用html静态化来实现。比如论坛 中论坛的公用设置信息，这些信息目前的主流论坛都可以进行后台管理并且存储在数据库中，这些信息其实大量被前台程序调用，但是更新频率很小，可以考虑将这 部分内容进行后台更新的时候进行静态化，这样避免了大量的数据库访问请求。 图片服务器分离 大家知道，对于Web服务器来说，不管是Apache、IIS还是其他容器，图片是最消耗资源的，于是我们有必要将图片与页面进行分离，这是基本上大型 网站都会采用的策略，他们都有独立的、甚至很多台的图片服务器。这样的架构可以降低提供页面访问请求的服务器系统压力，并且可以保证系统不会因为图片问题 而崩溃。 在应用服务器和图片服务器上，可以进行不同的配置优化，比如apache在配置ContentType的时候可以尽量少支持、尽可能少的LoadModule，保证更高的系统消耗和执行效率。 数据库集群、库表散列 大型网站都有复杂的应用，这些应用必须使用数据库，那么在面对大量访问的时候，数据库的瓶颈很快就能显现出来，这时一台数据库将很快无法满足应用，于是我们需要使用数据库集群或者库表散列。 在数据库集群方面，很多数据库都有自己的解决方案，Oracle、Sybase等都有很好的方案，常用的MySQL提供的Master/Slave也是类似的方案，您使用了什么样的DB，就参考相应的解决方案来实施即可。 上面提到的数据库集群由于在架构、成本、扩张性方面都会受到所采用DB类型的限制，于是我们需要从应用程序的角度来考虑改善系统架构，库表散列是常用并且最有效的解决方案。 我们在应用程序中安装业务和应用或者功能模块将数据库进行分离，不同的模块对应不同的数据库或者表，再按照一定的策略对某个页面或者功能进行更小的数据库散列，比如用户表，按照用户ID进行表散列，这样就能够低成本的提升系统的性能并且有很好的扩展性。 sohu的论坛就是采用了这样的架构，将论坛的用户、设置、帖子等信息进行数据库分离，然后对帖子、用户按照板块和ID进行散列数据库和表，最终可以在配置文件中进行简单的配置便能让系统随时增加一台低成本的数据库进来补充系统性能。 缓存 缓存一词搞技术的都接触过，很多地方用到缓存。网站架构和网站开发中的缓存也是非常重要。这里先讲述最基本的两种缓存。高级和分布式的缓存在后面讲述。 架构方面的缓存，对Apache比较熟悉的人都能知道Apache提供了自己的缓存模块，也可以使用外加的Squid模块进行缓存，这两种方式均可以有效的提高Apache的访问响应能力。 网站程序开发方面的缓存，Linux上提供的Memory Cache是常用的缓存接口，可以在web开发中使用，比如用Java开发的时候就可以调用MemoryCache对一些数据进行缓存和通讯共享，一些大 型社区使用了这样的架构。另外，在使用web语言开发的时候，各种语言基本都有自己的缓存模块和方法，PHP有Pear的Cache模块，Java就更多 了，.net不是很熟悉，相信也肯定有。 镜像 镜像是大型网站常采用的提高性能和数据安全性的方式，镜像的技术可以解决不同网络接入商和地域带来的用户访问速度差异，比如ChinaNet和 EduNet之间的差异就促使了很多网站在教育网内搭建镜像站点，数据进行定时更新或者实时更新。在镜像的细节技术方面，这里不阐述太深，有很多专业的现 成的解决架构和产品可选。也有廉价的通过软件实现的思路，比如Linux上的rsync等工具。 负载均衡 负载均衡将是大型网站解决高负荷访问和大量并发请求采用的高端解决办法。 负载均衡技术发展了多年，有很多专业的服务提供商和产品可以选择，我个人接触过一些解决方法，其中有两个架构可以给大家做参考。 （1）、硬件四层交换 第四层交换使用第三层和第四层信息包的报头信息，根据应用区间识别业务流，将整个区间段的业务流分配到合适的应用服务器进行处理。 第四层交换功能就像是虚IP，指向物理服务器。它传输的业务服从的协议多种多样，有HTTP、FTP、NFS、Telnet或其他协议。这些业务在物理 服务器基础上，需要复杂的载量平衡算法。在IP世界，业务类型由终端TCP或UDP端口地址来决定，在第四层交换中的应用区间则由源端和终端IP地址、 TCP和UDP端口共同决定。 在硬件四层交换产品领域，有一些知名的产品可以选择，比如Alteon、F5等，这些产品很昂贵，但是物有所值，能够提供非常优秀的性能和很灵活的管理能力。“Yahoo中国”当初接近2000台服务器，只使用了三、四台Alteon就搞定了。 (2)、软件四层交换 大家知道了硬件四层交换机的原理后，基于OSI模型来实现的软件四层交换也就应运而生，这样的解决方案实现的原理一致，不过性能稍差。但是满足一定量的压力还是游刃有余的，有人说软件实现方式其实更灵活，处理能力完全看你配置的熟悉能力。 软件四层交换我们可以使用Linux上常用的LVS来解决，LVS就是Linux Virtual Server，他提供了基于心跳线heartbeat的实时灾难应对解决方案，提高系统的强壮性，同时可供了灵活的虚拟VIP配置和管理功能，可以同时满 足多种应用需求，这对于分布式的系统来说必不可少。 一个典型的使用负载均衡的策略就是，在软件或者硬件四层交换的基础上搭建squid集群，这种思路在很多大型网站包括搜索引擎上被采用，这样的架构低成本、高性能还有很强的扩张性，随时往架构里面增减节点都非常容易。 对于大型网站来说，前面提到的每个方法可能都会被同时使用到，这里介绍得比较浅显，具体实现过程中很多细节还需要大家慢慢熟悉和体会。有时一个很小的squid参数或者apache参数设置，对于系统性能的影响就会很大。 CDN加速技术 什么是CDN？ CDN的全称是内容分发网络。其目的是通过在现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络“边缘”，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。 CDN有别于镜像，因为它比镜像更智能，或者可以做这样一个比喻：CDN=更智能的镜像+缓存+流量导流。因而，CDN可以明显提高Internet网 络中信息流动的效率。从技术上全面解决由于网络带宽小、用户访问量大、网点分布不均等问题，提高用户访问网站的响应速度。 CDN的实现 ​ 分为三类：镜像、高速缓存、专线。 镜像站点（Mirror Site），是最常见的，它让内容直接发布，适用于静态和准动态的数据同步。但是购买和维护新服务器的费用较高，还必须在各个地区设置镜像服务器，配备专业技术人员进行管理与维护。对于大型网站来说，更新所用的带宽成本也大大提高了。 高速缓存，成本较低，适用于静态内容。Internet的统计表明，超过80%的用户经常访问的是20%的网站的内容，在这个规律下，缓存服务器可以处 理大部分客户的静态请求，而原始的服务器只需处理约20%左右的非缓存请求和动态请求，于是大大加快了客户请求的响应时间，并降低了原始服务器的负载。 CDN服务一般会在全国范围内的关键节点上放置缓存服务器。 专线，让用户直接访问数据源，可以实现数据的动态同步。 CDN的实例 举个例子来说，当某用户访问网站时，网站会利用全球负载均衡技术，将用户的访问指向到距离用户最近的正常工作的缓存服务器上，直接响应用户的请求。 当用户访问已经使用了CDN服务的网站时，其解析过程与传统解析方式的最大区别就在于网站的授权域名服务器不是以传统的轮询方式来响应本地DNS的解析 请求，而是充分考虑用户发起请求的地点和当时网络的情况，来决定把用户的请求定向到离用户最近同时负载相对较轻的节点缓存服务器上。 通过用户定位算法和服务器健康检测算法综合后的数据，可以将用户的请求就近定向到分布在网络“边缘”的缓存服务器上，保证用户的访问能得到更及时可靠的响应。 由于大量的用户访问都由分布在网络边缘的CDN节点缓存服务器直接响应了，这就不仅提高了用户的访问质量，同时有效地降低了源服务器的负载压力。 附：某CDN服务商的服务说明 采用GCDN加速方式 采用了GCDN加速方式以后，系统会在浏览用户和您的服务器之间增加一台GCDN服务器。浏览用户访问您的服务器时，一般静态数据，如图片、多媒体资料等数据将直接从GCDN服务器读取，使得从主服务器上读取静态数据的交换量大大减少。 为VIP型虚拟主机而特加的VPN高速压缩通道，使用高速压缩的电信&lt;&gt;网通、电信&lt;&gt;国际（HK）、网通&amp; lt;==&gt;国际（HK）等跨网专线通道，智能多线，自动获取最快路径，极速的动态实时并发响应速度，实现了网站的动态脚本实时同步，对动态网站有 一个更加明显的加速效果。 每个网络运营商（电信、网通、铁通、教育网）均有您服务器的GCDN服务器，无论浏览用户是来自何处，GCDN都能让您的服务器展现最快的速度！另外，我们将对您的数据进行实时备份，让您的数据更安全！","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://bobit.github.io/categories/并发编程/"}],"tags":[{"name":"高并发","slug":"高并发","permalink":"https://bobit.github.io/tags/高并发/"}]},{"title":"Java日志框架总结","slug":"并发编程/Java日志框架总结","date":"2017-11-13T14:26:17.000Z","updated":"2018-12-21T12:57:03.788Z","comments":true,"path":"posts/18c040aa.html","link":"","permalink":"https://bobit.github.io/posts/18c040aa.html","excerpt":"","text":"作为一名Java程序员，我们开发了很多Java应用程序，包括桌面应用、WEB应用以及移动应用。然而日志系统是一个成熟Java应用所必不可少的，在开发和调试阶段，日志可以帮助我们更好更快地定位bug；在运行维护阶段，日志系统又可以帮我们记录大部分的异常信息，从而帮助我们更好的完善系统。本文要来分享一些Java程序员最常用的Java日志框架组件。 1、Log4j – 最受欢迎的Java日志组件 Log4j是一款基于Java的开源日志组件，Log4j功能非常强大，我们可以将日志信息输出到控制台、文件、用户界面，也可以输出到操作系统的事件记录器和一些系统常驻进程。更值得一提的是，Log4j可以允许你非常便捷地自定义日志格式和日志等级，可以帮助开发人员全方位地掌控日志信息。 官方网站：http://logging.apache.org/log4j/2.x/ 2、SLF4J – 基于API的Java日志框架 SLF4J提供了一个简单统一的日志记录接口，开发者在配置和部署时只需要实现这个接口即可实现日志功能。 Logging API实现既可以选择直接实现SLF4J接的loging APIs如： NLOG4J、SimpleLogger。也可以通过SLF4J提供的API实现来开发相应的适配器如Log4jLoggerAdapter、JDK14LoggerAdapter。 官方网站：http://www.slf4j.org/ 3、Commons Logging Commons Logging的实现不依赖于具体的日志实现工具，仅仅提供一些日志操作的抽象接口，它对其他的日志工具做了封装，比如Log4J, Avalon LogKit, 和JDK 1.4等。 4、gclogviewer – Java日志查看工具 gclogviewer是一个支持jdk 6的gc log可视化工具，和gcviewer相比，gclogviewer支持根据gc log生成GC的趋势图，也支持生成调优建议所需的数据趋势图。 官方网站：http://code.google.com/p/gclogviewer/ 5、Flume – Apache日志服务器 之前介绍的都是一些日志记录工具，Flume则是一个日志分析系统，Flume是分布式的，它有一个非常灵活的架构，用来收集、聚合以及移动大量日志数据，并且提供可靠、容错的系统架构。 官方网站：http://flume.apache.org/ 6、zLogFabric – 日志存储系统 zLogFabric 是一个集成的跨平台日志解决方案，通过消息系统收集各个应用的日志信息存储到一个集中式的系统中。模块化的设计使得服务器可对日志进行存储、转发、警报以及生成日志统计信息。 zLogFabric 可收集来自文件、syslog、log4j、log4net 以及 Windows 事件的数据。 官方网站：http://www.zlogfabric.com/ 7、logstash – Java日志管理工具 logstash是一款功能非常强大的日志管理工具，利用logstash，你可以对日志进行传输、处理、管理和检索，并且提供Web接口以便开发者统计和查询日志信息。 官方网站：http://www.logstash.net/ 官方网站：http://commons.apache.org/proper/commons-logging/ 8、Darks Logs Darks Logs和log4j类似，也适用于Java、Android等项目，但是Darks Logs使用更加简单，而且对Android端做了非常大的改善。Darks Logs对Sqlite的日志保存增加了Appender。其旨在解决Android日志无法灵活控制日志等级、格式、保存或显示目标等常用操作等的问题。","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://bobit.github.io/categories/并发编程/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bobit.github.io/tags/Java/"}]},{"title":"Docker容器镜像删除","slug":"微服务/Docker容器镜像删除","date":"2017-11-13T14:21:17.000Z","updated":"2018-12-21T12:57:25.836Z","comments":true,"path":"posts/ce026f5a.html","link":"","permalink":"https://bobit.github.io/posts/ce026f5a.html","excerpt":"","text":"1.停止所有的container，这样才能够删除其中的images： docker stop $(docker ps -a -q) 如果要删除所有container的话再加一个指令： docker rm $(docker ps -a -q) 2.查看当前有些什么images docker images 3.删除images，通过image的id来指定删除谁 docker rmi 如果要删除untagged images，也就是那些id为的image的话可以用 docker rmi $(docker images | grep “^” | awk “{print $3}”) 要删除全部image的话 docker rmi $(docker images -q)","categories":[{"name":"Docker","slug":"Docker","permalink":"https://bobit.github.io/categories/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://bobit.github.io/tags/docker/"}]},{"title":"Spring5源码解析-Spring","slug":"源码分析/Spring5源码阅读-Spring","date":"2017-11-13T14:18:17.000Z","updated":"2018-12-27T15:12:19.444Z","comments":true,"path":"posts/6a130ff3.html","link":"","permalink":"https://bobit.github.io/posts/6a130ff3.html","excerpt":"","text":"为什么要阅读源码 学习编程不是学习配置东西，需要多看看底层的知识，《Java编程思想》里有一句深刻的话，“编程语言是程序员的表达的方式，而架构是程序员对世界的认知”。 怎么阅读源码 Spring框架包含了非常多的功能，不能漫无目地阅读，可以针对性阅读部分源码。 针对性阅读如下部分： Spring架构 Spring模块 Spring运用的设计模式 Spring框架 Spring 是一个开源框架，是为了解决企业应用程序开发复杂性而创建的。 框架的主要优势之一就是其分层架构，分层架构允许您选择使用哪一个组件， 同时为 J2EE 应用程序开发提供集成的框架 Spring框架由如下7个模块构成，组成 Spring 框架的每个模块（或组件）都可以单独存在，或者与其他一个或多个模块联合实现。 Spring模块功能 核心容器(Spring core) 核心容器提供Spring框架的基本功能。Spring以bean的方式组织和管理Java应用中的各个组件及其关系。Spring使用BeanFactory来产生和管理Bean，它是工厂模式的实现。BeanFactory使用控制反转(IoC)模式将应用的配置和依赖性规范与实际的应用程序代码分开。BeanFactory使用依赖注入的方式提供给组件依赖。 Spring上下文(Spring context) Spring上下文是一个配置文件，向Spring框架提供上下文信息。Spring上下文包括企业服务，如JNDI、EJB、电子邮件、国际化、校验和调度功能。 Spring面向切面编程(Spring AOP) 通过配置管理特性，Spring AOP 模块直接将面向方面的编程功能集成到了 Spring框架中。所以，可以很容易地使 Spring框架管理的任何对象支持 AOP。Spring AOP 模块为基于 Spring 的应用程序中的对象提供了事务管理服务。通过使用 Spring AOP，不用依赖 EJB 组件，就可以将声明性事务管理集成到应用程序中。 Spring DAO模块 DAO模式主要目的是将持久层相关问题与一般的的业务规则和工作流隔离开来。Spring 中的DAO提供一致的方式访问数据库，不管采用何种持久化技术，Spring都提供一直的编程模型。Spring还对不同的持久层技术提供一致的DAO方式的异常层次结构。 Spring ORM模块 Spring 与所有的主要的ORM映射框架都集成的很好，包括Hibernate、JDO实现、TopLink和IBatis SQL Map等。Spring为所有的这些框架提供了模板之类的辅助类，达成了一致的编程风格。 Spring 框架插入了若干个 ORM 框架，从而提供了 ORM 的对象关系工具，其中包括 JDO、Hibernate 和 iBatis SQL Map。所有这些都遵从 Spring 的通用事务和 DAO 异常层次结构。 Spring Web模块 Web上下文模块建立在应用程序上下文模块之上，为基于Web的应用程序提供了上下文。Web层使用Web层框架，可选的，可以是Spring自己的MVC框架，或者提供的Web框架，如Struts、Webwork、tapestry和jsf。 Web 模块还简化了处理多部分请求以及将请求参数绑定到域对象的工作。 Spring MVC框架(Spring WebMVC) MVC框架是一个全功能的构建Web应用程序的MVC实现。通过策略接口，MVC框架变成为高度可配置的。Spring的MVC框架提供清晰的角色划分：控制器、验证器、命令对象、表单对象和模型对象、分发器、处理器映射和视图解析器。Spring支持多种视图技术，其中包括 JSP、Velocity、Tiles、iText 和 POI。 Spring运用的设计模式","categories":[{"name":"Source","slug":"Source","permalink":"https://bobit.github.io/categories/Source/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://bobit.github.io/tags/Spring/"},{"name":"Spring5","slug":"Spring5","permalink":"https://bobit.github.io/tags/Spring5/"}]},{"title":"互联网名词大全","slug":"English/互联网名词大全","date":"2017-11-13T13:29:17.000Z","updated":"2018-12-21T13:10:40.872Z","comments":true,"path":"posts/d6a87309.html","link":"","permalink":"https://bobit.github.io/posts/d6a87309.html","excerpt":"","text":"数据统计分析篇 PC 网站 Traffic 流量，在互联网领域内，统计网站使用量的笼统用语。 UV Unique Vister，独立访客。 PV Page View，即网站被浏览的总次数。 IP 即Internet Protocols，指独立 IP 数，一天内相同 IP 地址只被计算一次。 Impressions 展示数，也称接触人次，用户打开网页或者广告的每一次显示，就是一个 Impression；广告主希望 10 万人次看到广告，就是 10 万次 Impression；是评估广告效果的元素之一。 Click （点击量/点击次数）即 Click through，用户点击广告的次数，评估广告效果的指标之一。 Click Rate （点击率/点进率）即 Click through Rate;即网络广告被点击的次数与访问次数的比例，即 clicks/impressions.如果这个页面 被访问了 100 次，而页面上的广告也被点击了 20 次，那么 CTR 为 20%，CTR 是评估广告效果的指标之一。 人均访问页面 PV 总和除以 IP=人均访问页面。人均访问页面&gt;=10 个，才算优质用户。 页面停留时间 访客浏览单页面所花费的平均时长,页面的停留时长=进入下一个页面的时 间-进入本页面 的时间。 Reach 到达率，特定目标受众，在特定时期内有机会看到广告或广告活动的比例。也称为“覆盖 ”或“覆盖范围”。 跳出率： 跳出率是指浏览了一个页面就离开的用户占一组页面或一个页面访问次数的百分比。 二跳率 网站页面展开后，用户在页面上产生的首次点击被称为 “二跳”，二跳的次数即为”二跳量”，二跳量与浏览量的比值称为页面的二跳率。 CR 转化率，Conversion Rate 的缩写，是指访问某一网站访客中，转化的访客占全部访客的比例。 ROI Return On Investment 的缩写，投资回报率。是指通过投资而应返回的价值，即企业从一项投资活动 中得到的经济回报。它涵盖了企业的获利目标。 电商 SKU Stock Keeping Unit（库存量单位）。即库存进出计量的单位，可以是以件，盒，托盘等为单位。SKU 这是 对于大型连锁超市 DC（配送中心）物流管理的一个必要的方法。现在已经被引申为产品统 一编号的简称，每种产品均对应有唯一的 SKU 号。 客单价 是指每一个订单的平均购买商品金额，也就是平均交易金额。 GMV Gross Merchandise Volume，是成交总额（一定时间段内）的意思。 动销率 商品动销率=动销品种数 ÷ 门店经营总品种数*100%。 重复购买率 指消费者在网站中的重复购买次数。 APP DAU Daily Active User，日活跃用户数量。 MAU Month Active User 月活跃用户量。 ARPU (Average Revenue Per User)即每用户平均收入，用于衡量电信运营商和互联网公司业务收入的指标。 用户留存率 在互联网行业中，用户在某段时间内开始使用应用，经过一段时间后，仍然继续使用该应用的用户，被认作是留存用户。这部分用户占当时新增用户的比例即是留存率，会按照每隔 1 单位时间（例日、周、月）来进行统计。 商业模式篇 B2B（经济组织对经济组织） 是指企业对企业之间的营销关系，它将企业内部网，通过B2B网站与客户紧密结合起来，通过网络的快速反应，为客户提供更好的服务，从而促进企业的业务发展。 B2C（经济组织对消费者） B2C 即企业通过互联网为消费者提供一个新型的购物环境—— 网上商店，消费者通过网络在网上购物、网上支付等消费行为。 B2B2C（企业对企业对消费者） 是一种电子商务类型的网络购物商业模式，B是BUSINESS的简称，C是CUSTOMER的简称，第一个B指的是商品或服务的供应商，第二个B指的是从事电子商务的企业，C则是表示消费者。 C2C（消费者对消费者） 就是个人与个人之间的电子商务。比如一个消费者有一台电脑，通过网络进行交易，把它出售给另外一个消费者，此种交易类型就称为 C2C 电子商务。 C2B（消费者集合竞价团购） 先有消费者需求产生而后有企业生产，即先有消费者提出需求，后有生产企业按需求组织生产。 F2C 指的是 Factory to customer，即从厂商直接到消费者个人的电子商务模式 O2O（网上与网下相结合）是指将线下的商务机会与互联网结合，让互联网成为线下交易的前台。 P2P（点对点、渠道对渠道） 是英文 peer-to peer 的缩写，意即个人对个人。又称点对点网络借款，是一种将小额资金聚集起来借贷给 有资金需求人群的一种民间小额借贷模式。 P2P 还有一种更广泛的概念，泛指互联网金融，借助互联网、移动互联网技术的网络信贷平 台及相关理财行为、金融服务。 众筹 是指用团购+预购的形式，向网友募集项目资金的模式。众筹利用互联网和 SNS 传播的特性，让小企业、艺术家或个人对公众展示他们的创意，争取大家的关注和支持，进而获得所需要的资金援助。 众包 众包指的是一个公司或机构把过去由员工执行的工作任务，以自由自愿的形式外包给非特定的（而且通常是大型的）大众网络的做法。众包的任务通常是由个人来承担，但如果涉及到需要多人协作完成的任务，也有可能以依靠开源的个体生产的形式出现。 孵化器 一般指企业孵化器，在中国也称高新技术创业服务中心，它通过为新创办的科技型中小企业提供物理空间和基础设施，提供一系列的服务支持，进而降低创业者的创业风 险和创业成本，提高创业成功率，促进科技成果转化，培养成功的企业和企业家。 SaaS（软件服务） 是 Software-as-aService（软件即服务）的简称。它是一种通过 Internet 提供软件的模式，厂商将应用软件 统一部署在自己的服务器上，客户可以根据自己实际需求，通过互联网向厂商定购所需的 应用软件服务，按定购的服务多少和时间长短向厂商支付费用，并通过互联网获得厂商提 供的服务。 CRM 现代信息技术、经营思想的结合体，它以信息技术为手段，通过对以“客户为中心” 的业务流程的重要组合和设计，形成一个自动化的解决方案，以提高客户的忠诚度，最终实现业务操作效益的提高和利润的增长。 SoLoMo（社交+本地化+移动） 这个词形容三种概念混合的产物，即：Social（社交的）、Local（本地的）、Mobile（移动的），连起来就是 SoLoMo（索罗门），社交本地移动，即社交加本地化加移动，它代表着未来互联网发展的趋势。 LBS 基于位置的服务，它是通过电信移动运营商的无线电通讯网络（如 GSM 网、CDMA 网）或外部定位方式(如 GPS)获取移动终端用户的位置信息（地理坐标，或大地坐标），在地理信息系统（外语缩写：GIS、外语全称：Geographic Information System）平台的支持下，为用户提供相应服务的一种增值业务。 SNS Social Networking Services，即社会性网络服务，是指个人之间的关系网络,这种基于社会网络关 系系统思想的网站就是社会性网络网站(SNS 网站)。现在许多 WEB2.0 网站都属于SNS 网站， 如网络聊天（IM）、交友、视频分享、博客、播客、网络社区、音乐共享等。社会性网络 的理论基础源于六度理论（六度分隔理论，Six Degrees of Separation）和150 法则（Rule Of 150）。另外不仅现在一些大公司网站开始了一些 SNS 应用，一些垂直领域的行业站点也开 始了 SNS 的尝试。目前国外较出名的是 facebook、myspac，国内流行的 SNS 有海内、校内、 开心、51 等。 OTT “Over The Top”的缩写，是指通过互联网向用户提供各种应用服务。这种应用和目前运营商所提供的 通信业务不同，它仅利用运营商的网络，而服务由运营商之外的第三方提供。目前，典型的OTT业务有互联网电视业务，苹果应用商店等。 OTA 旅游电子商务行业的专业词语。代表为号码百事通、旅游百事通、驴妈妈旅游网、携程网、出游客旅游网、乐途旅游网、欣欣旅游网、芒果网、艺龙网、同程网、搜旅网、途 牛旅游网和易游天下、快乐 e 行旅行网等。OTA 的出现将原来传统的旅行社销售模式放到网络平台上，更广泛的传递了线路信息，互动式的交流更方便了客人的咨询和订购。 电子商务 以信息网络技术为手段，以商品交换为中心的商务活动。在因特网开放的网络 环境下，基于浏览器/服务器应用方式，买卖双方不谋面地进行各种商贸活动，实现消费者的网上购物、商户之间的网上交易和在线电子支付以及各种商务活动、交易活动、金融活 动和相关的综合服务活动的一种新型的商业运营模式。电子商务分为：ABC、B2B、B2C、C2 C、B2M、M2C、B2A(即 B2G)、C2A(即 C2G)、O2O 等。 海淘 通过互联网检索海外商品信息，并通过电子订购单发出购物请求，然后填上私人信用卡号码，由海外购物网站通过国际快递发货，或是由转运公司代收货物再转寄回国。海淘，一般付款方式是款到发货(在线信用卡付款、PayPal 账户付款)。 Rebate Site 返利站 返利站采用购物返现金的形式聚集大量网络购物会员，会员从这里去淘宝网和各大网上商城购物，订单完成后(无退货)，返利站作为该商城的合作伙伴，可从该商城得到一定比例的销售佣金，返利站再把佣金的50%—— 100%的返还给会员，返利站还推出团购返利，涵盖几十家知名团购网站，团购后再返利！ 这就是现金返利的来源，一点也不影响会员本来能享受到的任何优惠活动。 POP 为向网站以外的用户提供服务的开放平台，例如京东、苏宁、亚马逊都推出开放平台业务。未来电商在这块的竞争也日趋激烈。 微商 基于微信生态的社会化分销模式，是企业或者个人基于社会化媒体开店的新型电商 ，从模式上来说主要分为两种：基于微信公众号的微商成为 B2C 微商，基于朋友圈开店的成 为C2C 微商。微商和淘宝一样，有天猫平台(B2C 微商)也有淘宝集市(C2C 微商)。所不同的是 微商基于微信“连接一切”的能力，实现商品的社交分享、熟人推荐与朋友圈展示。从微商来流程来说，微商主要由基础完善的交易平台微盟旺铺、营销插件、分销体系以及个人端分享推广微客四个流程部分组成。 微店 全球第一个云销售电子商务，是零成本开设的巨型商城，是计算机云技术和传统电子商务相结合的创新模式。微店并不是利用手机开网店，这个“微”是指无须资金、无须成本、无须处理货源，无须处理物流和客服，就可以赚取推广佣金。微店的模式之所以受到追捧，是因为它颠覆了传统网商既要找货源，又要做推广的高门槛要求，很好地解决了货源与推广的分工问题。这是互联网分工进一步细化的体现。 UGC 互联网术语，全称为 User Generated Content，也就是用户生成内容的意思。UGC 的概念最早起源于互联网领域，即用户将自己 原创的内容通过互联网平台进行展示或者提供给其他用户。UGC 是伴随着以提倡个性化为主 要特点的 Web2.0 概念兴起的。 PGC 全称：Professional Generated Content），互联网术语。指专业生产内容（视频网站）、专家生产内容（微博）。用来泛 指内容个性化、视角多元化、传播民主化、社会关系虚拟化。 OEM 也称为定点生产，俗称代工（生产），基本含义为品牌生产者不直接生产产品，而是 利用自己掌握的关键的核心技术负责设计和开发新产品，控制销售渠道，具体的加工任务 通过合同订购的方式委托同类产品的其他厂家生产。之后将所订产品低价买断，并直接贴上自己的品牌商标。 ODM 某“原始设计制造商”设计出某产品后，在某些情况下可能会被另外一些企业看中， 要求配上后者的品牌名称来进行生产，或者稍微修改一下设计来生产。这样可以使其他厂商减少自己研制的时间。承接设计制造业务的制造商被称为 ODM 厂商，其生产出来的产品就是 ODM 产品。 鼠标+水泥（Clicks and Mortar） 又称为“砖块+鼠标”（Bricks and Clicks），是指传统商业模式（主要运用直接的面对面的方式与顾客发生联系）与互联网商业模式（主要通过网站、电子邮件、FTP 以及其他互联网技术手段与顾客发生联系）的联姻。它是一种将先进的互联网技术与传统优势资源相结合，利用先进的信息技术提高传统 业务的效率和竞争力，实现真正的商业利润的电子商务运作模式。鼠标+水泥是一个传统企 业电子化和互联网公司实体化的趋同过程，是电子商务发展的趋同方向。 “互联网+” 互联网+”是创新 2.0 下的互联网发展新形态、新业态，即充分发挥互联网在 生产要素配置中的优化和集成作用，将互联网的创新成果深度融合于经济社会各领域之中，提高实体经济的创新力和生产力，形成更广泛的以互联网为基础设施和实现工具的经济发展新形态。“互联网+”，是知识社会创新 2.0 推动下的互联网形态演进。新一代信息技术发展催生了创新 2.0，而创新 2.0 又反过来作用与新一代信息技术形态的形成与发展，重塑了物联网、云计算、社会计算、大数据等新一代信息技术的新形态，并进一步推动知识社会以用户创新、开放创新、大众创新、协同创新为特点的创新 2.0，改变了我们的生产、 工作、生活方式，也引领了创新驱动发展的“新常态”。 物联网 把所有物品通过信息传感设备与互联网连接起来，进行信息交换，即“物物相息”，以实现智能化识别和管理。 网络媒体、广告、营销篇 网络媒体 Portal 门户网站 是指通向某类综合性互联网信息资源并提供有关信息服务的应用系统。门户网站最初提供搜索服务、目录服务，后来由于市场竞争日益激烈，门户网站不得不快速地拓展各种新的业务类型，希望通过门类众多的业务来吸引和留住互联网用户，以至于目前门户网站的业务包罗万象，成为网络世界的“百货商场”或“网络超市”。在中国，综合门户网站包含 新浪，网易，搜狐，腾迅。 vertical portal 垂直门户 是相对新浪这样的传统门户网站而言， 传统门户网站的内容广泛而全面，覆盖各行各业，“垂直门户”则专注于某一领域（或地 域）如 IT、娱乐、体育、汽车，力求成为关心某一领域（或地域）内容的人上网的第一站 。 Dictionary 网址导航站 网址导航就是一个集合较多网址，并按照一定条件进行分类的一种网址站。网址导航方便网友们快速找到自己需要的网站，而不用去记住各类网站的网址，就可以直接进到所需的网站。现在的网址导航一般还自身提供常用查询工具，以及邮箱登陆、搜索引擎入口，有的还有热点新闻等功能。网址导航从诞生的那一刻起，就凭借其简单的模式和便利的服务 以及好的用户体验深得民心，不过也注定其发展与竞争都将成为互联网网站中竞争最激烈的类别，发展至今，更是成为互联网大佬们最大的竞争对象。 Search Engine 搜索引擎 可被搜索的网站及其内容数据库。搜索引擎一般通过搜索用户指定的关键词来帮助用户找 到他们所需要的信息。搜索引擎会提供一个网页的索引，供用户输入关键词或相关内容来 查询信息。创建索引时可以使用专门的资源列表，或者使用称为“机器人”的程序来自动 访问站点和网页 HTML 代码中的索引文本。 Social Media 社交媒体 也称为社会化媒体、社会性媒体，指允许人们撰写、分享、评价、讨论、相互沟通的网站和技术。所谓社交媒体应该是大批网民自发贡献，提取，创造新闻咨询，然后传播的过程 。 Streaming Media 数据流媒体 一种以稳定、持续的数据流来传输的技术。随着互联网的发展，数据流媒体已变得越来越重要。大多数用户无法足够快速地下载大型多媒体文件，利用数据流，用户在该文件完成下载之前即可开始在网上观赏或收听。 自媒体(外文名：We Media) 又称“公民媒体”或“个人媒体”，是指私人化、平民化、普泛化、自主化的传播 者,以现代化、电子化的手段，向不特定的大多数或者特定的单个人传递规范性及非规范性 信息的新媒体的总称。自媒体平台包括:博客、微博、微信、百度官方贴吧、论坛/BBS 等网络社区。 TMT 数字新媒体 或叫 TMT（Technology，Media，Telecom）产业。TMT 是电信、媒体和科 技三个英文单词的缩写的第一个字头，整合在一起，实际是未来电信、媒体科技(互联网) ，包括信息技术这样一个融合趋势所产生的大的背景，这就是 TMT 产业。 网络广告 Ad Network 在线广告网络 Ad Network 即“广告网络”。在广告业内，这是一个较为广泛的概念。是一种介于想出售广告 流量资源的网站与想在网站上刊登广告的广告主之间的平台。 Ad Server 广告管理系统 指为媒体提供的一套综合性广告发布系统，可以帮助媒体管理、优化其广告流量，简化广告管理及投放流程，提供全面的广告投放报告，制定高效的投放解决方案，提升广告价值。Display AD 展示广告网站广告的主要形式，通常在文本的基础上再加上图像型信息，其形式如企业标识、相关产品图片，企业所在位置的简易电子地图或其他相关信息。 品牌广告 以树立产品品牌形象，提高品牌的市场占有率为直接目的，突出传播品牌在消费者心目中确定的位置的一种方法。 效果广告 基于效果为基础的广告系统中，广告主只需要为可衡量的结果付费。 Banner 横幅广告 一种常见的网络广告形式，常表现为 GIF、JPG 等格式建立的图像文件，定位在网页中，大多用来表现广告内容，同时还可实用 Java 等语言使其产生交互性，用 Shockwave 等插件工具增强表现力。 Buttons 按钮 网站上一小块形似按钮的可点击区域，往往采用动画形式，并连接到广告主的网站。 Pop-up Ad 弹出式广告 在用户浏览网页或打开新网页时弹出的短暂的广告。在已经显示内容的页面上出现的具有独立广告内容的窗口，一般是网页内容下载完成弹出式广告也随之出现，因而对浏览网页内容产生直接影响。 Skyscraper 擎天柱广告 一种又高又窄的网络广告格式，通常位于网页左右两侧的狭窄空间。 Rich Media (富媒体) 这种应用采取了所有适合的最先进技术，以最好的传达广告主的信息， 甚至与用户进行互动，如视频、flash 广告等。 Keyword 关键字广告 用户输入到搜索引擎中用于搜索匹配和相关结果的单词或词语。 竞价排名 一种按效果付费的网络推广方式。基本特点是按点击付费，推广信息出现在搜索结果中（一般是靠前的位置），如果没有被用户点击，则不收取推广费。竞价就是拍卖 ，关键词出价是影响排名的一个重要因素。 AdWords Google 的关键词竞价广告。 Adsens Google AdSense 是一种获取收入的快速简便的方法，适合于各种规模的网站发布商。它可以在网站的内容 网页上展示相关性较高的 Google 广告，并且这些广告不会过分夸张醒目。 百度凤巢 百度的关键词竞价广告。 淘宝直通车 淘宝的关键词竞价广告。 钻石展位 是淘宝网图片类广告位竞价投放平台，是为淘宝卖家提供的一种营销工具。钻石展位依靠图片创意吸引买家点击，获取巨大流量。 积分墙广告 在一个应用内展示各种积分任务（下载安装推荐的优质应用、注册、填表等 ），以供用户完成任务获得积分的页面。是除“广告条”、“插屏广告”外，第三方移动广告平台提供给应用开发者的另一新型移动广告盈利模式。 Ad Exchange 广告交易平台 Ad Exchange 是针对每次广告展示，以受众为单位进行实时竞价的互联网流量交换市场。能帮助广告联盟、代理机构和第三方技术提供商通过实时竞价的方式购买众多互联网站点的广告资源。 DSP （Demand-Side Platform） 需求方平台 DSP 需求方平台是一个综合性管理平台，在这个平台上，广告主可以通过同一个界面管理多 个数字广告和数据交换的账户。利用 DSP，广告主可以在广告交易平台（Ad Exchange）对在线广告进行实时竞价（RTB Real-Time Bidding），高效管理广告定价，利用 DSP 也可以根据目标受众数据分析进行理性定价，就 像付费搜索的操作原理一样，在用户优化的基础上使用 DSP 设置如 CPC 和 CPA 这些关键性能指 标，从而达到理性定价的目 标。 DMP （Data-Management Platform） 数据管理平台 DMP 数据管理平台，是把分散的第一、第三方数据进行整合纳入统一的技术平台，并对这些数据进行标准化和细分，让用户可以把这些细分结果推向现有的互动营销环境里。 RTB （Real-Time Bidding） 实时竞价 RTB 实时竞价，是一种利用第三方技术在数以百万计的网站上针对每一个用户展示行为进行 评估以及出价的竞价技术。与大量购买投放频次不同，实时竞价规避了无效的受众到达， 只针对有意义的用户进行购买。它的核心是 DSP 平台（需求方平台）。 RTB 对于媒体来说，可以带来更多的广告销量、实现销售过程自动化及减低各项费用的支出 。而对于广告商和代理公司来说，最直接的好处就是提高了效果与投资回报率。 Media Plan 媒介计划 包含了传播目标，同时描述如何通过广告途径来实现这些目标的概述。它由媒介策划人员提供。媒介计划一般包括市场营销、广告投放以及媒介目标，相关的媒介策略通常在其基础上制定。 Campaign 广告活动 广告活动指在某一特定市场上为实现某一重大目标所集中进行的大规模的广告活动，是广 告决战思想的一种体现，是企业之间进行市场竞争的策略之一。 Landing Page 登陆页面 当用户点击了广告之后所访问的广告主网页。通常登陆页面会要求用户注册以便获得服务或购买产品，也称为点进 URL 或目标 URL。 Positioning 定位 投放广告的位置，可以指定广告出现的位置。 Targeted 针对性广告 通过分析人口特征、网络行为、消费习惯等制定的面向特定受众市场的广告 。 植入式广告 在电影或电视剧或者其它场景插入相关的广告。如变形金刚，非诚勿扰等。eCPM（effective cost per mille）指的就是每一千次展示可以获得的广告收入，展示的单位可以是网页，广告单元， 甚至是单个广告（在 AdSense “高级报告”的“数据展示依据”下拉框中可以选择）。默认情况下，eCPM 指的都是千次网页展示（Pageview）收入。eCPM 只是用来反映网站盈利能力的参数，不代表收入。 CPD （Cost Per Day） 每日成本，是按天收费的一种模式，是广告合作的一种常见方式。 CPM （Cost Per Mille 或者 Cost Per Thousand; Cost Per Impressions） 千人成本，指由某一媒介或媒介广告排期表所送达 1000 人所需的成本。其原始英文为 Cost Per Mille，简称 CPM。其计算公式为：千人成本=（广告费用/到达人数）×1000。目前，CPM已经作为&quot;按广告每千次被展现收费&quot;的广告模式,成为网络广告的基本术语。 CPC （Cost Per Click; Cost Per Thousand Click-Through ） 点击成本，以每点击一次计费。在这种模式下广告主仅为用户点击广告的行为付费，而不再为广告的显示次数付费。 CPA （Cost Per Action） 行动成本，每次行动的费用。即根据每个访问者对网络广告所采取的行动收费的定价模式，对于用户行为的定义，包括形成一次交易、获得一个注册用户、或者对网络广告的一次点击等。 CPE （Cost Per Engagement） 每参与成本，旨在评估用户与品牌之间参与程度的价值。多应用于社交媒体，例如链接点击、喜欢、转发和“@回复”等等。另外 CPE 也指用户浏览过广告后，在一定时间内（如一周）与品牌进行的互动。 CPS (Cost Per Sales =CPP Cost Per Purchase) 每购买成本，以实际销售产品数量来换算广告投放金额。广告主为规避风险，只有在用户点击广告并进行在线交易后，才支付广告费用。 网络营销推广 网络营销 以现代营销理论为基础，借助网络、通信和数字媒体技术实现营销目标的商务活动。企业网络营销包含企业网络推广和电子商务两大要素，网络推广就是利用互联网进行宣传推广活动，电子商务指的是利用简单、快捷、低成本的电子通讯方式，买卖双方无需谋面地进行各种商贸活动。 网络推广 通过互联网把产品或服务推广出去，使产品或服务增加曝光率，尽可能让更多的人知道。常见网络推广渠道有分类信息、问答、博客、论坛、视频网站等。 SEM 是“Search Engine Marketing”的缩写，意为“搜索引擎营销”。包含关键字广告和 SEO两大主要手段。 SEO 搜索引擎优化。搜索引擎优化（Search Engine Optimization，简称“SEO”），泛指为了提升网站在搜索引擎中的表现而采取的各种符合 必要的规则的手段和由此开展的各种工作。 EDM 内部邮件群发，第三方平台，数据库整合营销等方式，数据库营销。 社会化媒体营销 基于微博、微信、QQ、sns、bbs、博客等社交媒体来进行推销并创造业务机会和销售的行为。其最大的优势在于能够帮助企业推销，从而增加流量并建立新的业务合作关系。 口碑营销 企业在调查市场需求的情况下，为消费者提供需要的产品和服务，同时制定一定的口碑推广计划，让消费者自动传播公司产品和服务的良好评价，从而让人们通过口碑 了解产品、树立品牌、加强市场认知度，最终达到企业销售产品和提供服务的目的。 病毒式营销 是指通过用户的社会人际网络，使信息像病毒一样传播和扩散，利用快速复制 的方式传向数以千计、数以百万计的受众。也就是说，通过提供有价值的产品或服务，“ 让大家告诉大家”，通过别人为你宣传，实现“营销杠杆”的作用。 SMO （社交媒体优化）通过社会化媒体、在线组织及社区网站获得公共传播的一整套方法。SMO的方法包括添加 RSS 订阅、顶上去、博客写作及非合作形式的第三方社区功能（如：Flickr图片幻灯片、YouTube 的视频分享）。 ASO (App Store Optimization)就是提升你 APP 在各类 APP 电子市场排行榜和搜索结果排名的过程。类似移动 APP 的 SEO 优化。 饥饿营销 商品提供者有意调低产量，以期达到调控供求关系、制造供不应求“假象”、 维持商品较高售价和利润率，也达到维护品牌形象、提高产品附加值的目的。“饥饿营销 ”是把双刃剑，苹果公司的“可控泄漏”战略为其赢得了全球市场，而小米手机却也因过 分的“饥饿”让用户失去了耐心。 Interactive Marketing 互动营销通过互动营销能够向潜在客户进行推销并记住他们的行为和话语，从而使潜在客户知道广告主已了解其之前提供的信息。 SEO 相关 Meta 关键词密度 面包屑导航 内链 外链 反向链接 友情链接 锚文本 Home Page 主页 网站的第一张网页，是导航的起点。访问者可通过主页链接到站点内的其他页面。 SERP 搜索结果页面 SPAM 互联网上到处散布垃圾广告消息的现象。在搜索引擎上的 Spam 通常也称为作弊。搜索引擎营销中所说的 SPAM 是专门针对那些欺骗搜索引擎的信息。搜索引擎垃圾技术是利用不道德的技巧去提高自己搜索引擎上的排名。不诚实的网站管理员就是利用这样的手段去欺骗搜索引擎从而获得较高的排名。 PageRank PR 值 PR 值是网页的级别技术。取自 Google 的创始人 Larry Page，它是 Google 排名运算法则(排名公式)的一部分，用来标识网页的等级/重要性。级别 从 1 到 10 级，10 级为满分。PR值越高说明该网页越受欢迎(越重要)。 Alexa Alexa.com 是专门发布网站世界排名的网站，网站排名有两种：综合排名和分类排名。 沙盒 Google 反击垃圾网站的重要措施，出现在 2004 年，也就是举世瞩目的 Google 佛罗里达风暴和奥斯丁风暴之后的半年。有了沙盒，Google 仍然象过去一样迅速收录网站，从互联网上从新的网站里努力获取新鲜的信息，但是不再 象以前那样信任这些新网站。所有收录的网站都要经过“适用期”或者 “观察期”。经过时间的考验，如果这些网站能顺利通过 Google 多次的反“泛滥”过滤器(spam filter)的考验，最终这些网站就被放回搜索的“大海”之中，参与正常的排名竞赛之中。 这个过程少则两、三个月，长则要一年。新网站可以采取一些积极 的措施，争取早日走出沙盒。 技术及其他篇 技术 域名 由一串用点分隔的名字组成的 Internet 上某一台计算机或计算机组的名称，用于在数据传输时标识计算机的电子方位。一个域名的目的是便于记忆和沟通的一组服务器的地 址（网站，电子邮件，FTP 等）。 服务器 是提供计算服务的设备。由于服务器需要响应服务请求，并进行处理，因此一般来说服务器应具备承担服务并且保障服务的能力。服务器的构成包括处理器、硬盘、内存 、系统总线等，和通用的计算机架构类似，但是由于需要提供高可靠的服务，因此在处理能力、稳定性、可靠性、安全性、可扩展性、可管理性等方面要求较高。在网络环境下， 根据服务器提供的服务类型不同，分为文件服务器，数据库服务器，应用程序服务器，WEB 服务器等。 虚拟主机 在网络服务器上分出一定的磁盘空间供用户放置站点、应用组件等，提供必要的站点功能、数据存放和传输功能。也叫“网站空间”，就是把一台运行在互联网上的服 务器划分成多个“虚拟”的服务器，每一个虚拟主机都具有独立的域名和完整的 Internet 服务器（支持WWW、FTP、E-mail 等）功能。 DNS （Domain Name System，域名系统），因特网上作为域名和 IP 地址相互映射的一个分布式数据库，能够使 用户更方便的访问互联网，而不用去记住能够被机器直接读取的 IP 数串。通过主机名，最 终得到该主机名对应的 IP 地址的过程叫做域名解析（或主机名解析）。 VPN （Virtual Private Network）VPN 网关通过对数据包的加密和数据包目标地址的转换实现远程访问。 FTP 文件传输协议。是一个用于在两台装有不同操作系统的机器中传输计算机文件的软件标准。它属于网络协议组的应用层。 SSL “Secure Socket Layer”，意为“安全套接层”，是一种加密通信技术，用于保证数据在网络上传输的安全 性，避免被截取、窃听和篡改。目前，SSL 被广泛地应用于 Web 浏览器与服务器之间的身份 认证和数据加密。 Load balancing（负载平衡） 在路由选择中，路由器在它所有的到目的端地址均是同样距离的 网络端口上分配业务量的能力。一个好的负载平衡算法使用线路速度和可靠性信息两者。负载平衡增加网段的使用率，从而增加有效的网络带宽。 HTTP 超文本传输协议，一种控制网络信息传输的协议，通常出现在地址栏或统一资源定位符的前面。 HTML 超文本标记语言，设计网页时实用的标准互联网编程语言。它使信息能够呈现所包含的指向其他相关文件的链接。 URL 统一资源定位符，指独一无二的互联网地址。 绝对URL 是指 Internet 上资源的完整地址，其形式通常如下：协议://主机名[/[路径/]资源 文件名] 相对 url 相对 URL 是指 Internet 上资源相对于当前页面的地址，它包含从当前页面指向目标页面的路径。当使用相对 URL 时，可以使用与 DOS 文件目录类似的特殊符号：点（.）和双点（…）， 分别表示当前目录和上一级目录。相对 URL 本身并不能唯一资源，但浏览器会根据当前页面的绝对 URL 正确理解相对 URL。 404 错误 HTTP 404 错误意味着链接指向的网页不存在，即原始网页的URL失效。 Cookie 一种由网站发出并存储在用户的硬盘内的文本文件，网站用它来储存/检索每个访问者的信息。Cookie 存储信息的范围从每个访问者唯一的单独编号一直到有关个人喜好的详细信息和用户提供的人口统计信息。一旦用户收到一个 Cookie，其中将包含该用户所做出的每个网页请求信息。这就使网站的日志文件能够跟踪每个访问者访问网站的活动。Cookie信息还可用于个性化提供给用户的内容，包括广告—— 某些广告滚动软件可以识别出用户刚刚看到过哪一个广告，然后将另一个不同的广告滚动 到下一个网页视图中送出。 Session 在计算机中，尤其是在网络应用中，称为“会话控制”。具体到 Web 中的 Session 指的就是用户在浏览某个网站时，从进入网站到关闭这个网站所经过的这段时间，也就是用户浏览这个网站所花费的时间。因此从上述的定义中我们可以看到，Session 实际上是一个 特定的时间概念。 CMS 内容管理系统。它具有许多基于模板的优秀设计，可以加快网站开发的速度和减少开发的成本。CMS 的功能并不只限于文本处理，它也可以处理图片、Flash 动画、声像流、图像甚至电子邮件档案。 开放平台 （Open Platform）在软件业和网络中，开放平台是指软件系统通过公开其应用程序编程接口（API ）或函数（function)来使外部的程序可以增加该软件系统的功能或使用该软件系统的资源 ，而不需要更改该软件系统的源代码。 API Application Programming Interface,应用程序编程接口）是一些预先定义的函数，目的是提供应用程序与开发人员基于某软件或硬件得以访问一组例程的能力，而又无需访问源码，或理解内部工作机制的细节。 SDK （全称：Software Development Kit，软件开发工具包）一般都是一些软件工程师为特定的软件包、软件框架、硬件平台、 操作系统等建立应用软件时的开发工具的集合。软件开发工具包广义上指辅助开发某一类 软件的相关文档、范例和工具的集合。 Native app 而 App 因为位于平台层上方，向下访问和兼容的能力会比较好一些，可以支持在线或离线，消息推送或本地资源访问，摄像拨号功能的调取。但是由于设备碎片化，App 的开发成本要高很多，维持多个版本的更新升级比较麻烦，用户的安装门槛也比较高。但是比较乐观的是，App store 培养了一种比较好的用户付费模式，所以在 Apple 的生态圈里，开发者的盈利模式是一种明朗状态，其他 market 也在往这条路上靠拢。 Web app Web 无需安装，对设备碎片化的适应能力优于 App，它只需要通过 XHTML、CSS 和 JavaScript 就可以在任意移动浏览器中执行。随着 iPhone 带来的 WebKit 浏览体验升级，使得专为 iPhone 等有 WebKit 浏览内核的移动设备开发的 Web 应用，也有了如 App 一般流畅的用户体验。 Html5 HTML5 提供了一些新的元素和属性，例如（网站导航块）和。这种标签将有利于搜索引擎的索引整理，同时更好的帮助小屏幕装置和视障人士使用，除此之外，还为其他浏览要素提供了新的功能。 大数据 所涉及的资料量规模巨大到无法透过目前主流软件工具，在合理时间内达到撷取 、管理、处理、并整理成为帮助企业经营决策更积极目的的资讯。我国对大数据的搜集利 用主要体现在电子商务领域：电商通过物流掌握用户数据，进行线上线下联动；通过分析购买商品的数据，精确进行商品推荐等。 数据挖掘 一般是指从大量的数据中通过算法搜索隐藏于其中信息的过程。数据挖掘通常与 计算机科学有关，并通过统计、在线分析处理、情报检索、机器学习、专家系统（依靠过去的经验法则）和模式识别等诸多方法来实现上述目标。 机器学习 (Machine Learning, ML)是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多 门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新 组织已有的知识结构使之不断改善自身的性能。 它是人工智能的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域 ，它主要使用归纳、综合而不是演绎。 云存储 是在云计算(cloud computing)概念上延伸和发展出来的一个新的概念，是指通过集群应用、网格技术或分布式文件系统等功能，将网络中大量各种不同类型的存储设备通过应用软件集合起来协同工作，共同对外提供数据存储和业务访问功能的一个系统。当云计算系统运算和处理的核心是大量数据的存储和管理时，云计算系统中就需要配置大量的存储设备，那么云计算系统 就转变成为一个云存储系统，所以云存储是一个以数据存储和管理为核心的云计算系统。 NFC （Near Field Communication，NFC），又称近距离无线通信，是一种短距离的高频无线通信技术，允许电子设备之间进行非接触式点对点数据传输（在十厘米内）交换数据。 RFID 射频识别即 RFID（Radio Frequency IDentification）技术，又称电子标签、无线射频识别，是一种通信技术，可通过无线电 讯号识别特定目标并读写相关数据，而无需识别系统与特定目标之间建立机械或光学接触 。 VR Virtual Reality 即虚拟现实（简称 VR），是由美国 VPL 公司创建人拉尼尔 Jaron Lanier，在 20 世纪 80 年代初提出的。其具体内涵是：综合利用计算机图形系统和各种现实及控制等接口设备，在计算机上生成的，可交互的三维环境中提供沉浸感觉的技术。其中，计算机生成的，可交互的三维环境成为虚拟环境，即 Virtual Environment（简称 VE），虚拟现实技术实现的载体是虚拟现实仿真平台，即 Virtual Reality Platform（简称 VRP）。 其他 SWOT 分析 用于对企业的市场地位进行评估的体系，包括优势、劣势、机遇和威胁。优势和劣势都是企业可以改变的内部因素。机遇和威胁则是企业无法控制但是又必须制定应对 措施的外部因素。 Prototype 产品原型 可以概括的说是整个产品面市之前的一个框架设计。以网站注册作为例子,整个前期的交互设计流程图之后,就是原形开发的设计阶段,简单的来说是将页面的模块、元素、人机交互的形式，利用线框描述的方法，将产品脱离皮肤状态下更加具体跟生动的进行表达。 Flow Chart 流程图 是流经一个系统的信息流、观点流或部件流的图形代表，使用图形表示算法的思路。 MRD 市场需求文档 是产品项目由“准备”阶段进入到“实施”阶段的第一文档，其作用就是 “对年度产品中规划的某个产品进行市场层面的说明”。 BRD 商业需求文档 是基于商业目标或价值所描述的产品需求内容文档（报告）。其核心的用途就是用于产品在投入研发之前，由企业高层作为决策评估的重要依据。其内容涉及市场分析，销售策略，盈利预测等，通常是供决策层们讨论的演示文档，一般比较短小精炼，没有产品细节。 PRD 产品需求文档 是产品项目由“概念化”阶段进入到“图纸化”阶段的最主要的一个文档，其作用就是“对MRD 中的内容进行指标化和技术化”。 AB 测试 本质上是个分离式组间实验，A/B 测试的目的在于通过科学的实验设计、采样样本代表性、流量分割与小流量测试等方式来获得具有代表性的实验结论，并确信该结论在推广 到全部流量可信。 灰度发布 是指在黑与白之间，能够平滑过渡的一种发布方式。AB test 就是一种灰度发布方式，让一部分用户继续用 A，一部分用户开始用 B，如果用户对 B 没 有什么反对意见，那么逐步扩大范围，把所有用户都迁移到 B 上面来。灰度发布可以保证整 体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。 快速检查清单 (Check list) 为了达到优化的目标，整理了一个简易的 checklist，方便在走查时对架构、布局、内容、行为四个方面对照检查。 FAQ 是英文 Frequently Asked Questions 的缩写，中文意思就是“经常问到的问题”，或者更通俗地叫做“常见问题解答 ”。 MVP（Minimum Viable Product – 最简化可实行产品） 一种产品理论，它的重点就是制作的成本要极低，但是却能展示最 终产品的主要特色。作用就是让你拿来接触客户，从很早就根据客户的回馈来改进你的产品。 职位、职业或部门相关 CEO 首席执行官 COO 首席运营官 CMO 首席市场官 CFO 首席财务官 VP 副总裁 PM 产品经理、项目经理 RD 研发 OP 运营 UI 设计 UED 用户体验 BD 商务拓展 AE 客户执行 PR 公关 HR 人力资源 HRD 人力资源总监 KA 大客户部门 Soho 即 Small Office Home Office，家居办公，大多指那些专门的自由职业者。 Geek 极客是一群以创新、技术和时尚为生命意义的人，这群人不分性别，不分年龄，共同的战斗在新经济、尖端技术和世界时尚风潮的前线，共同为现代的电子化社会文化做出自己的贡献。 淘宝客 是指基于阿里妈妈平台帮助卖家推广商品并获取佣金的人。淘宝客推广是一种按成 交计费的推广模式，淘宝客只要从淘宝客推广专区获取商品代码，布置到您要推广的地方，等买家（包括您自己）经过您的推广(链接、个人网站、博客或者社区发的帖子)进入淘 宝卖家店铺完成购买后，就可得到由卖家支付的佣金。 淘拍档 即淘宝网优质电子商务服务提供商，经过淘宝网从淘宝服务商中严格审核，他们被授予“淘拍档”称号，拥有“淘拍档”授牌。常用缩写 TP。 Aidma 模型 该法则于 1898 年由美国广告学家 E.S.刘易斯最先提出。A、I、D、M、A 的含义分别为：A(At tention)引起注意；I (Interest)产生兴趣；D(Desire)培养欲望；M(Memory)形成记忆；A(Action)促成行动。所谓 AIDMA 法则，是指在消费者从看到广告，到发生购物行为之间，动态式地引导其心理过 程，并将其顺序模式化的一种法则。 其过程是首先消费者，注意到(attention)该广告，其次感到兴趣(interest)而阅读下去，再者产生想买来试一试的欲望(desire)。然后记住 (memory)该广告的内容最后产生购买行为(action)。这种广告发生功效而引导消费者产生 的心理变化，就称为 AIDMA 法则。 长尾理论 网络时代兴起的一种新理论，由于成本和效率的因素，当商品储存流通展示的场地和渠道 足够宽广，商品生产成本急剧下降以至于个人都可以进行生产，并且商品的销售成本急剧 降低时，几乎任何以前看似需求极低的产品，只要有卖，都会有人买。这些需求和销量不高的产品所占据的共同市场份额，可以和主流产品的市场份额相比，甚至更大。 六度空间理论 又名“六度分割理论”、“小世界理论”等，起源于一个数学领域的猜想。该理论的核心是：你和任何一个陌生人之间所间隔的人不会超过六个，也就是说，最多通过六个人你就能够认识任何一个陌生人。 七次印象理论 广告学的一个理论，含义是：一个广告通常需要被目标受众反复看 7 次以后才能形成深刻稳定的印象（被人记住）。 该理论的主要应用场景：各类品牌广告。极端案例：著名的恒源祥恶搞广告事件。 八秒法则 网络营销领域的一个重要法则，主要原理为：着陆页的打开速度对访客的访问意愿具有较大的影响，如果能在 3 秒内打开，则访客的体验是良好的；如果超过 5 秒，则访客将产生焦 虑和烦躁的情绪；而 8 秒是多数访客忍耐的临界点，如果着陆页在 8 秒内没有完全打开，多数访客将直接关闭该网页（从而造成访客流失）。 避风港原则 避风港原则是互联网著作权领域的一个司法原则，最早来自美国 1998 年制定的《数字千年版权法案》（DMCA 法案）。它的含义是：发生著作权侵权案件时，如果 ISP（网络服务提供商）只提供空间服务，并不制作网页内容，那么当 ISP 被告知侵权时，有删除相关信息的义 务，否则就被视为侵权。如果侵权内容既不在 ISP 的服务器上存储，又没有被告知哪些内容应该删除，则 ISP 不承担侵权责任。后来避风港原则也被应用在搜索引擎、网络存储、在线图书馆等方面。避风港原则包括两 部分，“通知+移除”（notice－take down procedure）。由于网络中介服务商没有能力进行事先内容审查，一般事先对侵权信息的存在不知情。所以，采取“通知+移除”规则，是对网络中介服务商间接侵权责任的限制。 作者：Acelit 来源：CSDN 原文：https://blog.csdn.net/acelit/article/details/74357277 版权声明：本文为博主原创文章，转载请附上博文链接！","categories":[{"name":"English","slug":"English","permalink":"https://bobit.github.io/categories/English/"}],"tags":[{"name":"英语","slug":"英语","permalink":"https://bobit.github.io/tags/英语/"},{"name":"互联网","slug":"互联网","permalink":"https://bobit.github.io/tags/互联网/"},{"name":"转载","slug":"转载","permalink":"https://bobit.github.io/tags/转载/"}]},{"title":"MongoDB 学习总结","slug":"分布式/MongoDB 学习总结","date":"2017-11-13T04:19:17.000Z","updated":"2018-12-21T12:55:19.535Z","comments":true,"path":"posts/33388948.html","link":"","permalink":"https://bobit.github.io/posts/33388948.html","excerpt":"","text":"MongoDB GUI（ Robo 3T） Shell使用及操作 Robo 3T 下载及使用 之前叫 Robomongo，后面被收购了，改名 Robo 3T 。 下载链接：https://robomongo.org/download 安装版：安装步骤省略，下一步下一步… 解压版：解压即可。 图形界面，连接默认，取个名字就行。 连接成功，可以愉快的使用了，不用总是敲命令了，简洁方便，多种显示。 软件右边可以切换显示样式。 Robo 3T Shell 操作 1、批量插入（默认是不支批量操作，只能用for循环。） 2、$type 操作符，基于BSON类型来检索集合中匹配的数据类型，并返回结果。 先增加一些数据，然后查询出来 （同一界面，需要选中执行的一行，不然会一直执行第一个命令。） 3、Limit与Skip的用法 查询文档中两条记录 第一个 {} 放 where 条件，为空表示返回集合中所有文档。 第二个 {} 指定那些列显示和不显示 （0表示不显示 1表示显示)。 查询显示第2、3条文档数据 skip()方法默认参数为 0 。 skip 和 limit 结合就能实现分页。 排序 sort() 方法 索引 ensureIndex() 方法 多个字段索引：db.student.ensureIndex({“name”:1,“hobby”:-1}) 聚合 aggregate() 这里只操作一种方法，分组并统计，其它的可以查看相关用法和文档。 总结：常用的一些基本用法就这些，高级用法可以慢慢再研究。 mongodb insert()和save()的相同点和区别 区别 ​ 若新增的数据中存在主键 ，insert() 会提示错误，而save() 则更改原来的内容为新内容。 ​ 如： ​ 已存在数据： {_id : 1, &quot; name &quot; : &quot; n1 &quot; }，再次进行插入操作时， ​ insert({_id : 1, &quot; name &quot; : &quot; n2 &quot; }) 会报主键重复的错误提示 ​ save({ _id : 1, &quot; name &quot; : &quot; n2 &quot; }) 会把 n1 修改为 n2 。 相同点： ​ 若新增的数据中没有主键时，会增加一条记录。 ​ 已存在数据： { _id : 1, &quot; name &quot; : &quot; n1 &quot; }，再次进行插入操作时， ​ insert({ &quot; name &quot; : &quot; n2 &quot; }) 插入的数据因为没有主键，所以会增加一条数据 ​ save({ &quot; name &quot; : &quot; n2 &quot; }) 增加一条数据。 附录 ​ $gt -------- greater than &gt; ​ $gte --------- gt equal &gt;= ​ $lt -------- less than &lt; ​ $lte --------- lt equal &lt;= ​ $ne ----------- not equal != ​ $eq -------- equal =","categories":[{"name":"分布式","slug":"分布式","permalink":"https://bobit.github.io/categories/分布式/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://bobit.github.io/tags/MongoDB/"},{"name":"Robo 3T","slug":"Robo-3T","permalink":"https://bobit.github.io/tags/Robo-3T/"}]},{"title":"MySQL 官方 Docker 镜像的使用","slug":"微服务/Docker使用MySQL","date":"2017-11-12T14:20:17.000Z","updated":"2018-12-21T12:57:32.849Z","comments":true,"path":"posts/ac33bd8a.html","link":"","permalink":"https://bobit.github.io/posts/ac33bd8a.html","excerpt":"","text":"获取镜像 首先是pull image，这里我拉取的是5.6.35: docker pull mysql:5.6.35 安全使用 docker run --name mysql -p 6666:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.6.35 试着用客户端连接，成功了，查询mysql.user表发现允许从任何地方用root访问，这太不安全了！ 连接到bash: docker exec -it mysql bash 运行mysql，竟然有！ 下面修改为安全使用： 就是基本的操作，收回root权限，建库，开用户……等等 数据库文件在哪？还有，字符集不是UTF-8？？？ 启动容器 docker run --name mysql -p 6666:3306 -v /home/bobit/docker/mysql/5.6.35/data:/var/lib/mysql -v /home/bobit/docker/mysql/5.6.35/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.6.35 docker run --name mysql -p 6666:3306 -v /home/bobit/docker/mysql/5.6.35/data:/var/lib/mysql -v /home/bobit/docker/mysql/5.6.35/conf:/etc/mysql/conf.d -d mysql:5.6.35 进入容器 docker exec -it mysql bash 登录MYSQL（有ROOT权限）。 mysql -u root -p 输入密码 修改root密码 Mysql5.6使用如下方式： use mysql update user set password=password(“123123”) where user=“root”; MySQL5.7及后续版本 改密码无password字段（未测试，如下） MySQL5.7版本密码设置，MySQL 设置的密码中必须至少包含一个大写字母、一个小写字母、一个特殊符号、一个数字， 密码长度至少为8个字符 update user set authentication_string=password(“123123”) where user=“root”; 为用户创建一个数据库(testdb) mysql&gt;create database testdb; 创建用户同时授权 授权 bobit 用户拥有 testdb 数据库的所有权限 mysql&gt; grant all privileges on testdb.* to bobit@localhost identified by ‘123456’; Query OK, 0 rows affected (0.00 sec) mysql&gt; flush privileges; Query OK, 0 rows affected (0.01 sec) PS:必须执行flush privileges,刷新系统权限表; 添加远程登录用户 mysql&gt; GRANT ALL PRIVILEGES ON . TO bobit@&quot;%&quot; IDENTIFIED BY ‘123456’; Query OK, 0 rows affected (0.00 sec) 说明： （1）grant all 赋予所有的权限 （2）testdb.* 数据库 testdb 中所有的表 （3）newuser 用户名 （4）@localhost 在本地电脑上的 mysql server 服务器 （5）identfified by ‘password’ 设置密码 备注 因MYSQL5.7版本sql_mode=only_full_group_by问题，暂时降低版本到5.6.35","categories":[{"name":"Docker","slug":"Docker","permalink":"https://bobit.github.io/categories/Docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://bobit.github.io/tags/docker/"}]},{"title":"常用易错单词","slug":"English/常用易错单词","date":"2017-11-11T15:29:17.000Z","updated":"2018-12-21T13:10:31.939Z","comments":true,"path":"posts/62f2c90a.html","link":"","permalink":"https://bobit.github.io/posts/62f2c90a.html","excerpt":"","text":"state condition situation 的区别 都含&quot;情况&quot;的意思。 state：比较常用，各种状态都可以用它，但是它更着重于一种心理状态或者物理状态。指&quot;人或物存在或所处的状态&quot;, 但不着重于&quot;这种状态和具体原因或条件的关系&quot;, 如: He is in a good state.他身体健康。水在标准大气压下 100 摄氏度时是什么状态？state。 condition：指&quot;由于一定的原因、条件或环境所产生的特定情况&quot;, 如: His condition will not permit him to travel.他的情况不允许他旅游。 situation：指&quot;多种具体情况造成的综合状态&quot;, 常着重&quot;这种状态的影响或和处于该状态的事物的关系&quot;, 如: We are in difficult situation. 我们处于困境。 status：用在人的身上一般是其身份和地位，作“状态，情形”讲时，多指政治和商业，指物时相当于 situation。如：最近的国际形式如何？status。 生词本 mediocre 英 [,miːdɪ’əʊkə] 美 [,midɪ’okɚ] adj. 普通的；平凡的；中等的 demonstrate英 ['demənstreɪt]美 ['dɛmən’stret] vt. 证明；展示；论证 vi. 示威 proficiency英 [prə’fɪʃ(ə)nsɪ]美 [prə’fɪʃənsi] n. 精通，熟练","categories":[{"name":"English","slug":"English","permalink":"https://bobit.github.io/categories/English/"}],"tags":[{"name":"英语","slug":"英语","permalink":"https://bobit.github.io/tags/英语/"}]},{"title":"Python高级","slug":"人工智能/Python高级","date":"2017-09-02T01:00:12.000Z","updated":"2018-12-21T13:34:36.571Z","comments":true,"path":"posts/bce7e83e.html","link":"","permalink":"https://bobit.github.io/posts/bce7e83e.html","excerpt":"","text":"[TOC] Python3列表排序 python语言中的列表排序方法有4个：利用步长对序列进行倒序取值、reverse反向排序、sort正序排序、sorted可以获取排序后的列表。 利用步长对序列进行倒序取值 str_list = ['a', 'b', 'd', 'c'] print(str_list[::-1] ) # 输出['c', 'd', 'b', 'a'] reverse()方法 str_list = ['a', 'b', 'd', 'c'] str_list.reverse() print(str_list)#输出['c', 'd', 'b', 'a'] reverse列表反转排序：是把原列表中的元素顺序从左至右的重新存放，而不会对列表中的参数进行排序整理。如果需要对列表中的参数进行整理，就需要用到列表的另一种排序方式sort正序排序。 sort()排序方法 此函数方法对列表内容进行正向排序，排序后的新列表会覆盖原列表（id不变），也就是sort排序方法是直接修改原列表list排序方法。 正向排序 str_list = ['a', 'b', 'd', 'c'] str_list.sort() print(str_list)#输出['a', 'b', 'c', 'd'] 反向排序 str_list = ['a', 'b', 'd', 'c'] str_list.sort(reverse=True) print(str_list) # 输出['d', 'c', 'b', 'a'] 问题：print(str_list.sort())返回值为None 原因：list.sort()功能是针对列表自己内部进行排序， 不会有返回值， 因此返回为None。 解决：解决办法： 1） str_list.sort() print(str_list) 2) print(sorted(str_list)) sorted()方法 即可以保留原列表，又能得到已经排序好的列表sorted()操作方法如下： 正向排序 str_list = ['a', 'b', 'd', 'c'] str_list_sorted = sorted(str_list) print(str_list)#输出['a', 'b', 'd', 'c'] print(sorted(str_list))#输出['a', 'b', 'c', 'd'] 反向排序 str_list = ['a', 'b', 'd', 'c'] str_list_sorted = sorted(str_list,reverse=True) print(str_list)#输出['a', 'b', 'd', 'c'] print(sorted(str_list,reverse=True))#输出['d', 'c', 'b', 'a'] sorted()方法可以用在任何数据类型的序列中，返回的总是一个列表形式： print(sorted('iloveapitest@163.com'))#输出['.', '1', '3', '6', '@', 'a', 'c', 'e', 'e', 'i', 'i', 'l', 'm', 'o', 'o', 'p', 's', 't', 't', 'v'] 总结 不是根据首字母排序,可以理解为列表倒序可以使用reverse()， 根据字母顺序排序可以使用sorted(list)函数； 根据字母相反顺序排序可以使用sorted(list, reverse = True)函数； 切片操作 切片操作的方法 对于具有序列结构的数据来说，切片操作的方法是：consequence[start_index: end_index: step]。 start_index：表示是第一个元素对象，正索引位置默认为0；负索引位置默认为 -len(consequence) end_index：表示是最后一个元素对象，正索引位置默认为 len(consequence)－1；负索引位置默认为 -1。 step：表示取值的步长，默认为1，步长值不能为0。 几种常见的表达 con[start_index: ]：缺省end_index，表示从start_index开始到序列中最后一个对象。 con[: end_index］：缺省start_index，表示从序列中第一个对象到end_index-1之间的片段。 con[:]：缺省start_index和end_index，表示从第一个对象到最后一个对象的完整片段。 con[::step]：缺省start_index和end_index，表示对整个序列按照索引可以被step整除的规则取值。 在使用单索引对序列寻址取值时，你所输入的索引值必须是处于 -len(consequence) 到 len(consequence)-1 之间的值，否则会报错提示索引值超出范围。如： list = [1, 2, 3, 4, 5, 6, 7] print(list[len(list) - 1]) print(list[-len(list)]) #print(list[len(list)]) 利用步长对序列进行倒序取值 list_a=[1,2,3,4,5,6,7] list_b=(1,2,3,4,5,6,7) list_c='Let me show you list little thing' print(list_a[::-1]) print(list_b[::-1]) print(list_c[::-1]) list_a.reverse() print(list_a) #相对reverse而言，切片的方法不会改变列表的结构，所以这是在实际应用中比较有用的一个技巧。","categories":[{"name":"Python","slug":"Python","permalink":"https://bobit.github.io/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://bobit.github.io/tags/python/"}]},{"title":"Anaconda学习总结","slug":"人工智能/Anaconda学习总结","date":"2017-09-02T01:00:10.000Z","updated":"2018-12-21T13:34:30.343Z","comments":true,"path":"posts/8ec8f94.html","link":"","permalink":"https://bobit.github.io/posts/8ec8f94.html","excerpt":"","text":"安装Anaconda和Python 简介 Anaconda是专业的数据科学计算环境，已经集成绝大部分包和工具，不需要多余的安装和调试，使用方便。 安装 Anaconda在官网下载各个操作系统的安装包，网址：https://www.anaconda.com/download/ 双击下载下来的.exe文件，安装时将两个选项都选上，将安装路径写入环境变量，然后等待完成就可以了。 安装完成后，打开Windows的命令提示符输入conda list 就可以查询现在安装了哪些库，常用的numpy, scipy等安装上就可以。 配置 安装其他包，可以运行conda install *** 更新某个包版本不是最新的，运行 conda update *** Jupyter Jupyter，是一个交互式的笔记本，能快速创建程序，支持实时代码、可视化和Markdown语言，数据分析最常用。 在“开始”菜单中“Anaconda3”文件下找到“Jupyter Notebook”，点击进入，它会自动创建一个本地环境localhost。 点击界面右上角的new，创建一个Python文件。到此Anaconda安装就已经全部成功了，我们就可以在这个界面进行输入输出了。 注意事项 Python版本建议3.0以上，现在最新版本是3.6，不要选择2.7的版本，否则你会被无尽的中文编码问题困扰","categories":[{"name":"Python","slug":"Python","permalink":"https://bobit.github.io/categories/Python/"}],"tags":[{"name":"Anaconda","slug":"Anaconda","permalink":"https://bobit.github.io/tags/Anaconda/"},{"name":"python","slug":"python","permalink":"https://bobit.github.io/tags/python/"}]},{"title":"Python基础","slug":"人工智能/Python基础","date":"2017-09-01T01:00:11.000Z","updated":"2018-12-21T13:34:34.185Z","comments":true,"path":"posts/99832f47.html","link":"","permalink":"https://bobit.github.io/posts/99832f47.html","excerpt":"","text":"算术运算符 算术运算 加 减 乘 / 除（浮点数除法） % 取模（相除后的余数） ** 取幂（注意 ^ 并不执行该运算，你可能在其他语言中见过这种情形） // 取整除（表示整数除法,相除后向下取整到最接近的整数） 优先级 从最高到最低优先级的所有运算符： 运算符 描述 ** 指数 (最高优先级) ~ + - 按位翻转, 一元加号和减号 (最后两个的方法名为 +@ 和 -@) * / % // 乘，除，取模和取整除 + - 加法减法 &gt;&gt; &lt;&lt; 右移，左移运算符 &amp; 位 'AND' ^ | 位运算符 &lt;= &lt; &gt; &gt;= 比较运算符 &lt;&gt; == != 等于运算符 = %= /= //= -= += *= **= 赋值运算符 is is not 身份运算符 in not in 成员运算符 not and or 逻辑运算符 变量和赋值运算符 命名 只能在变量名称中使用常规字母、数字和下划线。不能包含空格，并且需要以字母或下划线开头。 不能使用保留字或内置标识符 保留字 False await else import pass None break except in raise True class finally is return and continue for lambda try as def from nonlocal while assert del global not with async elif if or yield 布尔型运算符、比较运算符和逻辑运算符 布尔型运算符 布尔数据类型存储的是值 True 或 False，通常分别表示为 1 或 0。 通常有 6 个比较运算符会获得布尔值： 比较运算符 符号使用情况 布尔型 运算符 5 &lt; 3 False 小于 5 &gt; 3 True 大于 3 &lt;= 3 True 小于或等于 3 &gt;= 5 False 大于或等于 3 == 5 False 等于 3 != 5 True 不等于 逻辑运算符： 逻辑使用情况 布尔型 运算符 5 &lt; 3 and 5 == 5 False and - 检查提供的所有语句是否都为 True 5 &lt; 3 or 5 == 5 True or - 检查是否至少有一个语句为 True not 5 &lt; 3 True not - 翻转布尔值 字符串 将字符串与整数相乘，会得出由原始字符串重复多次构成的新字符串，类型是字符串。 len 仅适用于“序列（例如字符串、字节、元组、列表或范围）或集合（例如字典、集合或冻结集合）”。 类型和类型转换 数据类型： 整型 浮点型 布尔型 字符串 类型检查 type()，它可以用来检查你所处理的任何变量的数据类型。 字符串方法 方法就像某些你已经见过的函数： len(“this”) type(12) print(“Hello world”) 上述三项都是函数。注意，它们使用了小括号并接受一个参数。 type 和 print 函数可以接收字符串、浮点型、整型和很多其他数据类型的参数，函数 len 也可以接受多种不同数据类型的参数，稍后你将在这节课中详细了解。 python 中的方法和函数相似，但是它针对的是你已经创建的变量。方法特定于存储在特定变量中的数据类型。 字符串的每个方法都接受字符串本身作为该方法的第一个参数。但是，它们还可以接收其他参数。count 和 find 方法都接受另一个参数。但是，islower 方法不接受参数。如果我们要在变量中存储浮点数、整数或其他类型的数据，可用的方法可能完全不同！ 列表 列表可排序，你可以使用 .append 向列表中添加项目，列表项的索引始终以 0 开始。 集合 集合是无序的，因此项目的出现顺序可能不一致，你可以使用 .add 向集合中添加项目。和字典及列表一样，集合是可变的。 集合中不能有重复项，不能对集合排序。对于这两个属性，更适合使用列表。 字典 字典是另一种可变容器模型，且可存储任意类型对象。 键必须是唯一的(键必须是不可变的，如字符串，数字或元组)，值可以取任何数据类型。 字典是无序的，因此不能排序。不能使用 .append 向字典中添加项目。 字典中的每项都包含两部分（键和值），字典中的项目是无序的，我们在这节课见到了嵌套字典示例。 但这里有一点需要注意，Python中其他数据结构也是可以嵌套的，不过嵌套字典在我们的使用中会更为普遍一些，所以我们在这里选择了这一项。","categories":[{"name":"Python","slug":"Python","permalink":"https://bobit.github.io/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://bobit.github.io/tags/python/"}]},{"title":"算法的时间复杂度和空间复杂度","slug":"Algorithms/算法时间复杂度","date":"2016-12-21T08:24:25.000Z","updated":"2018-12-27T15:12:05.215Z","comments":true,"path":"posts/19e44aed.html","link":"","permalink":"https://bobit.github.io/posts/19e44aed.html","excerpt":"","text":"算法复杂度 算法复杂度分为时间复杂度和空间复杂度，一个好的算法应该具体执行时间短，所需空间少的特点。 随着计算机硬件和软件的提升，一个算法的执行时间是算不太精确的。只能依据统计方法对算法进行估算。我们抛开硬件和软件的因素，算法的好坏直接影响程序的运行时间。 例子 1234int value = 0; // 执行了1次for (int i = 0; i &lt; n; i++) &#123; // 执行了n次 value += i;&#125; 这个算法执行了 1 + n 次，如果n无限大，我们可以把前边的1忽略，也就是说这个算法执行了n次 时间复杂度常用大O符号表示，这个算法的时间复杂度就是O(n). 概念： 一般情况下，算法的基本操作重复执行的次数是模块n的某一函数f(n),因此，算法的时间复杂度记做 T(n) = O(f(n))。 随着模块n的增大，算法执行的时间增长率f(n)的增长率成正比，所以f(n)越小，算法 的时间复杂度越低，算法的效率越高。 计算时间复杂度 去掉运行时间中的所有加法常数。 只保留最高阶项。 如果最高阶项存在且不是1，去掉与这个最高阶相乘的常数得到时间复杂度 例子 12345for (int i = 0; i &lt; n; i++) &#123; for (int j = i; j &lt; n; j++) &#123; // do ..... &#125;&#125; 当 i = 0 时 里面的fo循环执行了n次，当i等待1时里面的for循环执行了n - 1次，当i 等于2里里面的fro执行了n - 2次…所以执行的次数是 根据我们上边的时间复杂度算法 去掉运行时间中的所有加法常数： 没有加法常数不用考虑 只保留最高阶项: 只保留 去掉与这个最高阶相乘的常数: 去掉 只剩下 最终这个算法的时间复杂度为 再看一个线性的 ​ for ( int i = 0; i &lt; n; i++) { ​ // do … ​ } ​ 因为循环要执行n次所以时间复杂度为O(n) 其它的我也就不一个一个算了，下面给出了常用的时间复杂度 排序法 最差时间分析 平均时间复杂度 稳定度 空间复杂度 冒泡排序 O(n2n^{2}n2) O(n2n^{2}n2) 稳定 O(1) 快速排序 O(n2n^{2}n2) O(n*log(2)log_(2)log(​2)(n)^(n)(n)) 不稳定 O(log2n)~O(n) 二叉树排序 O(n2) O(n*log2n) 不一顶 O(n) 插入排序 O(n2) O(n2) 稳定 O(1) 堆排序 O(n*log2n) O(n*log2n) 不稳定 O(1) 希尔排序 O O 不稳定 O(1)","categories":[{"name":"Algorithms","slug":"Algorithms","permalink":"https://bobit.github.io/categories/Algorithms/"}],"tags":[{"name":"Algorithms","slug":"Algorithms","permalink":"https://bobit.github.io/tags/Algorithms/"}]},{"title":"健康美味饺子","slug":"Life/健康美味饺子","date":"2016-12-15T00:38:12.000Z","updated":"2018-12-21T13:33:50.475Z","comments":true,"path":"posts/2dda6b6e.html","link":"","permalink":"https://bobit.github.io/posts/2dda6b6e.html","excerpt":"","text":"胡萝卜猪肉鸡蛋饺 富含维生素A，补肝明目，清热解毒。 韭菜蘑菇猪肉饺 温中开胃，行气活血，补肾助阳，散瘀。 韭黄三鲜饺 鲜贝、海米和瘦肉中含有丰富的锌元素，促进生长发育，提高抵抗力。 全麦香芹虾肉饺 内含丰富的B族维生素和膳食纤维，有助于控制血糖，适合糖尿病病人食用。 山药豆香鲜肉饺 内含山药，有健脾养胃的功效 香菇鸡肉黄金饺 热量较低，膳食纤维高，可降低血脂。","categories":[{"name":"Life","slug":"Life","permalink":"https://bobit.github.io/categories/Life/"}],"tags":[{"name":"life","slug":"life","permalink":"https://bobit.github.io/tags/life/"},{"name":"eat","slug":"eat","permalink":"https://bobit.github.io/tags/eat/"}]},{"title":"宝宝晚上睡不安的原因","slug":"Life/宝宝晚上睡不安的原因","date":"2016-12-14T23:38:15.000Z","updated":"2018-12-21T13:33:58.874Z","comments":true,"path":"posts/23c9dee4.html","link":"","permalink":"https://bobit.github.io/posts/23c9dee4.html","excerpt":"","text":"宝宝晚上睡不安的原因很多，应该可以分为两大类： 一、外在因素 1、饥饿 多见于新生儿和三个月之内的宝宝。这时需要哺乳或喂奶来解决。稍大的宝宝如果睡前吃饱，可以排除这个因素。 天气干燥的情况下，宝宝夜间可能会口渴，给他补充点水分可以让他安静。 2、缺钙 缺钙是导致小宝宝睡觉不安稳首要因素之一，大多数MM都会考虑到它。缺钙、血钙降低，引起大脑植物性神经兴奋性增高，导致宝宝夜醒、夜惊、夜间烦躁不安，睡不安稳。解决方案就是给宝宝补钙和维生素D并多晒太阳。 A、补钙：每日元素钙300-500mg B、补VD：每日400-800IU 3、太热 现在的宝宝穿盖多半是偏热的。其实小宝宝凉一点没有关系，太热会使他不舒服，也容易生病。如果室温挺高，又穿着睡袋，再盖上小被子，宝宝自身散热能力差，会感到热而醒来。这时只要减少穿盖即可解决。 4、腹胀 1岁以内的婴儿都会出现这种情况。如果睡前吃得过饱，或喝奶后没有打嗝排气，小宝宝都会因腹胀而醒来。大点的婴儿多半是睡前几小时内吃了一些难以消化的东西。注意按摩、排气和调整饮食即可解决。积食的宝宝可用点小中药治疗。 5、尿湿 因尿裤太湿或勒得太紧，也会使宝宝不舒服。有的宝宝想尿尿时不愿轻易尿在尿裤上，也会翻来覆去不安稳。细心的MM观察一下. 6、白天太兴奋或环境的变化 稍大点的宝宝的睡眠不安也可与白天过度兴奋或紧张、日常生活的变化有关。如出门、睡眠规律改变、搬新屋、有新的保姆和陌生人来。比如老的保姆走了会引起婴儿晚上睡眠不安。经常更换抚养人也使孩子睡眠障碍的发生率明显升高。白天睡的太多也可影响晚上的睡眠。 7、出牙或身体不适 宝宝出牙期间往往会有睡不安稳的现象。有时几夜反复折腾之后妈妈才发现，宝宝的牙床冒出了白白的小牙。可见出牙还是有些疼痛的。其他疾病当然也会引起睡眠不安。生病或发烧前的夜晚往往是翻覆不宁的。这些都需要细心的观察和判断。 二、内在因素 小儿的内在因素对睡眠也有影响：大脑神经发育尚未成熟。孩子生理上尚未建立固定的作息时间表。宝宝生物时钟日夜规律的调整，要倚赖宝宝生理成熟度的配合。 调查表明，神经系统兴奋性较高的宝宝，生理成熟度往往晚些，容易出现睡眠不安的情况。这种宝宝相对睡眠好的宝宝，性格可能更趋向活跃、外向、敏感。 人的睡眠分为深度睡眠和浅度睡眠，夜间约3-4小时交替一次。婴儿和幼儿同样，可能深睡和浅睡的交替时间更短一些，约2-3小时交换一次。大人和许多睡整夜觉的宝宝，在浅度睡眠到来时，可以较好地自我调整，重新进入深度睡眠。而也有许多小宝宝甚至许多大人，无法自我调整入睡，所以就从浅度睡眠中醒来。 许多正在吃母乳的宝宝，无法自我调整，心理渴望爱抚，妈妈的乳房无疑是她最大的安慰。当然，有时抱睡、边走边摇等也会有效。尤其随着神经系统的发育和大脑皮层活跃，宝宝越长大越容易无法自我调整。这就是宝宝在四、五个月之后反而睡觉比小时候还要差、醒的次数还要多的原因。 排除掉渴饿冷热缺钙腹胀出牙兴奋等等外在因素之后，你的睡不好觉的宝宝，也许只是因为大脑皮层活跃，无法自我调整进入深睡状态。何必奢望自己的宝宝是能够自行完成调整的那一个？在断奶之后，或随着宝宝的成长，这些现象总归会解决的。 最后要提醒妈妈的是：哭闹或烦躁不安时可采取轻拍或抚摸孩子，或给他喂奶和喝水，可使宝宝重新入睡。不要马上又抱又哄，这样会恶性循环。某些神经类型的正常小儿晚上睡眠很差，但只要吃、发育增长没问题就不必太担心。","categories":[{"name":"Life","slug":"Life","permalink":"https://bobit.github.io/categories/Life/"}],"tags":[{"name":"life","slug":"life","permalink":"https://bobit.github.io/tags/life/"}]},{"title":"0-12个月宝宝每月注意事项","slug":"Life/0-12个月宝宝每月注意事项","date":"2016-12-14T23:38:11.000Z","updated":"2018-12-21T13:33:46.808Z","comments":true,"path":"posts/3892ebd9.html","link":"","permalink":"https://bobit.github.io/posts/3892ebd9.html","excerpt":"","text":"一个月 1、24小时内要接种乙肝疫苗、卡介苗 2、每天可以睡16—20小时 3、不要枕枕头，把毛巾折两折枕，三个月后给宝宝枕枕头，枕高3到4厘米. 4、母乳喂奶前后半小时不要喂水，稀释胃液影响消化，睡前不喂水。纯母乳喂养6个月内可以不喂水。人工喂养，两餐之间需要喂水。 5、早看黑白图片，培养智力，距离眼镜20厘米处，每周换一张照片，直至宝宝有反应。（0—3个月内） 6、新生儿期间，按需喂养。 两个月 1、每个乳房喂奶10—15分钟，每三小时喂一次，养成按顿喂养好习惯。 2、不要用摇晃的方式哄宝宝睡觉，影响脑发育，造成轻微智力低下。若要哄，可幅度小、有规律、轻柔舒缓、10分钟左右。 3、45天可以训练宝宝抬头，每天两次，每次10秒钟，每次俯卧时间不宜超过一分钟 4、不要经常抱宝宝，不利于独立性格形成。 三个月 1、上午可以睡12次，下午2次，晚上睡12个大觉。 2、喂奶每天6次，每次100ml~120ml，分6：00、9：30、13：00、14：30、8：00、11：00.。每日喂养总量超过600ml即可。为四月添加辅食培养好习惯。 3、陪宝宝发a、e等元音，训练宝宝追视能力。 4、给宝宝做按摩，每天洗澡后做抚触按摩，有效促进神经系统发育和锻炼宝宝的感觉系统（益智）。 5、预防宝宝经常偏头睡。 四个月 1、给宝宝枕枕头，枕高3~4厘米。 2、宝宝游泳可以提高智力。可以增强自信心、增强免疫力、增大肺活量，睡前游泳更可以促进宝宝身高和体重的增加。 3、不要看电视超过3分钟，辐射，对眼睛不好。 4、训练宝宝视觉，准备纯色的彩色图片，教宝宝认识不同颜色。 5、用棉签给宝宝擦牙。 6、宝宝若哭，非让抱着才睡，可让宝宝哭个够，一般一周哭的现象就会消失。 7、可以喝果汁，每天10ml，用果汁和果肉分离的榨汁机。按1：3（水）的比例将果汁稀释，用60度的温开水稀释，冷却到40度喂宝宝，上午两餐之间喂一次，适应后加至20ml，一周一种水果。 8、训练宝宝用手抓东西、训练宝宝嗅觉。 9、听三字儿歌学发音。 五个月 1、可加辅食鸡蛋黄（不要鸡蛋清，容易致敏），以蛋黄恰好凝固为宜，用小勺取1/4碾碎，加少量温开水调成糊状，或加入果汁。于喂奶后喂辅食，每次1/4，一周后无过敏，加至1/2蛋黄，再一周加至1个蛋黄。 2、适应蛋黄后，可喂养苹果泥、香蕉泥、米汤等，每次一勺。47个月喂养半流质食物，712个月添加碎菜末、等碎状固体食物。 3、此月宝宝出牙，会吃手，应阻止，否则会影响出牙或牙齿排列不整齐，有缝隙。可用磨牙棒，或转移宝宝注意力。 4、不要添加淀粉类食物 5、训练宝宝发ma、ba等。 六个月 1、不要喝豆浆、不要用牛奶、酸奶代替配方奶。 2、宝宝开始有脾气，不要纵容，要让宝宝自己安静下来后，再引导。 七个月 1、保护宝宝牙齿，吃完奶后，喂几口温开水冲洗口腔，棉签粘淡盐水每天早晚帮宝宝清洗牙齿和牙床。 2、给宝宝讲故事和看彩色图片书，重复讲一个故事，看宝宝反映。 3、宝宝会出现假哭、假笑等来达到自己的目的，妈妈应视情况让宝宝觉得这样做不能达到目的，几次之后，宝宝就不会再这样了。如不然，宝宝就会想办法编造更复杂的谎言。 4、宝宝扔东西，不是惹你生气，开始时是因为发育不全拿不稳，妈妈不应生气，应和宝宝玩扔东西的游戏，适当加以引导。 5、宝宝怕生人，出现依恋，可给予更多陪伴和引导。 八个月 1、不要给宝宝喝糖水、冰水 2、训练宝宝用小勺 3、宝宝会出现很多重复的动作，如反复摆同一积木，不要阻止。 4、不要告诉宝宝“天黑，外面有鬼之类的话”宝宝以后会怕黑，胆子小，不敢独处。 九个月 1、可以吃面食、小馒头等 2、6个月前纯母乳喂养的宝宝可以不喝水、6个月后的宝宝不要喝纯净水和矿泉水，喝煮好的温开水。 3、不要给宝宝吃膨化食品、爆米花、松花蛋、油条、腌制食品、味精多的食品，会影响宝宝智力。 4、经常锻炼宝宝的爬行能力，不要急于让宝宝行走。爬好了，才能走。 十个月 1、不要吃糖和巧克力 2、制定宝宝吃饭规则、定时定量定位置，养成良好习惯，否则宝宝容易不爱吃饭，影响发育。坚决不吃零食，吃零食会影响吃正餐。 3、和宝宝一起看书、翻书。 4、给宝宝准备玩具箱，让宝宝玩完玩具自己放回去。可以告诉他，小球回家了。 5、培养宝宝乐感，每天10~15分钟古典音乐，宝宝爬行时可以放有节奏的音乐。 6、做游戏激发宝宝好奇心，可以将搭好的积木推到，再陪宝宝搭、可以让宝宝找小球。 十一个月 1、学习站立，摔倒了，鼓励宝宝站起来继续走。 2、给宝宝营造独立思考的环境，宝宝玩玩具或积木时不要打扰，若买了新玩具看见宝宝还在玩别的玩具，也不要打断宝宝，等宝宝不玩后，再告诉宝宝玩新玩具，不然宝宝会对什么事情都不专心，会习惯浅尝辄止。 3、看图片学动物叫 4、不要使用学步车 5、宝宝任性不能纵容，可转移宝宝注意力，或等宝宝安静下来再处理。 十二个月 1、让宝宝多翻书，可以锻炼手指灵活，陪宝宝看书识字，每天坚持看，养成宝宝主动看书的习惯。 2、训练宝宝自己走，宝宝摔倒了，一定不要扶，忍痛引导宝宝自己起来，开始时宝宝会很慢，慢慢会自己起，这样的宝宝坚强、独立。 3、给宝宝说话的机会，如宝宝如果想拿杯子，不要马上递给他，要鼓励宝宝说出来。要经常训练宝宝说话的机会，1224个月是宝宝口语的表达阶段，应训练宝宝主动表达自己的需求。学习口语最佳时间是24岁，所以不用等上学再学习英语。 4、光脚丫走路好处多","categories":[{"name":"Life","slug":"Life","permalink":"https://bobit.github.io/categories/Life/"}],"tags":[{"name":"life","slug":"life","permalink":"https://bobit.github.io/tags/life/"}]},{"title":"Redis学习总结","slug":"分布式/Redis学习总结","date":"2016-12-13T14:09:17.000Z","updated":"2018-12-21T12:55:42.349Z","comments":true,"path":"posts/276848db.html","link":"","permalink":"https://bobit.github.io/posts/276848db.html","excerpt":"","text":"简介 Redis 是一款依据BSD开源协议发行的高性能Key-Value存储系统（cache and store）。它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(hashes), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave。Redis并用于构建高性能，可扩展的Web应用程序的完美解决方案。 主要特点 Redis从它的许多竞争继承来的三个主要特点： Redis数据库完全在内存中，使用磁盘仅用于持久性。 相比许多键值数据存储，Redis拥有一套较为丰富的数据类型。 Redis可以将数据复制到任意数量的从服务器。 Redis 优势 异常快速：Redis的速度非常快，每秒能执行约11万集合，每秒约81000+条记录。 支持丰富的数据类型：Redis支持最大多数开发人员已经知道像列表，集合，有序集合，散列数据类型。这使得它非常容易解决各种各样的问题，因为我们知道哪些问题是可以处理通过它的数据类型更好。 操作都是原子性：所有Redis操作是原子的，这保证了如果两个客户端同时访问的Redis服务器将获得更新后的值。 多功能实用工具：Redis是一个多实用的工具，可以在多个用例如缓存，消息，队列使用(Redis原生支持发布/订阅)，任何短暂的数据，应用程序，如Web应用程序会话，网页命中计数等。 安装Redis 官方网站：http://redis.io/ 官方下载：http://redis.io/download 可以根据需要下载不同版本 windows版：https://github.com/mythz/redis-windows Windows 64位操作系统 Redis 安装包 下载完成后 可以右键解压到 某个硬盘下 比如D:\\Redis\\redis-2.6。 在D:\\Redis\\redis-2.6\\bin\\release下 有两个zip包 一个32位一个64位。 根据自己windows的位数 解压到D:\\Redis\\redis-2.6 根目录下。 文件介绍： redis-benchmark.exe #基准测试 redis-check-aof.exe # aof redischeck-dump.exe # dump redis-cli.exe # 客户端 redis-server.exe # 服务器 redis.windows.conf # 配置文件 客户端 redis-desktop-manager-0.8.3.3850.exe Windows下Redis的安装使用 启动Redis 进入redis目录后 开启服务 （注意加上redis.conf） redis-server.exe redis.windows.conf 这个窗口要保持开启 关闭时redis服务会自动关闭 redis会自动保存数据到硬盘 所以图中是我第二次开启时 多了一个 DB loaded from disk 测试使用 另外开启一个命令行窗口 进入redis目录下 （注意修改自己的ip） redis-cli.exe（默认为127.0.0.1:6379） redis-cli.exe -h 192.168.10.61 -p 6379 redis-cli.exe -h 192.168.80.72 -p 6379 如下： 12345127.0.0.1:6379&gt; set name zhangsanOK127.0.0.1:6379&gt; get name&quot;zhangsan&quot;127.0.0.1:6379&gt; 将Redis设为windows启动项 win7下安装完redis之后，每次开机都得用cmd命令行启动redis，所以就想办法实现开机自启动redis. 每次打开命令行启动Redis会很麻烦，把Redis设为windows启动项就不用每次都入命令行了 一、把启动命令写入bat 在redis的目录下新建一个start.bat文件内容为 E:\\DevTools\\redis64\\redis-server.exe E:\\DevTools\\redis64\\redis.windows.conf 二、利用vb脚本调用bat 再新建一个文件redis_run.vbs内容为 CreateObject(“WScript.Shell”).Run “cmd /c E:\\DevTools\\redis64\\start.bat”,0 三、设置开机自启动 cmd =》 regedit 打开注册表 HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run 新建一个字符串值， 数值名称：startRedis 数值数据：E:\\DevTools\\redis64\\start.vbs Java开发包Jedis 操作命令总结 这篇文章主要介绍了Redis操作命令总结,本文讲解了key pattern 查询相应的key、字符串类型的操作、链表操作、hashes类型及操作、集合结构操作、有序集合、服务器相关命令等内容,需要的朋友可以参考下 key pattern 查询相应的key （1）keys *：redis允许模糊查询key 有3个通配符 *、?、[] （2）randomkey：返回随机key （3）type key：返回key存储的类型 （4）exists key：判断某个key是否存在（1:存在，0：不存在） （5）del key：删除key （6）rename key newkey：改名 （7）renamenx key newkey：如果newkey不存在则修改成功 （8）move key 1：将key移动到1数据库 （9）ttl key：查询key的生命周期（秒） （10）expire key 整数值：设置key的生命周期以秒为单位 （11）pexpire key 整数值：设置key的生命周期以毫秒为单位 （12）pttl key：查询key 的生命周期（毫秒） （13）perisist key：把指定key设置为永久有效 字符串类型的操作 （1）set key value [ex 秒数] [px 毫秒数] [nx/xx] 如果ex和px同时写，则以后面的有效期为准 nx：如果key不存在则建立 xx：如果key存在则修改其值 （2）get key：取值 （3）mset key1 value1 key2 value2 一次设置多个值 （4）mget key1 key2 ：一次获取多个值 （5）setrange key offset value：把字符串的offset偏移字节改成value 如果偏移量 &gt; 字符串长度，该字符自动补0x00 （6）append key value ：把value追加到key 的原值上 （7）getrange key start stop：获取字符串中[start, stop]范围的值 对于字符串的下标，左数从0开始，右数从-1开始 注意：当start&gt;length，则返回空字符串 当stop&gt;=length，则截取至字符串尾 如果start所处位置在stop右边，则返回空字符串 （8）getset key nrevalue：获取并返回旧值，在设置新值 （9）incr key：自增，返回新值，如果incr一个不是int的value则返回错误，incr一个不存在的key，则设置key为1 （10）incrby key 2：跳2自增 （11）incrbyfloat by 0.7： 自增浮点数 （12）setbit key offset value：设置offset对应二进制上的值，返回该位上的旧值 注意：如果offset过大，则会在中间填充0 offset最大到多少 2^32-1，即可推出最大的字符串为512M （13）bitop operation destkey key1 [key2…] 对key1 key2做opecation并将结果保存在destkey上 opecation可以是AND OR NOT XOR （14）strlen key：取指定key的value值的长度 （15）setex key time value：设置key对应的值value，并设置有效期为time秒 链表操作 Redis的list类型其实就是一个每个子元素都是string类型的双向链表，链表的最大长度是2^32。list既可以用做栈，也可以用做队列。 list的pop操作还有阻塞版本，主要是为了避免轮询 （1）lpush key value：把值插入到链表头部 （2）rpush key value：把值插入到链表尾部 （3）lpop key ：返回并删除链表头部元素 （4）rpop key： 返回并删除链表尾部元素 （5）lrange key start stop：返回链表中[start, stop]中的元素 （6）lrem key count value：从链表中删除value值，删除count的绝对值个value后结束 count &gt; 0 从表头删除 count &lt; 0 从表尾删除 count=0 全部删除 （7）ltrim key start stop：剪切key对应的链接，切[start, stop]一段并把改制重新赋给key （8）lindex key index：返回index索引上的值 （9）llen key：计算链表的元素个数 （10）linsert key after|before search value：在key 链表中寻找search，并在search值之前|之后插入value （11）rpoplpush source dest：把source 的末尾拿出，放到dest头部，并返回单元值 应用场景： task + bak 双链表完成安全队列 业务逻辑： rpoplpush task bak 接收返回值并做业务处理 如果成功则rpop bak清除任务，如果不成功，下次从bak表取任务 （12）brpop，blpop key timeout：等待弹出key的尾/头元素 timeout为等待超时时间，如果timeout为0则一直等待下去 应用场景：长轮询ajax，在线聊天时能用到 hashes类型及操作 Redis hash 是一个string类型的field和value的映射表，它的添加、删除操作都是O(1)（平均）。hash特别适用于存储对象，将一个对象存储在hash类型中会占用更少的内存，并且可以方便的存取整个对象。 配置： hash_max_zipmap_entries 64 #配置字段最多64个 hash_max_zipmap_value 512 #配置value最大为512字节 （1）hset myhash field value：设置myhash的field为value （2）hsetnx myhash field value：不存在的情况下设置myhash的field为value （3）hmset myhash field1 value1 field2 value2：同时设置多个field （4）hget myhash field：获取指定的hash field （5）hmget myhash field1 field2：一次获取多个field （6）hincrby myhash field 5：指定的hash field加上给定的值 （7）hexists myhash field：测试指定的field是否存在 （8）hlen myhash：返回hash的field数量 （9）hdel myhash field：删除指定的field （10）hkeys myhash：返回hash所有的field （11）hvals myhash：返回hash所有的value （12）hgetall myhash：获取某个hash中全部的field及value 集合结构操作 特点：无序性、确定性、唯一性 （1）sadd key value1 value2：往集合里面添加元素 （2）smembers key：获取集合所有的元素 （3）srem key value：删除集合某个元素 （4）spop key：返回并删除集合中1个随机元素（可以坐抽奖，不会重复抽到某人） （5）srandmember key：随机取一个元素 （6）sismember key value：判断集合是否有某个值 （7）scard key：返回集合元素的个数 （8）smove source dest value：把source的value移动到dest集合中 （9）sinter key1 key2 key3：求key1 key2 key3的交集 （10）sunion key1 key2：求key1 key2 的并集 （11）sdiff key1 key2：求key1 key2的差集 （12）sinterstore res key1 key2：求key1 key2的交集并存在res里 有序集合 概念：它是在set的基础上增加了一个顺序属性，这一属性在添加修改元素的时候可以指定，每次指定后，zset会自动按新的值调整顺序。可以理解为有两列的mysql表，一列存储value，一列存储顺序，操作中key理解为zset的名字。 和set一样sorted，sets也是string类型元素的集合，不同的是每个元素都会关联一个double型的score。sorted set的实现是skip list和hash table的混合体。 当元素被添加到集合中时，一个元素到score的映射被添加到hash table中，所以给定一个元素获取score的开销是O(1)。另一个score到元素的映射被添加的skip list，并按照score排序，所以就可以有序地获取集合中的元素。添加、删除操作开销都是O(logN)和skip list的开销一致，redis的skip list 实现是双向链表，这样就可以逆序从尾部去元素。sorted set最经常使用方式应该就是作为索引来使用，我们可以把要排序的字段作为score存储，对象的ID当元素存储。 （1）zadd key score1 value1：添加元素 （2）zrange key start stop [withscore]：把集合排序后,返回名次[start,stop]的元素 默认是升续排列 withscores 是把score也打印出来 （3）zrank key member：查询member的排名（升序0名开始） （4）zrangebyscore key min max [withscores] limit offset N：集合（升序）排序后取score在[min, max]内的元素，并跳过offset个，取出N个 （5）zrevrank key member：查询member排名（降序 0名开始） （6）zremrangebyscore key min max：按照score来删除元素，删除score在[min, max]之间 （7）zrem key value1 value2：删除集合中的元素 （8）zremrangebyrank key start end：按排名删除元素，删除名次在[start, end]之间的 （9）zcard key：返回集合元素的个数 （10）zcount key min max：返回[min, max]区间内元素数量 （11）zinterstore dest numkeys key1[key2…] [WEIGHTS weight1 [weight2…]] [AGGREGATE SUM|MIN|MAX] 求key1，key2的交集，key1，key2的权值分别是weight1，weight2 聚合方法用 sum|min|max 聚合结果 保存子dest集合内 注意：weights,aggregate如何理解？ 答：如果有交集，交集元素又有score，score怎么处理？aggregate num-&gt;score相加，min最小score，max最大score，另外可以通过weights设置不同的key的权重，交集时 score*weight 服务器相关命令 （1）ping：测定连接是否存活 （2）echo：在命令行打印一些内容 （3）select：选择数据库 （4）quit：退出连接 （5）dbsize：返回当前数据库中key的数目 （6）info：获取服务器的信息和统计 （7）monitor：实时转储收到的请求 （8）config get 配置项：获取服务器配置的信息 config set 配置项 值：设置配置项信息 （9）flushdb：删除当前选择数据库中所有的key （10）flushall：删除所有数据库中的所有的key （11）time：显示服务器时间，时间戳（秒），微秒数 （12）bgrewriteaof：后台保存rdb快照 （13）bgsave：后台保存rdb快照 （14）save：保存rdb快照 （15）lastsave：上次保存时间 （16）shutdown [save/nosave] 注意：如果不小心运行了flushall，立即shutdown nosave，关闭服务器，然后手工编辑aof文件，去掉文件中的flushall相关行，然后开启服务器，就可以倒回原来是数据。如果flushall之后，系统恰好bgwriteaof了，那么aof就清空了，数据丢失。 （17）showlog：显示慢查询 问：多慢才叫慢？ 答：由slowlog-log-slower-than 10000，来指定（单位为微秒） 问：服务器存储多少条慢查询记录 答：由slowlog-max-len 128，来做限制 常用命令 查看匹配前缀的keys keys “key*” 查看当前所有key keys * 当前的key是否存在（返回0不存在，1存在） exists key 删除当前key del key 设置过期时间 expire key 10 重命名key rename key newkey 数据库切换 select ad4databank 当前数据库中key的数量 dbsize 清空当前数据库 flushdb 清除所有数据库 flushall 清空redis flushdb 随机取出一个key randomkey 查看key的类型 type key 查看数据库中key的数量 dbsize 查看服务器信息 info 查看redis正在做什么 monitor 查看日志 slowlog get slowlog get 10","categories":[{"name":"分布式","slug":"分布式","permalink":"https://bobit.github.io/categories/分布式/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://bobit.github.io/tags/Redis/"}]},{"title":"MQ学习总结","slug":"分布式/MQ学习总结","date":"2016-11-13T03:38:35.000Z","updated":"2018-12-21T12:55:28.554Z","comments":true,"path":"posts/2da7d583.html","link":"","permalink":"https://bobit.github.io/posts/2da7d583.html","excerpt":"","text":"简介 MQ全称为Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。消 息传递指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信，直接调用通常是用于诸如远程过程调用的技术。排队指的是应用程序通过 队列来通信。队列的使用除去了接收和发送应用程序同时执行的要求。其中较为成熟的MQ产品有IBM WEBSPHERE MQ。还有：MSMQ.ActiveMQ. RabbitMQ.ZeroMQ. MQ特点 MQ是消费-生产者模型的一个典型的代表，一端往消息队列中不断写入消息，而另一端则可以读取或者订阅队列中的消息。MQ和JMS类似，但不同的是JMS是SUN JAVA消息中间件服务的一个标准和API定义，而MQ则是遵循了AMQP协议的具体实现和产品。 使用场景 在项目中，将一些无需即时返回且耗时的操作提取出来，进行了异步处理，而这种异步处理的方式大大的节省了服务器的请求响应时间，从而提高了系统的吞吐量。 MOM：企业消息系统，即面向消息的中间件，提供了以松散耦合的灵活方式集成应用程序的一种机制。它们提供了基于存储和转发的应用程序之间的异步数据发送，即应用程序彼此不直接通信，而是与作为中介的MOM通信。 JMS：是Java平台上有关面向消息中间件的技术规范。 ActiveMQ：ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现。可以理解为ActiveMQ是支持jms规范的一个server；相对于对于JDBC和数据库的关系来说，它就是个mysql。 ActiveMQ 下载 http://activemq.apache.org/download.html 运行 解压缩，运行bin目录下的activemq.bat文件，此时使用的是默认的服务端口：61616和默认的console端口：8161。 运行起来后，可以用IE访问:http://localhost:8161/admin/index.jsp 然后创建一个Queue，命名为FirstQueue。 修改ActiveMQ的服务端口和console端口 1234567A、修改服务端口：打开conf/activemq.xml文件，修改以下红色字体部分 &lt;transportConnectors&gt; &lt;transportConnector name=&quot;openwire&quot; uri=&quot;tcp://10.42.220.72:61618&quot;discoveryUri=&quot;multicast://default&quot;/&gt;&lt;/transportConnectors&gt;B、修改console的地址和端口:打开conf/jetty.xml文件，修改以下红色字体部分&lt;bean id=&quot;jettyPort&quot;class=&quot;org.apache.activemq.web.WebConsolePort&quot;init-method=&quot;start&quot;&gt; &lt;property name=&quot;port&quot; value=&quot;8162&quot;/&gt;&lt;/bean&gt; activemq的特性 多种语言和协议编写客户端。语言: Java, C, C++, C#, Ruby, Perl, Python, PHP。应用协议: OpenWire,Stomp REST,WS Notification,XMPP,AMQP 完全支持JMS1.1和J2EE 1.4规范 (持久化,XA消息,事务) 对Spring的支持,ActiveMQ可以很容易内嵌到使用Spring的系统里面去,而且也支持Spring2.0的特性 通过了常见J2EE服务器(如 Geronimo,JBoss 4, GlassFish,WebLogic)的测试,其中通过JCA 1.5 resourceadaptors的配置,可以让ActiveMQ可以自动的部署到任何兼容J2EE1.4商业服务器上 支持多种传送协议:in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA 支持通过JDBC和journal提供高速的消息持久化 从设计上保证了高性能的集群,客户端-服务器,点对点 支持Ajax 支持与Axis的整合 可以很容易得调用内嵌JMS provider,进行测试 客户端demo 需要提前将activemq解压包中的lib目录下的相关包引入到工程中，再进行如下编码： 发送端的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667importjavax.jms.Connection;importjavax.jms.ConnectionFactory;importjavax.jms.DeliveryMode;importjavax.jms.Destination;importjavax.jms.MessageProducer;importjavax.jms.Session;importjavax.jms.TextMessage;importorg.apache.activemq.ActiveMQConnection;importorg.apache.activemq.ActiveMQConnectionFactory;publicclass Sender &#123; privatestaticfinalintSEND_NUMBER = 5; publicstaticvoid main(String[] args) &#123; // ConnectionFactory：连接工厂，JMS用它创建连接 ConnectionFactory connectionFactory; // Connection：JMS客户端到JMS Provider的连接 Connection connection = null; // Session：一个发送或接收消息的线程 Session session; // Destination：消息的目的地;消息发送给谁. Destination destination; // MessageProducer：消息发送者 MessageProducer producer; // TextMessage message; //构造ConnectionFactory实例对象，此处采用ActiveMq的实现jar connectionFactory = new ActiveMQConnectionFactory( ActiveMQConnection.DEFAULT_USER, ActiveMQConnection.DEFAULT_PASSWORD, &quot;failover:(tcp://10.42.220.72:61617,tcp://10.42.220.72:61618)&quot;); try &#123; //构造从工厂得到连接对象 connection =connectionFactory.createConnection(); //启动 connection.start(); //获取操作连接 session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE); //获取session destination = session.createQueue(&quot;FirstQueue&quot;); //得到消息生成者【发送者】 producer =session.createProducer(destination); //设置不持久化，此处学习，实际根据项目决定 producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); //构造消息，此处写死，项目就是参数，或者方法获取 sendMessage(session, producer); session.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (null != connection) connection.close(); &#125; catch (Throwable ignore) &#123; &#125; &#125; &#125; publicstaticvoid sendMessage(Session session,MessageProducer producer) throws Exception &#123; for (int i = 1; i &lt;=SEND_NUMBER; i++) &#123; TextMessage message = session .createTextMessage(&quot;ActiveMq发送的消息&quot; + i); //发送消息到目的地方 System.out.println(&quot;发送消息：&quot; + &quot;ActiveMq 发送的消息&quot; + i); producer.send(message); &#125; &#125;&#125; 接收端代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556importjavax.jms.Connection;importjavax.jms.ConnectionFactory;importjavax.jms.Destination;importjavax.jms.MessageConsumer;importjavax.jms.Session;importjavax.jms.TextMessage;importorg.apache.activemq.ActiveMQConnection;importorg.apache.activemq.ActiveMQConnectionFactory; publicclass Receive &#123; publicstaticvoid main(String[] args) &#123; // ConnectionFactory：连接工厂，JMS用它创建连接 ConnectionFactory connectionFactory; // Connection：JMS客户端到JMS Provider的连接 Connection connection = null; // Session：一个发送或接收消息的线程 Session session; // Destination：消息的目的地;消息发送给谁. Destination destination; //消费者，消息接收者 MessageConsumer consumer; connectionFactory = new ActiveMQConnectionFactory( ActiveMQConnection.DEFAULT_USER, ActiveMQConnection.DEFAULT_PASSWORD, &quot;failover:(tcp://10.42.220.72:61617,tcp://10.42.220.72:61618)&quot;); try &#123; //构造从工厂得到连接对象 connection =connectionFactory.createConnection(); //启动 connection.start(); //获取操作连接 session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //获取session destination = session.createQueue(&quot;FirstQueue&quot;); consumer =session.createConsumer(destination); while (true) &#123; //设置接收者接收消息的时间，为了便于测试，这里谁定为100s TextMessage message =(TextMessage) consumer.receive(100000); if (null != message) &#123; System.out.println(&quot;收到消息&quot; + message.getText()); &#125; else &#123; break; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (null != connection) connection.close(); &#125; catch (Throwable ignore) &#123; &#125; &#125; &#125;&#125; 通过监控查看消息堆栈的记录 登陆http://localhost:8162/admin/queues.jsp，默认的用户名和密码：admin/admin ActiveMQ的多种部署方式 单点的ActiveMQ作为企业应用无法满足高可用和集群的需求，所以ActiveMQ提供了master-slave(主备方式)、broker-cluster等多种部署方式，但通过分析多种部署方式之后我认为需要将两种部署方式相结合才能满足我们公司分布式和高可用的需求，所以后面就重点将解如何将两种部署方式相结合。 Master-Slave部署方式 1）shared filesystem Master-Slave部署方式 主要是通过共享存储目录来实现master和slave的热备，所有的ActiveMQ应用都在不断地获取共享目录的控制权，哪个应用抢到了控制权，它就成为master。 多个共享存储目录的应用，谁先启动，谁就可以最早取得共享目录的控制权成为master，其他的应用就只能作为slave。 2）shared database Master-Slave方式 与shared filesystem方式类似，只是共享的存储介质由文件系统改成了数据库而已。 3）Replicated LevelDB Store方式 这种主备方式是ActiveMQ5.9以后才新增的特性，使用ZooKeeper协调选择一个node作为master。被选择的master broker node开启并接受客户端连接。 其他node转入slave模式，连接master并同步他们的存储状态。slave不接受客户端连接。所有的存储操作都将被复制到连接至Master的slaves。 如果master死了，得到了最新更新的slave被允许成为master。fialed node能够重新加入到网络中并连接master进入slave mode。所有需要同步的disk的消息操作都将等待存储状态被复制到其他法定节点的操作完成才能完成。所以，如果你配置了replicas=3，那么法定大小是(3/2)+1=2. Master将会存储并更新然后等待 (2-1)=1个slave存储和更新完成，才汇报success。至于为什么是2-1，熟悉Zookeeper的应该知道，有一个node要作为观擦者存在。 单一个新的master被选中，你需要至少保障一个法定node在线以能够找到拥有最新状态的node。这个node将会成为新的master。因此，推荐运行至少3个replica nodes，以防止一个node失败了，服务中断。 Broker-Cluster部署方式 前面的Master-Slave的方式虽然能解决多服务热备的高可用问题，但无法解决负载均衡和分布式的问题。Broker-Cluster的部署方式就可以解决负载均衡的问题。 Broker-Cluster部署方式中，各个broker通过网络互相连接，并共享queue。当broker-A上面指定的queue-A中接收到一个message处于pending状态，而此时没有consumer连接broker-A时。如果cluster中的broker-B上面由一个consumer在消费queue-A的消息，那么broker-B会先通过内部网络获取到broker-A上面的message，并通知自己的consumer来消费。 1）static Broker-Cluster部署 在activemq.xml文件中静态指定Broker需要建立桥连接的其他Broker： 1、 首先在Broker-A节点中添加networkConnector节点： 12 &lt;networkConnector uri=&quot;static:(tcp:// 0.0.0.0:61617)&quot;duplex=&quot;false&quot;/&gt;&lt;/networkConnectors&gt; 2、 修改Broker-A节点中的服务提供端口为61616： 12 &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;/transportConnectors&gt; 3、 在Broker-B节点中添加networkConnector节点： 12 &lt;networkConnector uri=&quot;static:(tcp:// 0.0.0.0:61616)&quot;duplex=&quot;false&quot;/&gt;&lt;/networkConnectors&gt; 4、 修改Broker-A节点中的服务提供端口为61617： 12 &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61617?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;/transportConnectors&gt; 5、分别启动Broker-A和Broker-B。 2）Dynamic Broker-Cluster部署 在activemq.xml文件中不直接指定Broker需要建立桥连接的其他Broker，由activemq在启动后动态查找： 1、 首先在Broker-A节点中添加networkConnector节点： 123456 &lt;networkConnectoruri=&quot;multicast://default&quot; dynamicOnly=&quot;true&quot; networkTTL=&quot;3&quot; prefetchSize=&quot;1&quot; decreaseNetworkConsumerPriority=&quot;true&quot; /&gt;&lt;/networkConnectors&gt; 2、修改Broker-A节点中的服务提供端口为61616： 12 &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61616? &quot; discoveryUri=&quot;multicast://default&quot;/&gt;&lt;/transportConnectors&gt; 3、在Broker-B节点中添加networkConnector节点： 123456 &lt;networkConnectoruri=&quot;multicast://default&quot; dynamicOnly=&quot;true&quot; networkTTL=&quot;3&quot; prefetchSize=&quot;1&quot; decreaseNetworkConsumerPriority=&quot;true&quot; /&gt;&lt;/networkConnectors&gt; 4、修改Broker-B节点中的服务提供端口为61617： 12 &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61617&quot; discoveryUri=&quot;multicast://default&quot;/&gt;&lt;/transportConnectors&gt; 5、启动Broker-A和Broker-B Master-Slave与Broker-Cluster相结合的部署方式 可以看到Master-Slave的部署方式虽然解决了高可用的问题，但不支持负载均衡，Broker-Cluster解决了负载均衡，但当其中一个Broker突然宕掉的话，那么存在于该Broker上处于Pending状态的message将会丢失，无法达到高可用的目的。 由于目前ActiveMQ官网上并没有一个明确的将两种部署方式相结合的部署方案，所以我尝试者把两者结合起来部署： 1、部署的配置修改 这里以Broker-A + Broker-B建立cluster，Broker-C作为Broker-B的slave为例： 1）首先在Broker-A节点中添加networkConnector节点： 12345&lt;networkConnectors&gt; &lt;networkConnector uri=&quot;masterslave:(tcp://0.0.0.0:61617,tcp:// 0.0.0.0:61618)&quot; duplex=&quot;false&quot;/&gt;&lt;/networkConnectors&gt; 2）修改Broker-A节点中的服务提供端口为61616： 12345&lt;transportConnectors&gt; &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61616?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;/transportConnectors&gt; 3）在Broker-B节点中添加networkConnector节点： 12345&lt;networkConnectors&gt; &lt;networkConnector uri=&quot;static:(tcp:// 0.0.0.0:61616)&quot;duplex=&quot;false&quot;/&gt;&lt;/networkConnectors&gt; 4）修改Broker-B节点中的服务提供端口为61617： 12345&lt;transportConnectors&gt; &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61617?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;/transportConnectors&gt; 5）修改Broker-B节点中的持久化方式： 12345&lt;persistenceAdapter&gt; &lt;kahaDB directory=&quot;/localhost/kahadb&quot;/&gt; &lt;/persistenceAdapter&gt; 6）在Broker-C节点中添加networkConnector节点： 12345&lt;networkConnectors&gt; &lt;networkConnector uri=&quot;static:(tcp:// 0.0.0.0:61616)&quot;duplex=&quot;false&quot;/&gt;&lt;/networkConnectors&gt; 7）修改Broker-C节点中的服务提供端口为61618： 12345&lt;transportConnectors&gt; &lt;transportConnectorname=&quot;openwire&quot;uri=&quot;tcp://0.0.0.0:61618?maximumConnections=1000&amp;amp;wireFormat.maxFrameSize=104857600&quot;/&gt;&lt;/transportConnectors&gt; 8）修改Broker-B节点中的持久化方式： 12345&lt;persistenceAdapter&gt; &lt;kahaDB directory=&quot;/localhost/kahadb&quot;/&gt; &lt;/persistenceAdapter&gt; 9）分别启动broker-A、broker-B、broker-C，因为是broker-B先启动，所以“/localhost/kahadb”目录被lock住，broker-C将一直处于挂起状态，当人为停掉broker-B之后，broker-C将获取目录“/localhost/kahadb”的控制权，重新与broker-A组成cluster提供服务。","categories":[{"name":"分布式","slug":"分布式","permalink":"https://bobit.github.io/categories/分布式/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://bobit.github.io/tags/MQ/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://bobit.github.io/tags/ActiveMQ/"}]},{"title":"坐月子可以吃什么水果","slug":"Life/坐月子可以吃什么水果","date":"2015-12-15T02:38:14.000Z","updated":"2018-12-21T13:33:56.173Z","comments":true,"path":"posts/8d1d0ebf.html","link":"","permalink":"https://bobit.github.io/posts/8d1d0ebf.html","excerpt":"","text":"1.奇异果 又称弥猴桃，味甘性冷，维生素C含量极高，有解热、止渴、利尿、通乳的功效，常食可强化免疫系统。对于剖腹产术后恢复有利。因其性冷，食用前用热水烫温。每日一个为宜。 常食可强化免疫系统。对于剖腹产术后恢复有利 2.榴连 味甘性热，盛产于东南亚，有水果之王的美誉。因其性热，能壮阳助火，对促进体温、加强血液循环有良好的作用。产后虚寒，不妨以此为补品。 榴连性热，不易消化，多吃易上火。与山竹伴食，即可平定其热性。同时，剖腹产后易有小肠粘黏的产妇谨食。 3.苹果 苹果味甘凉，性温，主要为碳水化物。含有丰富的苹果酸、鞣酸、维生素、果胶及矿物质，可预防和治疗坏血病、癞皮病，使皮肤润滑、光泽。其粘胶和细纤维能吸附并消除细菌和毒素，能涩肠、健胃、生津、开胃和解暑，尤其对治疗产妇腹泻效果更佳。苹果还能降低血糖及胆固醇，有利于患妊娠高血压综合症、糖尿病及肝功能不良产妇的产后恢复。此外苹果中含大量钾盐，能与体内过剩的钠盐结合并排出体外，故低钾及摄盐过多者食用苹果是有益的。 4.木瓜 ​ 木瓜的功效很多，降压、解毒、消肿驱虫，帮助乳汁分泌 味甘性平。木瓜的功效很多，降压、解毒、消肿驱虫，帮助乳汁分泌，让胸部更丰满、消脂减肥等。 木瓜的营养成分主要有糖类、膳食纤维、蛋白质、维生素B、C、钙、钾、铁等，产于我国南方。 我国自古就有用木瓜来催乳的传统。木瓜中含有一种木瓜素，有高度分解蛋白质的能力，鱼肉、蛋品等食物在极短时间内便可被它分解成人体很容易吸收的养分，直接刺激母体乳腺的分泌。 同时，木瓜自身的营养成分较高，故又称木瓜为乳瓜。产妇产后乳汁稀少或乳汁不下，均可用木瓜与鱼同炖后食用。 5.橄榄 ​ 孕妇及哺乳期妇女常食橄榄，可使宝宝更聪明 味甘，略酸涩，性平。有清热解毒、生津止渴之效。孕妇及哺乳期妇女常食橄榄，可使宝宝更聪明。 6.葡萄 味甘酸，性平。有补气血、强筋骨、利小便的功效。因其含铁量较高，所以可补血。制成葡萄干干后，铁占比例更大，可当作补铁食品，常食可消除困倦乏力、形体消瘦等症状，是健体延年的佳品品。妇女产后失血过多，可以葡萄作为补血圣品。 7.菠萝 味甘酸，性平。产于广东、广西一带。有生津止渴、助消化、止泻、利尿的功效。富含维生素B1，可以消除疲劳、增进食欲，有益于产妇产后恢复。 8.香蕉 味甘、性寒。有清热、润肠的功效。产后食用香蕉，可使人心情舒畅安静，有催眠作用，甚至 使疼痛感下降。香蕉中含有大量的纤维素和铁质，有通便补血的作用。可有效防止因产妇卧床休息时间过长，胃肠蠕动较差而造成的便秘。 ​ 因其性寒，每日不可多食，食用前先用热水浸烫。 9.龙眼 又称桂圆，味甘性温，产于两广等地。龙眼益心脾、补气血、安精神，是名贵的补品。产后体质虚弱的人，适当吃些新鲜的桂圆或干燥的龙眼肉，既能补脾胃之气，又能补心血不足。 将龙眼肉与蛋花同煮后喝汤，对于产后调养效果极好。 ​ 山楂有散瘀活血作用，能排出子宫内的瘀血，减轻腹痛 10.山楂 味甘酸，性温。山楂含大量碳水化物、维生素及钙、磷、铁等，其中钙含量为诸果之冠。还含有山楂酸、柠檬酸、苹果酸、果糖及黄酮类，有散瘀消积、化痰解毒、提神清脑、止血清胃和增进食欲的作用，能降低血压及血胆固醇的含量。产妇生孩子后过度劳累，往往食欲不振、口干舌燥、饭量减少，如果适当吃些山楂，能够增进食欲、帮助消化。 另外，山楂有散瘀活血作用，能排出子宫内的瘀血，减轻腹痛。","categories":[{"name":"Life","slug":"Life","permalink":"https://bobit.github.io/categories/Life/"}],"tags":[{"name":"life","slug":"life","permalink":"https://bobit.github.io/tags/life/"}]},{"title":"判断车距","slug":"Life/判断车距","date":"2015-12-15T01:38:13.000Z","updated":"2018-12-21T13:33:52.928Z","comments":true,"path":"posts/b8467e52.html","link":"","permalink":"https://bobit.github.io/posts/b8467e52.html","excerpt":"","text":"判断车距： 1、车影占后视镜的全部，车距为3米。 2、车影占后视镜的2/3，车距为5米。 3、车影占后视镜的1/2，车距为9米。 4、车影占后视镜的1/3，车距为12米。 5、前挡风玻璃下沿，看到前车后保险杠的上沿，车距为1米。 6、前挡风玻璃下沿，看到前车后保险杠的下沿，车距为2米。 7、前挡风玻璃下沿，看到前车后轮胎的下沿，车距为3米。 8、前方停止线和左前门角5CM处对正，刚好不越线。 9、前挡风玻璃下沿，看到前方行人小腿中部，正面距人约2.5米。 10、前挡风玻璃下沿，看到前方行人膝盖上，正面距人约1米。 11、前挡风玻璃左下角，看到行人臂部，侧面距人约0.3米。 12、前挡风玻璃右下角，看到行人臂部，侧面距人约0.5米。 13、前挡风玻璃左下角，看到行人膝盖下，侧面距人约0.7米。 注意事项： 1、倒车时，左侧中窗下沿看到他车车轮中心时，左侧面距左车约0.8米。 2、倒车时，右侧中窗竖后中间，看到他车车轮中心时，右侧面距左车约1米。 3、倒车时，后视镜看到后轮胎上保险杠后端与停车线对齐时，本车后部距离停车线约0.2米。 可以车不启动，直接挂倒档显示倒车影像图像，然后倒车后看大概距离就好，关键是倒车影像要带有倒车标尺线的比较好看大概距离。","categories":[{"name":"Life","slug":"Life","permalink":"https://bobit.github.io/categories/Life/"}],"tags":[{"name":"life","slug":"life","permalink":"https://bobit.github.io/tags/life/"},{"name":"car","slug":"car","permalink":"https://bobit.github.io/tags/car/"}]},{"title":"驾车好习惯，终身受用","slug":"Life/驾车好习惯 终身受用","date":"2015-12-14T23:38:19.000Z","updated":"2018-12-21T13:34:08.674Z","comments":true,"path":"posts/f2686f9c.html","link":"","permalink":"https://bobit.github.io/posts/f2686f9c.html","excerpt":"","text":"1、加油的时候别加满了，40升的油箱加个35就行了，估计跑的公里数差不多，在航空领域这个现象叫“油耗油”，别白浪费钱，还污染环境。 2、正常行驶时，前车突然并线给你让路，绝对没好事，咱们现在的司机还没这个觉悟，千万别给油超车，最好马上松油预备刹车，同时迅速观察两侧后视镜，判断出如果要并线往哪边并，八成前面有情况。 3、堵车或等灯的时候别跟的太近，除非有人想加塞，至少要留出可以一把掰出去的距离，以防前车故障，自己也被加在中间。这是一个老司机告诉我的，当年他就这样陪着前车呆了半个小时。 4、排队时，为了防止别人加塞，在加塞来车一侧，多留半个车身。比如你在左转道排队，经常有人从直行道过来加塞，你尽量用右轮压着左转道的右边线开，给自己向左迂回留出余地，再跟紧前车，加塞的很难得逞。 5、当你从后视镜里看别的车有点费劲的时候，也就是你该开灯的时候了，不是为了看清道路，而是为了让别人看见你，尤其是白天下雨的时候！如果你愿意，时速超过100的时候也应该开灯，反正我是这么做的。 6、停车的时候，尽量将你的车头朝外，一个是走的时候方便，另外一个重要的功能就是防盗，虽然这不是灵丹妙药，但是如果我是贼，只有偷一辆车的机会时，我偷车头朝里的。 7、开车并线的原则是，不要让后车踩刹车，这也是你作为行人过马路的原则，如果你让他为了避让你而踩刹车的话，他就有可能踩到油门上！ 8、过路口的时候一定一定要减速，不管他是不是绿灯，至少不能再加油了，尤其是没有交通灯的路口，在咱们国家，很多人是不珍惜生命的，别跟他们较劲。 9、即便你是新手，也不要在高速公路上开的很慢，在路况较好的非高速公路也一样，经常看到很多大车为了超过一辆只有40公里/小时的轿车时而强行并线，险象环生！大货车从起步到开起来非常的吃力，所以货车司机很不爱踩刹车，他宁愿并线超车也不原减速到3档再花10分钟加到5档。 10、以我看来开车最危险的敌人不是开快车，而是分神！开快车的时候往往聚精会神，如果没有突发事件，一般不会出事，我不是在鼓吹开快车，10次事故9次快，一旦出事就有生命危险的，最好是中速行驶！我几次吓出汗来的时候，都是在我走神的时候发生的，记得一次手机想了，我低头想看一下谁的电话，等看清楚了打开接听时，一抬头，前车火红的刹车灯是如此的刺眼，最近的一次了，千万别走神。 11、在人车混行的道路上，尽量离路边的自行车和行人远点，向路的中间靠，如果你没把握，不要紧别害怕，因为对面的来车会躲你，而行人和自行车是背对你的，不但不能躲你，说不定还会向你晃动，得给他们留出余地！ 12、晚上行车的时候，不要用远光晃前方的行人和自行车，他们不懂的，不会给你让路的，你这么做只能使对面的车辆花了眼，不如直接的鸣笛。我经常能看到很多司机徒劳的用灯晃着行人，结果就是招来对面车辆刺眼的远光。 13、下雨之后，走在你不熟悉的路段时，见到积水的坑，一定要减速，因为你不知道它有多深，最好是尾随一辆车，有一次我就是在路边停了一下，让后面的一辆超了过去给趟路的，并不耽误时间。 14、如果在高速公路上遇到水洼，尽量躲开，千万别想看到水花四溅的壮观。如果躲不开，就尽量2个前轮一起压水，尽管高速上的水洼一般不会很深，但如果一边的轮子压上，会瞬时失去抓地力，如果速度很快，就会横甩出去，甚至翻车。 15、如果你的车上坐了3个人以上，就别开的太快了，一是咱们的车排量小，人多了车就没劲了，提速会打很大的折扣，最重要的是咱们的刹车会变的比较迟钝，距离会明显的加长，刹车的时机和力度都要比平时来的早和狠。 16、大家经常遇到赶灯的时候，如果你前面还有一辆车，那就算了，谁知道他会不会发什么神经停在线上，这样的事太多了，别跟的太近了，如果你是第一辆，那就别犹豫，冲过去，别加了半天的速，最后心虚了，一脚停在那里，后面来个追尾，虽然不是你责任，可是多别扭啊！ 17、停车超过3个小时后，再起步，一定要热车，无论春夏秋冬，这里的热车不是指水温，而是热你的润滑系统，至于水温，可以边开边热。 18、停车后，车里别放什么东西，别以为不放钱包，电脑包就行了，就是半条烟，也可能搭上你的挡风玻璃！ 19、有几个不能超车的原则要注意，拐弯的时候不能超，前方有路口的时候不能超，红灯变绿灯起步时，在没有完全通过路口时不要超，如果你想快点，就稍微往前探点，把路口的所有情况都看到，这时可以超。 20、遇到大公共靠边进站，千万别高兴，以为它给你让了路，一定要减速，经常会有人从公共的前头跑出来，你可以通过观察大公共的车底有没有行人的腿脚或影子来判断。","categories":[{"name":"Life","slug":"Life","permalink":"https://bobit.github.io/categories/Life/"}],"tags":[{"name":"life","slug":"life","permalink":"https://bobit.github.io/tags/life/"},{"name":"car","slug":"car","permalink":"https://bobit.github.io/tags/car/"}]},{"title":"科学合理“坐月子”的10条建议","slug":"Life/科学合理“坐月子”的10条建议","date":"2015-12-14T23:38:18.000Z","updated":"2018-12-21T13:34:05.804Z","comments":true,"path":"posts/d3d0aa5.html","link":"","permalink":"https://bobit.github.io/posts/d3d0aa5.html","excerpt":"","text":"适宜的室内环境。产妇和宝宝的居室要安静、整洁、光线充足、温度与湿度适中，有较好的通风。夏日温度高时，要注意降温防中暑，冬天气候寒冷时，要注意保暖防凉。 保持安静。产妇与宝宝休息时，卧室要保持安静，避免噪音，以免突然的响声，引起婴儿不自主的反射动作。 保持空气流通。产妇“坐月子”期间最忌讳空气不流通。比如门窗紧闭、裹头扎腿，导致室内空气混浊，容易让产妇及婴儿患病。冬天可以每天定时开窗通风，每次半小时左右，避免过堂风、直流风，或者开窗通风时，产妇和婴儿可以到另一个房间。 坐月子不等于卧床一月。产后第一天孕妇应保证充足的睡眠和休息，剖宫产的产妇在24小时候就可以起床做轻微的活动，这有利于加速血液循环，促进肠道蠕动，使大小便通畅。 衣着干净舒适。产后产妇新陈代谢旺盛，汗多恶露多，乳汁常溢出沾染衣物，容易引起细菌繁殖，引发多种感染，因此产妇的衣物要勤洗勤换，太阳下晾晒杀菌，以防疾病。 正常刷牙。月子里也要健康刷牙、漱口。产后牙龈娇嫩，建议用软毛质地的牙刷，避免冷水刺激，应用温水刷牙、漱口。动作要轻柔，避免损伤牙龈。 正常洗头。月子里适当的洗头和梳头对身体有好处。洗头水温适宜，在37℃左右，洗完后及时擦干或用吹风机吹干，避免被凉气吹。头发未干之前，不能立刻入睡，会导致湿邪入侵袭导致头疼、颈部不适。 正常洗澡。产后24小时后可以擦拭身体局部。产后1周可以淋浴。避免坐浴。控制好合理的水温，调整好浴室内的温度，把握好洗澡时间，可不太长，10分钟左右为宜。注意未愈合的会阴及腹部伤口处不要沾水。 饮食适度。饮食可以少量多餐，食物干稀搭配，荤素搭配，清淡为宜。 保持愉悦心情。产后身体内分泌激素变化较大，容易影响产妇情绪，应注意保持开朗情绪，避免烦心事。","categories":[{"name":"Life","slug":"Life","permalink":"https://bobit.github.io/categories/Life/"}],"tags":[{"name":"life","slug":"life","permalink":"https://bobit.github.io/tags/life/"}]},{"title":"汽车暴晒后如何降温","slug":"Life/汽车暴晒后如何降温","date":"2015-12-14T23:38:17.000Z","updated":"2018-12-21T13:34:03.511Z","comments":true,"path":"posts/8bc2c726.html","link":"","permalink":"https://bobit.github.io/posts/8bc2c726.html","excerpt":"","text":"汽车暴晒后如何降温 1．在高温天，车主停完车后可以将车窗留出1厘米左右的缝隙，这样有助于内外气流流通，不让车内温度过高。 2．汽车在高温下暴晒一段时间后，车内温度会超过室外气温，此时开车的话，可以先开窗透气，然后再开空调，将空调调至吹脚状态，这样利用冷气比热气重的原理将热气排出，有利于迅速降温。 车内凉快下来后，为了保持制冷效果，可切换至内循环，但不能长时间开内循环，因为长时间使用车内空气会使车内含氧量下降，容易造成司机疲惫，严重的甚至可能导致中毒。 注意事项: 千万别在车内睡觉 别把打火机放在车内 当心香水成隐形炸弹 高温天让轮胎多“歇歇”","categories":[{"name":"Life","slug":"Life","permalink":"https://bobit.github.io/categories/Life/"}],"tags":[{"name":"life","slug":"life","permalink":"https://bobit.github.io/tags/life/"}]},{"title":"汽车上高速前检查事项","slug":"Life/汽车上高速前检查事项","date":"2015-12-14T23:38:16.000Z","updated":"2018-12-21T13:34:01.295Z","comments":true,"path":"posts/ba488b1b.html","link":"","permalink":"https://bobit.github.io/posts/ba488b1b.html","excerpt":"","text":"轮胎 这是当属第一位要检查的部位，汽车的轮胎就像人的双腿，腿坏了，他还能走路么？ 仔细查看每条轮胎的外观，是否有划伤。如果只是橡胶划伤不影响使用，但是如果伤到里面的轮胎线，就必须更换新胎。如果超过两年轮胎没有动过，最好把前轮的两条轮胎和后轮的轮胎进行交换。仔细检查4个轮胎的一致性，开在平坦的路上，不扶方向盘，看能否走直线，否则赶紧去做下四轮定位。 1、检查胎纹；一般轮胎胎纹深度小于2mm时，就不能用于跑长途了。 2、测胎压；一般汽车胎压在2.5个压就可以了，不要过高或过低。 3、检查备胎；确认备胎完好，并需要确认备胎胎压是否达标。 机油 把车放在平坦的地方，待车凉后拔掉机油尺，用擦布擦干净再插进去，插到底后拔出来查看，机油位在油尺刻度最小上限/最大上限范围内即可，不可越过刻度区间。 需要考虑你的目的地当地的气候，如果冬天去东北，就要考虑机油的黏度，可以咨询当地维修点是否需要更换 防冻液/玻璃水 防冻液可以防止汽车在寒冷冬季停车时冷却液结冰膨胀，导致散热器和发动机气缸冻裂。防冻液全年都要使用的哦。 和检查机油的方法类似，防冻液的刻度一般在箱体上，确认防冻液液面在刻度的范围内即可。 跑高速玻璃水离不了，特别是遇到雨雪天气，所以出行前最好将玻璃水注满以备用。 灯光 包括行车灯、倒车灯、刹车灯、转向灯、车内灯、雾灯等，特别是雾灯，如果有问题，需要马上更换。一个旅途下来，遇到的天气可能变换几样，恶劣天气下，灯光的作用特别重要，平时使用中如果有灯泡损坏的，最好及时更换维修。 刹车 看看刹车片厚度，如果感觉太薄（小于2mm）就需要更换了。 正常速度行驶，踩刹车试试有没有什么异常。将车停到坡道上，看看手刹是否有作用。 电瓶 很多车友平时都不太注意对电瓶的检查与保养，其实电瓶却是汽车电子控制系统的心脏。 电瓶也有使用年限，如果使用期限大于3年的，目的地气候比较寒冷的，跑长途前一定要注意检查一下，另外最好随车带两根电瓶线，以备不时之需。 有的汽车电瓶上有个观察孔，电瓶灯是白色的则说明需要充电，如果电瓶灯是黑色则表示要更换电瓶了。没有观察孔的，就在熄火状态测量电瓶电压，大于12V就没问题。没有测量工具的可以根据车子启动是否顺畅，大灯灯光是否够亮来判断。 整车 检查玻璃是否有裂痕，车门开关是否异常，仪表盘是否正常工作，空调制冷制热功能，反光镜位置，喇叭，导航，转向，雨刷等等。这些也都是日常需要注意的地方。 工具 车内必备的一些自救工具：千斤顶，6mm~19mm扳手/套筒，一字/十字螺丝刀，破窗工具，牵引带等 车上必备的一些应急装备：三角警示牌、灭火器、警示灯等 行车必备的证件：驾照、行驶证、保险单等","categories":[{"name":"Life","slug":"Life","permalink":"https://bobit.github.io/categories/Life/"}],"tags":[{"name":"life","slug":"life","permalink":"https://bobit.github.io/tags/life/"}]},{"title":"MySQL数据库性能优化总结","slug":"性能优化/MySQL数据库性能优化总结","date":"2015-11-13T04:19:35.000Z","updated":"2018-12-21T12:57:38.175Z","comments":true,"path":"posts/56ddf855.html","link":"","permalink":"https://bobit.github.io/posts/56ddf855.html","excerpt":"","text":"模型的设计 MySQL数据库,性能是设计出来的，不是后期调出来的。在模型的设计上我想说下自己的一个观点： 要做模型的测试，我们往往通过界面原型对数据库进行了设计，保证了数据库设计的完整性，但模型是否合理，是否要冗余，性能是否够好，我们无法识别。这些问题都要去通过业务去验证，而业务是靠什么体现呢？是靠SQL语句。 模型测试 如何做模型测试呢？对照着界面原型，把主要功能的SQL语句写出来，如果SQL写不出来，或是非常复杂，就要考虑调整模型；再制造一些数据进行性能测试。 关系型数据库性能优化总结 对于web应用开发，多数性能瓶颈均出现在数据库上，除了采用分布式架构或云处理（大公司基本上都是），更重要的是平时程序设计时要遵照一些规则，从根本上提高系统的性能，以下总结了一些常用的规则方法，仅供参考，欢迎补充… 1、 把数据、日志、索引放到不同的I/O设备上，增加读取速度。数据量（尺寸）越大，提高I/O越重要。 2、 纵向、横向分割表，减少表的尺寸，如：可以把大数据量的字段拆分表。 3、 根据查询条件，建立索引，优化索引、优化访问方式，限制结果集的数据量。注意填充因子要适当（最好是使用默认值0）。索引应该尽量小，尽量使用字节数小的列建索引，不要对有限的几个值的列建单一索引。 4、 用OR的字句可以分解成多个查询，并且通过UNION链接多个查询。它们的速度只与是否使用索引有关，如果查询需要用到联合索引，用UNION all执行的效率更高。 5、 在查询SELECT语句中用WHERE子句限制返回的行数，避免表扫描。如果返回不必要的数据，则浪费了服务器的I/O资源，加重了网络的负担，降低了性能。如果表很大，在表扫描期间将表锁住，禁止其他的联结访问表，后果很严重。 6、 注意使用 DISTINCT ，在没有必要时不要用，它同UNION一样会使查询变慢。 7、 在IN后面值的列表中，将出现最频繁的值放在最前面，出现最少的放在最后面，减少判断的次数。 8、 一般在GROUP BY和HAVING子句之前就能剔除多余的行，所以尽量不要用它们来做剔除行的工作，也就是说尽可能在WHERE中过滤数据。 9、 尽量将数据的处理工作放在服务器上，减少网络的开销，如使用存储过程。存储过程是编译、优化过，并且被组织到一个执行规划里，且存储在数据库中的SQL语句（存储过程是数据库服务器端的一段程序），是控制流语言的集合，速度当然快。 10、不要在一句话里再三地使用相同的函数，浪费资源，将结果放在变量里再调用更快。 11、针对大量只读查询操作进行优化的方法： 1)数据量小的数据，可以考虑不存储在数据库中，而是通过程序常量的方式解决。 2)需要存储在数据库中的数据，可以考虑采用物化视图（索引视图）。当DBA在视图上创建索引时，这个视图就被物化（执行）了，并且结果集被永久地保存在唯一索引中，保存方式与一个有聚簇索引的表的保存方式相同。物化视图减除了为引用视图的查询动态建立结果集的开销，优化人员可以在查询中使用视图索引，而不需要在FROM子句中直接指定视图。 3)数据存储时可以考虑适当的数据冗余，以减少数据库表之间的链接操作，提高查询效率。 4)针对数据的特点，采取特定的索引类型。例如，位图索引等。 12、对于SQL语句书写时的一些建议： 1)写语句时能够确定数据库对象所有者的，尽可能把所有者带上，如： SELECT * FROM dbo.Users 2)存储过程中，参数定义最好放在最前面，尽可能一次定义，如： DECLARE @USER_ID INT ,@USER_NAME VARCHAR(50) ,@PASSWORD VARCHAR(50) 3)为参数赋值时，尽可能一次赋值，如： SELECT @USER_ID = 1001 ,@USER_NAME = ‘xiaojun.liu’ 4)尽量少用游标","categories":[{"name":"性能优化","slug":"性能优化","permalink":"https://bobit.github.io/categories/性能优化/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://bobit.github.io/tags/数据库/"},{"name":"性能优化","slug":"性能优化","permalink":"https://bobit.github.io/tags/性能优化/"}]},{"title":"Postman使用方法详解","slug":"Setting/Postman","date":"2015-11-13T03:16:35.000Z","updated":"2018-12-21T13:34:27.980Z","comments":true,"path":"posts/7bfeb391.html","link":"","permalink":"https://bobit.github.io/posts/7bfeb391.html","excerpt":"","text":"下载 摘要 : Postman是一款功能强大的网页调试与发送网页HTTP请求的Chrome插件。 插件大小：5.88MiB插件版本：4.1.3支持语言：English 下载完应该得到的是扩展名为crx的文件。 比如： Postman-REST-Client_v0.8.4.14.crx 安装 打开chrome浏览器，点击右上角“自定义及控制”按钮 -》 （更多）“工具” -》“扩展程序”。 直接把下载好的XXXXX.crx插件拖到chrome的扩展管理界面中，然后中间会出现“拖动以安装”的插件按钮，然后就安装。 如果出现提示说这个插件必须要在应用商店里面装 重命名crx文件，把后缀改成zip或者rar，比如：Postman-REST-Client_v0.8.4.14.zip。 然后解压，解压到的文件夹为： Postman-REST-Client_v0.8.4.14 接着回来刚才的扩展程序管理界面 先勾选右上角的“开发者模式”，这个时候左上角会出现下图所示的东西： 然后，点击左上角的“加载正在开发的扩展程序…”，打开刚才解压好的文件夹，就可以安装了。 如提示“_metadata”有问题之类的话，那就打开刚才解压好的文件夹（Postman-REST-Client_v0.8.4.14） 将里面的“_metadata”文件夹重命名为“metadata”，其实就是把前面的下划线去掉。 再重复操作，应该就可以了。 使用 Postman可以发送几乎所有类型的HTTP请求！。 用户的大部分数据都需要通过HTTP请求来与服务器进行交互。 Postman插件就充当着这种交互方式的“桥梁”，它可以利用Chrome插件的形式把各种模拟用户HTTP请求的数据发送到服务器，以便开发人员能够及时地作出正确的响应。 在Chrome中安装了Postman插件以后，发送HTTP数据的时候只需要编写相关测试数据的时候加入一定量的参数信息即可。 Get请求 在地址栏里输入请求url：http://localhost:9998/api/user 选择“GET”方式， 点击&quot;Url params&quot;,添加url params key:id , value:1 点击“send”得到json数据如下： Post请求 在地址栏里输入请求url：http://localhost:9998/api/user/1 选择“POST”方式， 点击&quot;application/x-www-form-urlencoded&quot;, 添加key:name , value:baidu-lulee007 添加key:sex , value:man 注意 请求支不支持post请求是由服务端决定 如果服务端需要请求类型为json，需要在“headers”添加 key:Content-Type , value:application/json 选择“raw”,并添加： { “id”: 1, “data”: { “name”: “baidu-lulee007”, “sex”: “man” } } form-data: 就是http请求中的multipart/form-data,它会将表单的数据处理为一条消息，以标签为单元，用分隔符分开。既可以上传键值对，也可以上传文件。当上传的字段是文件时，会有Content-Type来表名文件类型；content-disposition，用来说明字段的一些信息； 由于有boundary隔离，所以multipart/form-data既可以上传文件，也可以上传键值对，它采用了键值对的方式，所以可以上传多个文件。 x-www-form-urlencoded： 就是application/x-www-from-urlencoded,会将表单内的数据转换为键值对，比如,name=java&amp;age = 23 raw 可以上传任意格式的文本，可以上传text、json、xml、html等 binary 相当于Content-Type:application/octet-stream,从字面意思得知，只可以上传二进制数据，通常用来上传文件，由于没有键值，所以，一次只能上传一个文件。 multipart/form-data与x-www-form-urlencoded区别 multipart/form-data：既可以上传文件等二进制数据，也可以上传表单键值对，只是最后会转化为一条信息； x-www-form-urlencoded：只能上传键值对，并且键值对都是间隔分开的。","categories":[{"name":"Tools","slug":"Tools","permalink":"https://bobit.github.io/categories/Tools/"}],"tags":[{"name":"Postman","slug":"Postman","permalink":"https://bobit.github.io/tags/Postman/"}]},{"title":"Hexo 输入数学公式","slug":"Setting/Hexo 输入数学公式","date":"2015-11-13T03:14:35.000Z","updated":"2018-12-21T13:34:22.930Z","comments":true,"path":"posts/79274bb6.html","link":"","permalink":"https://bobit.github.io/posts/79274bb6.html","excerpt":"","text":"Hexo 输入数学公式主要通过MathJax 渲染LaTeX 公式实现的，具体开启步骤以及简要语法介绍如下。 安装配置 在next 主题配置文件_config.yaml 中找到 MathJax 选项，将enable 改成 true 即可： 12345MathJax Supportmathjax: enable: true per_page: false cdn: //cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML 页面插入 页面插入公式有两种形式，一是行内插入公式不居中显示： 1$公式$ 例如 E=mc2E=mc^2E=mc2 第二种是行间插入公式，居中显示： 1$$公式$$ 例如： S=π∗r2S=\\pi*r^2S=π∗r2 语法公式 关于公式的语法格式，主要有以下常用： 上下标 ^ 表示上标，_ 表示下标。 1234$$a_&#123;1&#125; x^&#123;2&#125; $$$$e^&#123;-\\alpha t&#125; $$$$a^&#123;i&#125;_&#123;ij&#125;$$$$e^&#123;x^2&#125; \\neq &#123;e^x&#125;^2$$ a1a_{1} a1​ x2x^{2} x2 e−αte^{-\\alpha t} e−αt aijia^{i}_{ij} aiji​ ex2≠ex2e{x2} \\neq {ex}2 ex2≠ex2 此外，如果左右两边都有上下标，则使用 \\sideset 命令，效果如下： 1\\sideset&#123;^xy&#125;&#123;^xy&#125;\\bigotimes \\sideset{xy}{xy}\\bigotimes 平方根 平方根输入命令为 \\sqrt，n次方根命令为 \\sqrt[n]，其符号大小由LaTeX 自动给定： 1$$\\sqrt&#123;x&#125;$$ $$\\sqrt&#123;x^2+\\sqrt&#123;y&#125;$$ $$\\sqrt[3]&#123;2&#125;$$ x\\sqrt{x} x​ x2+y\\sqrt{x^2+\\sqrt{y}} x2+y​​ 23\\sqrt[3]{2} 32​ 水平线 使用 \\overline 和 \\underline 分别在表达式上下方画出水平线： 12$$\\overline&#123;m + n&#125;$$$$\\underline&#123;m + n&#125;$$ m+n‾\\overline{m + n} m+n​ m+n‾\\underline{m + n} m+n​ 水平大括号 命令 \\overbrace 和 \\underrace，效果如下： 12$$\\underbrace&#123;a+b+\\cdots+z&#125;$$$$\\overbrace&#123;a+b+\\cdots+z&#125;$$ a+b+⋯+z⏞\\overbrace{a+b+\\cdots+z} a+b+⋯+z​ a+b+⋯+z⎵\\underbrace{a+b+\\cdots+z} a+b+⋯+z​ 矢量 矢量的命令是 \\vec，用于单个字母的向量表示。\\overrightarrow 和\\overleftarrow 分别表示向右和向左的向量箭头： 123$$\\vec&#123;a&#125;$$$$\\overrightarrow&#123;AB&#125;$$$$\\overleftarrow&#123;BA&#125;$$ a⃗\\vec{a} a AB→\\overrightarrow{AB} AB BA←\\overleftarrow{BA} BA 分数 分数使用 \\frac{…}{…} 进行排版： 123$$1\\frac&#123;1&#125;&#123;2&#125;$$$$\\frac&#123;x^2&#125;&#123;k+1&#125;$$$$x^&#123;1/2&#125;$$ 1121\\frac{1}{2} 121​ x2k+1\\frac{x^2}{k+1} k+1x2​ x1/2x^{1/2} x1/2 积分运算符 积分运算符使用 \\int 生成。求和运算符使用 \\sum 生成。乘积运算符使用 \\prod 生成。上下限使用^ 和_ 命令，类似 上下标： 123$$\\sum_&#123;i=1&#125;^&#123;n&#125;$$$$\\int_&#123;0&#125;^&#123;\\frac&#123;\\pi&#125;&#123;2&#125;&#125;$$$$\\prod_\\epsilon$$ ∑i=1n\\sum_{i=1}^{n} i=1∑n​ ∫0π2\\int_{0}^{\\frac{\\pi}{2}} ∫02π​​ ∏ϵ\\prod_\\epsilon ϵ∏​ 希腊字母 α\\alphaα \\alpha β\\betaβ \\beta γ\\gammaγ \\gamma δ\\deltaδ \\delta ϵ\\epsilonϵ \\epsilon 字体转换 要对公式的某一部分字符进行字体转换，可以用{\\rm需转换的部分字符}命令，其中\\rm可以参照下表选择合适的字体。 一般情况下，公式默认为意大利体。 12345\\rm 罗马体 \\rm test \\it 意大利体 \\it test\\bf 黑体 \\bf test \\cal 花体 \\cal test\\sl 倾斜体 \\sl test \\sf 等线体 \\sf test\\mit 数学斜体 \\mit test \\tt 打字机字体 \\tt test\\sc 小体大写字母 \\sc test","categories":[{"name":"Tools","slug":"Tools","permalink":"https://bobit.github.io/categories/Tools/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://bobit.github.io/tags/Hexo/"}]},{"title":"静态博客选型之hexo","slug":"Setting/Hexo","date":"2015-11-13T03:13:35.000Z","updated":"2018-12-27T12:39:59.948Z","comments":true,"path":"posts/9406e9db.html","link":"","permalink":"https://bobit.github.io/posts/9406e9db.html","excerpt":"","text":"背景 给自己的学习和生活做个记录，在github上创建自己的开源博客，也希望自己能坚持写文_。从最开始的wordpress，到现在的hexo，网站变得越来越简单，越来越轻量级。 选型 hexo 参考 hexo官方文档：https://hexo.io/zh-cn/docs/ hexo介绍 主页： https://hexo.io/zh-cn/ 主页中有非常详细的介绍，这里主要说说主页中没有详细说明内容。 hexo 可以理解为是基于node.js制作的一个博客工具，不是我们理解的一个开源的博客系统。其中的差别，有点意思。 hexo 正常来说，不需要部署到我们的服务器上，我们的服务器上保存的，其实是基于在hexo通过markdown编写的文章，然后hexo帮我们生成静态的html页面，然后，将生成的html上传到我们的服务器。简而言之：hexo是个静态页面生成、上传的工具。 源码结构 文件/文件夹 说明 _config.yml 配置文件 public 生成的静态文件，这个目录最终会发布到服务器 scaffolds 一些通用的markdown模板 source 编写的markdown文件，_drafts草稿文件，_posts发布的文章 themes 博客的模板 常用命令 初始化 $ hexo init 生成静态页面 $ hexo generate 或者hexo g 本地启动 $ hexo server 或者hexo s 本地启动服务，在浏览器中输入http://localhost:4000/查看生成的页面效果。 恭喜你，到此你成功了！ 更换主题 hexo自己默认的主题landscape，个人推荐主题yilia $ git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia 修改配置文件 修改Blog/_config.yml文件： theme: yilia //默认为landscape 部署到github 部署之前先修改Blog/_config.yml文件。 deploy: ​ type: git ​ repository: https://github.com/bobit/bobit.github.io //bobit替换为你自己的用户名 ​ branch: master 然后使用以下命令进行部署。 123hexo cleanhexo generate 或者 hexo ghexo deploy 备注：如果执行上述命令报错，你可以试试下面这个命令再试。 $ npm install hexo-deployer-git --save Q2A Hexo中使用MathJax公式 安装插件 1npm install hexo-math --save 配置 1234567891011math: engine: &apos;mathjax&apos; # or &apos;katex&apos; mathjax: src: # &quot;//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot; config: # MathJax config katex: css: #custom_css_source js: #custom_js_source # not used config: # KaTeX config 由于有默认配置，所以src和config的内容为空。 文章中需要打开公式，文章的Front-matter里打开mathjax开关后成功激活： 1234567---title: Hexo中使用MathJax公式date: 2016-12-25 13:38:47tags: [Hexo,MathJax]categories: [Tools,Hexo]mathjax: true--- 存在问题 由于markdown中的下划线 _ 是表示斜体，MathJax中 _ 是表示下标，存在冲突| 解决这个问题： 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 文章链接唯一化 也许你会数次更改文章题目或者变更文章发布时间，在默认设置下，文章链接都会改变，不利于搜索引擎收录，也不利于分享。唯一永久链接才是更好的选择。 安装 1npm install hexo-abbrlink --save 在站点配置文件中查找代码permalink，将其更改为（“posts/” 与“.html”可自行更换）: 1permalink: posts/:abbrlink.html 这里有个知识点： 百度蜘蛛抓取网页的规则: 对于蜘蛛说网页权重越高、信用度越高抓取越频繁，例如网站的首页和内页。蜘蛛先抓取网站的首页，因为首页权重更高，并且大部分的链接都是指向首页。然后通过首页抓取网站的内页，并不是所有内页蜘蛛都会去抓取。 搜索引擎认为对于一般的中小型站点，3层足够承受所有的内容了，所以蜘蛛经常抓取的内容是前三层，而超过三层的内容蜘蛛认为那些内容并不重要，所以不经常爬取。出于这个原因所以permalink后面跟着的最好不要超过2个斜杠。 然后在站点配置文件中添加如下代码: 1234# abbrlink configabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hex 可选择模式： crc16 &amp; hex crc16 &amp; dec crc32 &amp; hex crc32 &amp; dec 使用hexo generate命令，所有之前写的md会自动生成 abbrlink: 9406e9db 属性。 hexo+github上传图片到博客 查看_config.yml文件 查找 post_asset_folder 字段确定post_asset_folder 设置为true。当设置参数后，在建立文件时，Hexo 会自动建立一个与文章同名的文件夹，您可以把与该文章相关的所有资源都放到此文件夹内，这样就可以更方便的使用资源。 到博客的根目录下执行 npm install https://github.com/CodeFalling/hexo-asset-image --save 命令来进行插件的安装。 然后创建一文章 hexo new “test” 然后查看博客的 …/source/_posts 目录下的文件，会看到存在一个test 文件夹 和 test.md 文件 如果使用Typora，偏好设置需要把图片插入设置为复制到指定路径：./${filename} 如果使用了abbrlink，图片路径需要相应修改为abbrlink生成的值。 添加评论 使用gitalk 附录 命令 12345678hexo new [layout] &lt;title&gt;hexo new &quot;postName&quot; #新建文章hexo new page &quot;pageName&quot; #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server）hexo deploy #将.deploy目录部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本","categories":[{"name":"Tools","slug":"Tools","permalink":"https://bobit.github.io/categories/Tools/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://bobit.github.io/tags/Hexo/"}]},{"title":"Groovy基础","slug":"Setting/Groovy","date":"2015-11-13T03:12:35.000Z","updated":"2018-12-21T13:34:17.500Z","comments":true,"path":"posts/b88033e6.html","link":"","permalink":"https://bobit.github.io/posts/b88033e6.html","excerpt":"","text":"Groovy Groovy 是用于Java虚拟机的一种敏捷的动态语言，它是一种成熟的面向对象编程语言，即可以用于面向对象编程，又可以用作纯粹的脚本语言。 使用该种语言不必编写过多的代码，同时又具有闭包和动态语言中的其他特性 Groovy 特点 动态语言:运行时检查数据的类型 基于JVM 扩展JDK: 对JDK中的类型进行扩展，封装方法调用简化开发 元编程： 注入、拦截、合并、委托方法、操作编译运行行为 高效的Groovy特性 assert语句 可选类型定义 可选的括号 字符串 Groovy 与java对比 Groovy 完全兼容Java的语法 分号是可选的 类、方法默认是public的 == 等同于equals(),不会有NullPointerExceptions异常 12345678910111213141516171819202122232425262728293031323334// 可选类型定义def version = 1// assertassert version == 2// 可选的括号println(version)println version//字符串def s1 = &apos;ctoedu&apos;def s2 = &quot;version is $&#123;version&#125;&quot;def s3 = &apos;&apos;&apos; projectnameisctoedu&apos;&apos;&apos;// 集合api//listdef buildTools=[&apos;ant&apos;,&apos;maven&apos;]buildTools &lt;&lt; &apos;gradle&apos;assert buildTools.getClass() == ArrayListassert buildTools.size() == 3//mapdef buildYears = [&apos;ant&apos;:2000, &apos;maven&apos;:2004]buildYears.gradle = 2009println buildYears.antprintln buildYears[&apos;gradle&apos;]println buildYears.getClass() 在Groovy中，很多东西都是可以省略的 语句后面的分号是可以省略的 变量的类型和方法的返回值也是可以省略的 方法调用时，括号也是可以省略的 甚至语句中的return都是可以省略的 在Groovy中，类型是弱化的，所有的类型都可以动态推断，但是Groovy仍然是强类型的语言，类型不匹配仍然会报错； Groovy的数据类型 在Groovy中，数据类型有： Java中的基本数据类型 Java中的对象 Closure（闭包） 加强的List、Map等集合类型 加强的File、Stream等IO类型 类型可以显示声明，也可以用 def 来声明，用 def 声明的类型Groovy将会进行类型推断。 基本数据类型和对象这里不再多说，和Java中的一致，只不过在Gradle中，对象默认的修饰符为public。下面主要说下String、闭包、集合和IO等。 String String的特色在于字符串的拼接，比如 def a = 1 def b = “hello” def c = “a=a,b={a}, b=a,b={b}” println c outputs: a=1, b=hello 闭包 Groovy中有一种特殊的类型，叫做Closure，翻译过来就是闭包，这是一种类似于C语言中函数指针的东西。闭包用起来非常方便，在Groovy中，闭包作为一种特殊的数据类型而存在，闭包可以作为方法的参数和返回值，也可以作为一个变量而存在。 如何声明闭包？ { parameters -&gt; code } 闭包可以有返回值和参数，当然也可以没有。下面是几个具体的例子： def closure = { int a, String b -&gt; println “a=a,b={a}, b=a,b={b}, I am a closure!” } // 这里省略了闭包的参数类型 def test = { a, b -&gt; println “a=a,b={a}, b=a,b={b}, I am a closure!” } def ryg = { a, b -&gt; a + b } closure(100, “renyugang”) test.call(100, 200) def c = ryg(100,200) println c 闭包可以当做函数一样使用，在上面的例子中，将会得到如下输出： a=100, b=renyugang, I am a closure! a=100, b=200, I am a closure! 300 另外，如果闭包不指定参数，那么它会有一个隐含的参数 it // 这里省略了闭包的参数类型 def test = { println “find ${it}, I am a closure!” } test(100) outputs: find 100, I am a closure! 闭包的一个难题是如何确定闭包的参数，尤其当我们调用Groovy的API时，这个时候没有其他办法，只有查询Groovy的文档： http://www.groovy-lang.org/api.html http://docs.groovy-lang.org/latest/html/groovy-jdk/index-all.html 下面会结合具体的例子来说明如何查文档。 List和Map Groovy加强了Java中的集合类，比如List、Map、Set等。 List的使用如下： def emptyList = [] def test = [100, “hello”, true] test[1] = “world” println test[0] println test[1] test &lt;&lt; 200 println test.size outputs: 100 world 4 List还有一种看起来很奇怪的操作符&lt;&lt;，其实这并没有什么大不了，左移位表示向List中添加新元素的意思，这一点从文档当也能查到。 其实Map也有左移操作，这如果不查文档，将会非常费解。 Map的使用如下： def emptyMap = [:] def test = [“id”:1, “name”:“renyugang”, “isMale”:true] test[“id”] = 2 test.id = 900 println test.id println test.isMale outputs: 900 true 可以看到，通过Groovy来操作List和Map显然比Java简单的多。 这里借助Map再讲述下如何确定闭包的参数。比如我们想遍历一个Map，我们想采用Groovy的方式，通过查看文档，发现它有如下两个方法，看起来和遍历有关： 可以发现，这两个each方法的参数都是一个闭包，那么我们如何知道闭包的参数呢？当然不能靠猜，还是要查文档。 通过文档可以发现，这个闭包的参数还是不确定的，如果我们传递的闭包是一个参数，那么它就把entry作为参数；如果我们传递的闭包是2个参数，那么它就把key和value作为参数。 按照这种提示，我们来尝试遍历下： def emptyMap = [:] def test = [“id”:1, “name”:“renyugang”, “isMale”:true] test.each { key, value -&gt; println “two parameters, find [${key} : ${value}]” } test.each { println “one parameters, find [${it.key} : ${it.value}]” } outputs: two parameters, find [id : 1] two parameters, find [name : renyugang] two parameters, find [isMale : true] one parameters, find [id : 1] one parameters, find [name : renyugang] one parameters, find [isMale : true] 另外一个eachWithIndex方法教给大家练习，自己查文档，然后尝试用这个方法去遍历。 试想一下，如果你不知道查文档，你又怎么知道each方法如何使用呢？光靠从网上搜，API文档中那么多接口，搜的过来吗？记得住吗？ 加强的IO 在Groovy中，文件访问要比Java简单的多，不管是普通文件还是xml文件。怎么使用呢？还是来查文档。 根据File的eachLine方法，我们可以写出如下遍历代码，可以看到，eachLine方法也是支持1个或2个参数的，这两个参数分别是什么意思，就需要我们学会读文档了，一味地从网上搜例子，多累啊，而且很难彻底掌握： def file = new File(“a.txt”) println “read file using two parameters” file.eachLine { line, lineNo -&gt; println “${lineNo} ${line}” } println “read file using one parameters” file.eachLine { line -&gt; println “${line}” } outputs: read file using two parameters 1 欢迎 2 关注 3 玉刚说 read file using one parameters 欢迎 关注 玉刚说 除了eachLine，File还提供了很多Java所没有的方法，大家需要浏览下大概有哪些方法，然后需要用的时候再去查就行了，这就是学习Groovy的正道。 下面我们再来看看访问xml文件，也是比Java中简单多了。 Groovy访问xml有两个类：XmlParser和XmlSlurper，二者几乎一样，在性能上有细微的差别，如果大家感兴趣可以从文档上去了解细节，不过这对于本文不重要。 在下面的链接中找到XmlParser的API文档，参照例子即可编程， http://docs.groovy-lang.org/docs/latest/html/api/。 假设我们有一个xml，attrs.xml，如下所示： #98ff02 100 renyugang 那么如何遍历它呢？ def xml = new XmlParser().parse(new File(“attrs.xml”)) // 访问declare-styleable节点的name属性 println xml[‘declare-styleable’].@name[0] // 访问declare-styleable的第三个子节点的内容 println xml[‘declare-styleable’].attr[2].text() outputs： CircleView renyugang 更多的细节都可以从我发的那个链接中查到，大家有需要查文档即可。 Groovy的其他特性 除了本文中已经分析的特性外，Groovy还有其他特性。 Class是一等公民 在Groovy中，所有的Class类型，都可以省略.class，比如： func(File.class) func(File) def func(Class clazz) { } Getter和Setter 在Groovy中，Getter/Setter和属性是默认关联的，比如： class Book { private String name String getName() { return name } void setName(String name) { this.name = name } } class Book { String name } 上述两个类完全一致，只有有属性就有Getter/Setter；同理，只要有Getter/Setter，那么它就有隐含属性。 with操作符 在Groovy中，当对同一个对象进行操作时，可以使用with，比如： Book bk = new Book() bk.id = 1 bk.name = “android art” bk.press = “china press” 可以简写为： Book bk = new Book() bk.with { id = 1 name = “android art” press = “china press” } 判断是否为真 在Groovy中，判断是否为真可以更简洁： if (name != null &amp;&amp; name.length &gt; 0) {} 可以替换为： if (name) {} 简洁的三元表达式 在Groovy中，三元表达式可以更加简洁，比如： def result = name != null ? name : “Unknown” // 省略了name def result = name ?: “Unknown” 简洁的非空判断 在Groovy中，非空判断可以用?表达式，比如： if (order != null) { if (order.getCustomer() != null) { ​ if (order.getCustomer().getAddress() != null) { ​ System.out.println(order.getCustomer().getAddress()); ​ } } } 可以简写为： println order?.customer?.address 使用断言 在Groovy中，可以使用assert来设置断言，当断言的条件为false时，程序将会抛出异常： def check(String name) { // name non-null and non-empty according to Gro ovy Truth assert name // safe navigation + Groovy Truth to check assert name?.size() &gt; 3 } switch方法 在Groovy中，switch方法变得更加灵活，可以同时支持更多的参数类型： def x = 1.23 def result = “” switch (x) { case “foo”: result = “found foo” // lets fall through case “bar”: result += “bar” case [4, 5, 6, ‘inList’]: result = “list” break case 12…30: result = “range” break case Integer: result = “integer” break case Number: result = “number” break case { it &gt; 3 }: result = “number &gt; 3” break default: result = “default” } assert result == “number” ==和equals 在Groovy中，==相当于Java的equals，，如果需要比较两个对象是否是同一个，需要使用.is()。 Object a = new Object() Object b = a.clone() assert a == b assert !a.is(b) task","categories":[{"name":"Tools","slug":"Tools","permalink":"https://bobit.github.io/categories/Tools/"}],"tags":[{"name":"Gradle","slug":"Gradle","permalink":"https://bobit.github.io/tags/Gradle/"}]},{"title":"Gradle使用方法详解","slug":"Setting/Gradle","date":"2015-11-13T03:11:35.000Z","updated":"2018-12-27T12:39:59.943Z","comments":true,"path":"posts/21924951.html","link":"","permalink":"https://bobit.github.io/posts/21924951.html","excerpt":"","text":"Gradle Gradle 是基于 Groovy 语言的，Groovy 大家应该很熟悉吧，是基于 Java Virtual Machine 的敏捷开发语言，它结合了 Python、Ruby 和 Smalltalk 的许多强大的特性。 前言 构建，软件生命周期中重要的一环，在现代软件开发过程中，起着越来越重要的作用。过去在Java或类Java的世界里，Ant、Maven再熟悉不过了，Maven凭借其强大的依赖配置战胜Ant，基本上成为了Java构建的标准。而在现代，系统日益复杂，构建的灵活性要求越来越高，比如：构建过程中需要打包上传到服务器，Maven无法很好地支持这种复杂的系统构建，所以，我选择了Gradle，一个基于Groovy，更灵活更强大的构建系统，能帮助我们构建更复杂的项目。 历程 一开始的时候，我们只有一个工程，所有要用到的jar包都放到工程目录下面，时间长了，工程越来越大，使用到的jar包也越来越多，难以理解jar之间的依赖关系。再后来我们把旧的工程拆分到不同的工程里，靠ide来管理工程之间的依赖关系，各工程下的jar包依赖是杂乱的。一段时间后，我们发现用ide来管理项程很不方便，比如不方便脱离ide自动构建，于是我们写自己的ant脚本。再后来，维护ant脚本变得痛苦，管理jar包更加痛苦。svn能管理源码的版本，却不能管理构建出的部署部件的版本。于是我们决定用maven，然而pom.xml的配置实在太繁了！ 为什么选择Gradle 从使用方面来看： groovy 比 xml好用 Gradle用groovy来做为build脚本，比xml要易读易用得多。用过ant的人都知道，要在ant里面表达一个if分支功能有多么的麻烦，不直观。由于gradle的build脚本就是groovy程序，所以做分支循环等非常方便自然。 Convention over Configuration 比写大量ant基础脚本方便 用ant的时候，要得定义哪里放源码，哪里放jar包，哪里放编译出的class文件等等，每个项目都要这样做，非常麻烦。gradle和maven一样，都定义了一个默认的目录结构，只要按要这个默认的规则来做，就不需要多写一行代码。而且gradle的目录的结构规范和maven是一样的。 支付定义task，比maven灵活 maven可以帮助管理依赖关系，但是要在maven里实现一个简单的自定义功能，就很麻烦，要得写maven插件，而在gradle里，task是一等公民，可以轻易的添加自己的功能。 灵活的依赖管理 ant没有依赖管理的功能，都要自己手动做，maven的依赖管理很死板，只能依赖于标准的maven artifact，不能依赖本地的某个jar文件或者其它的源码。而gradle则可以混合地同时支持这些依赖方法，这样可以让旧项目的迁移容易得多。 默认就具有丰富的功能 只要安装好gradle，默认就支持java项目,war项目，ear项目，做单元测试，生成jar包，上传jar包到maven服务器，等等功能。一般的项目都已经够用了。 从框架方向来看： Gradle是很成熟的技术，可以处理大规模构建 Gradle对多语言、多平台有更natural的支持 Gradle关注在构建效率上 Gradle发布很频繁，重要feature开发计划透明化 Gradle社区很活跃，并且增加迅速 从语言特性来看： 代码很精简 Gradle基于Groovy，能完成复杂系统的构建任务 DSL比XML更简洁高效 配置 安装 安装JDK java -version 下载Gradle, https://gradle.org 完全版 设置环境变量 用户变量 GRADLE_HOME 环境变量 path 中增加 %GRADLE_HOME%\\bin; gradle -version Jar包目录 E:\\localRepoGradle\\caches\\modules-2\\files-2.1 修改本地库的位置 如果不想使用缺省目录，则可以设置环境变量GRADLE_USER_HOME的路径，就可改变gradle的缓存目录。 使用Gradle去构建项目，但是没有办法像Maven一样配置Setting文件来修改本地库的位置。后来纠结很久，修改系统的环境变量即可。注意：修改完成后一定要重启计算机才可以。 集成到IDE中（STS） 1、 打开eclipse，Help–&gt;Install new software,输入 在线安装地址 http://dist.springsource.com/release/TOOLS/update/e4.4或者 http://dist.springsource.com/release/TOOLS/gradle （貌似不翻墙也是可以下载，但是访问特别慢，建议翻墙下载。） 2、 选择Core / Eclipse Integration for Gradle -&gt; Gradle IDE 3、 设置下jar下载保存的地址,不然默认保存在C盘, “window-&gt;preferences-&gt;gradle” (可以不设置,我个人不喜欢在C盘) 使用以下配置文件对Gradle的构建进行配置： Gradle构建脚本（build.gradle）指定了一个项目和它的任务。 Gradle属性文件（gradle.properties）用来配置构建属性。 Gradle设置文件（gradle.settings）对于只有一个项目的构建而言是可选的，如果我们的构建中包含多于一个项目，那么它就是必须的，因为它描述了哪一个项目参与构建。每一个多项目的构建都必须在项目结构的根目录中加入一个设置文件。 STS设置gradle下jar包的保存地址 “window-&gt;preferences-&gt;gradle” 使用Maven本地缓存库 从Maven切换到Gradle，原有的几G的本地缓存库当然想继续使用。在用户手册中找到了答案。在50.6.3章节。大概意思是说使用mavenLocal()配置maven的本地仓库后，gradle默认会按以下顺序去查找本地的仓库：USER_HOME/.m2/settings.xml &gt;&gt; M2_HOME/conf/settings.xml &gt;&gt; USER_HOME/.m2/repository。 如果想使用Maven本地缓存，需要定义： repositories { //本地库，local repository(${user.home}/.m2/repository) mavenLocal() //Maven中心库(http://repo1.maven.org/maven2) //mavenCentral() } 注意： 在USER_HOME/.m2下的settings.xml文件必须存在（不存在，Gradle会无法使用。）。 M2_HOME/conf下的settings.xml文件配置后未起作用。 Gradle中下载慢的问题 一个简单的办法，修改项目根目录下的build.gradle，mavenCentral()替换掉即可： repositories { //如果maven本地缓存库没有，则下载到Gradle目录 mavenLocal() maven{ url ‘http://maven.oschina.net/content/groups/public/’} } 创建项目 1、 创建一个gradle项目，File -&gt; New -&gt; Project -&gt; Gradle -&gt; Gradle Project -&gt; Next，输入项目的名称，选择Sample project Java Quickstart,点击完成即可 2、 添加一个jar包依赖，编辑文件build.gradle,找到dependencies,在里面添加一条jar的信息,例如： dependencies { compile group: ‘commons-collections’, name: ‘commons-collections’, version: ‘3.2’ //添加一个spring 依赖 compile ‘org.springframework:spring-core:4.1.2.RELEASE’ testCompile group: ‘junit’, name: ‘junit’, version: ‘4.+’ } 3、 刷新项目，使得eclipse自动下载jar包，右击项目-&gt;Gradle-&gt;Refresh Dependencies 4、 打包项目，右击项目-&gt;Run As -&gt; Gradle Build… -&gt; 在命令行里面输入build,点击运行即可 Gradle和Maven比较 Gradle和Maven在依赖管理上几乎差不多，核心的概念是一样的，只不过Gradle语法更精简，并且多了一些更灵活的自定义配置。我们先看一个例子，Maven的pom.xml： org.springframework spring-core org.springframework spring-beans org.springframework spring-context junit junit 更换成Gradle脚本，结果是这样： dependencies { compile(‘org.springframework:spring-core:3.2.4.RELEASE’) compile(‘org.springframework:spring-beans:3.2.4.RELEASE’) compile(‘org.springframework:spring-context:3.2.4.RELEASE’) testCompile(‘junit:junit:4.7’) } 代码块少了很多。试想，生产环境下的中、大型应用如果用都用Gradle替换Maven，那势必会大大减少配置文件代码块，并有更强的可读性，也就意味着系统更加稳健。 1，Gradle在依赖配置上面，和Maven一样，支持传递性依赖，然后和Maven不同的是，它还支持排除传递性依赖以及关闭传递性依赖。 2，Gradle的依赖scope，也基本和Maven一样，不过它是通过配置来定义，plugin来支撑和加强的，所以除了基本的compile、runtime等scope外，Gradle还可以自定义出很多配置，针对不同的配置写不同的task来完成更复杂更灵活的构建任务。 依赖相关的仓库配置很灵活，支持多种repository， gradle项目与maven项目相互转化 gradle这几年发展迅猛，github越来越多的项目都开始采用gradle来构建了，但是并不是所有人都对gradle很熟悉，下面的方法可以把gradle转成maven项目，前提gradle项目目录结构保持跟maven一样的约定，即/src/main/java这一套。 gradle --&gt; maven 在build.gradle中增加以下内容(group,version可自行修改，artifactId默认为目录名称) apply plugin: ‘java’ apply plugin: ‘maven’ group = ‘com.demo’ version = ‘0.1-dev’ sourceCompatibility = 1.6 然后./gradlew build ，成功后将在build\\poms目录下生成pom-default.xml文件，把它复制到根目录下，改名成pom.xml即可 当然，通过修改build.gradle 也可以直接在根目录下生成pom.xml task writeNewPom &lt;&lt; { pom { project { inceptionYear ‘2008’ licenses { license { name ‘The Apache Software License, Version 2.0’ url ‘http://www.apache.org/licenses/LICENSE-2.0.txt’ distribution ‘repo’ } } } }.writeTo(&quot;$buildDir/pom.xml&quot;) } maven --&gt; gradle 先保证本机安装了gradle 2.0以上的版本 然后在maven根目录下运行 gradle init --type pom Gradle 的仓库(Repositories) 首先，Repository 是什么？Repository 是文件的集合，这些文件，通过group、name和version组织起来。 在使用上，主要体现为jar 和 xml文件,Gradle 通过这些Repository 找到外部依赖(external dependencies.) Gradle 并不默认指定任何仓库。它支持很多中仓库，如maven、ivy，通过文件访问或者通过HTTP 访问。下面举例说明： 1.使用本地maven 仓库： repositories { mavenLocal()() } 2.使用远程maven 仓库： repositories { maven { url &quot;http://repo.mycompany.com/maven2&quot; } //带认证的库 maven { credentials { username 'user' password 'password' } url &quot;http://repo.mycompany.com/maven2&quot; } } 3.使用本地的ivy 仓库： repositories { ivy { // URL can refer to a local directory url &quot;../local-repo&quot; } } 4.使用远程的ivy 仓库： repositories { ivy { url &quot;http://repo.mycompany.com/repo&quot; } } 使用 Maven 库 经实践，发现直接使用 mavenLocal() 时，gradle 会查找 Maven 配置文件 ${user.home}/.m2/settings.xml 来定位本地 Maven 库的路径， 如果没有找到该文件，则默认本地库路径为 ${user.home}/.m2/repository。 gradle项目与maven项目相互转化 gradle --&gt; maven maven --&gt; gradle 先保证本机安装了gradle 2.0以上的版本 然后在maven根目录下运行 gradle init --type pom Java项目结构 默认的项目结构如下： src/main/java目录包含了项目的源代码。 src/main/resources目录包含了项目的资源（如属性文件）。 src/test/java目录包含了测试类。 src/test/resources目录包含了测试资源。所有我们构建生成的文件都会在build目录下被创建， 这个目录涵盖了以下的子目录，这些子目录我们会在这篇教程中提到，另外还有一些子目录我们会放在以后讲解。 classes目录包含编译过的.class文件。 libs目录包含构建生成的jar或war文件。 Java工程中的任务 assemble任务会编译程序中的源代码，并打包生成Jar文件，这个任务不执行单元测试。 build任务会执行一个完整的项目构建。 clean任务会删除构建目录。 compileJava任务会编译程序中的源代码。 FAQ 解决遇到的问题 Q. 一个工程可以使用多个仓库。怎么寻找dependency呢？ A. Gradle是这么做的：按照你在文件中(build.gradle)仓库的顺序寻找所需依赖(如jar文件)， 如果在某个仓库中找到了，那么将不再其它仓库中寻找。 Q. 解决Gradle编译时出现： 编码GBK的不可映射字符 A. 在build.gradle文件中加入如下内容： [compileJava, compileTestJava]*.options*.encoding = 'UTF-8' 参考： https://dongchuan.gitbooks.io/gradle-user-guide-/content/ https://docs.gradle.org/current/userguide/userguide.html 小结 Gradle非常简洁，项目本身的配置代码非常少。 Gradle在外部project构建也支持很好，整体构建简单，并且通过公用外部构建脚本，让配置内容尽量没有冗余。 Gradle很灵活，可以方面的增加和修改构建过程。而Maven却需要开发插件来支持。 Gradle是基于Groovy的，也就是说配置中可以编写自定义代码，能适应更复杂的场景，能完成更强大的功能，比如说：自动上传、分发、部署等等。 随着公司业务的发展，软件系统变得日益复杂和庞大，这就要求有更灵活、更高效的构建系统来支撑。现代构建系统Gradle提供了强大的功能、简洁的语法、灵活的配置，能适应各种复杂的构建环境。利用多project构建，让整个系统模块化，管理更高效。 附录 gradle主配置文件","categories":[{"name":"Tools","slug":"Tools","permalink":"https://bobit.github.io/categories/Tools/"}],"tags":[{"name":"Gradle","slug":"Gradle","permalink":"https://bobit.github.io/tags/Gradle/"}]},{"title":"IDEA使用方法详解","slug":"Setting/IDEA","date":"2015-11-12T03:15:35.000Z","updated":"2018-12-21T13:34:25.286Z","comments":true,"path":"posts/5dcde84c.html","link":"","permalink":"https://bobit.github.io/posts/5dcde84c.html","excerpt":"","text":"IntelliJ IDEA import and reimport a project 以下是import一个Maven project的时候需要进行的配置： (1)Keep projects files in: 通过这一个check box来指定“项目文件”在导入之后的location。 比如说，当你import一个project并希望将“.iml”文件和“.idea”文件夹导入到指定的文件夹中，而不是默认的位置。 默认地，IntellJ IDEA会将“项目文件”放在pom.xml的旁边。 (2)Import Maven projects automatically： 选择该项，如果你想要每次你修改你的pom.xml文件时，IntelliJ IDEA都会自动执行reimport。 (3)Create IntelliJ IDEA modules for aggregator projects (with ‘pom’ packaging)： 选择该项，在该“aggressive project”的pom.xml中的包含的每一个Maven Modules将会被创建。 (4)Create module groups for multi-module Maven projects: 选择该项，IntelliJ IDEA将会根据该aggressive Maven project创建一个module group，包含每个nested modules。 (5)Keep source and test folders on reimport： 1.选择该项,所有的“source”和“test”文件夹将会在每次import时被保存。 2.不选该项,所有之前配置的“source”和“test”文件夹将会在每次import的时候被remove掉。 默认地，该check box如下设置的： 1.对于new project：不选该项； 2.对于already imported projects：选择该项。 (6)Exclude build directory (PROJECT_ROOT/target): 选择该项，来从该项目中排出build目录。 这个可能会有用，如果你想要加速项目导入的进程。 不选该项，IntelliJ IDEA在每次你import一个project的时候，将会在build目录下的文件建立索引，这样的话有可能会有额外的时间开销。 (7)Use Maven output directories： 不选该项，build将会被创建在IntelliJ IDEA的默认output目录：USER_HOME\\IdeaProjects&lt;project&gt;\\classes\\Production\\； 选择该项，build被创建在Mavende output目录，而且，IntelliJ IDEA编译的结果被reused。 但是，IntelliJ IDEA本身不会reuse Maven build的结果，and，会重头编译。 (8)Generated sources folders: 当你reimport一个project的时候，指定你的source root的directory。 你可以选择这下面的一种选项： 1.Detect automatically： 这是默认选项。IntelliJ IDEA将自动的识别产生sources的位置。 IntelliJ IDEA也会识别标记为source root的路径。但是，IntelliJ IDEA只在target/generated-sources和target/generated-sources/*下搜索。 2.target/generated-sources：这个选项让你手动的标记source root。 3.subdirectories of “target/generated-sources”：这个选项让你手动的标记subdirectory为source root。 4.Don’t detect：这个选项让你跳过detection process。 (9)Phase to be used for folders update： 选择用来folder updat的Maven phase。这可能有用，如果你调整你的plugins，为了使额外的sources在某些阶段被load进来。 (10)Automatically download： 选择source、documenation，在一个opening Maven project中，这些将会被自动下载。 (11)Dependency types： 使用这个field来指定，当你reimport project时候的dependency types。 (12)Use Maven3 to import a project: Q2A terminal设置成Linux的终端一样 setting-&gt;Tools-&gt;terminal-&gt;你的路径\\Git\\bin\\bash.exe 解决IDEA下的terminal中文Unicode编码问题，在Git的安装目录下的etc目录下bash.bashrc文件，在最后一行添加： 123export LC_ALL=zh_CN.UTF-8 # 设置终端打开的编码alias ls=&apos;ls -F --color=auto --show-control-chars&apos; # 使用ls命令的时候加上颜色alias ll=&apos;ls -la -F --color=auto --show-control-chars&apos; # 使用ll命令的时候加上颜色 重启IDEA就可以了。 can’t start git:git.exe Settings – Version Control – Git Path to Git executable:C:\\DevTools\\PortableGit\\bin\\git.exe IntelliJ IDEA怎么删除Module idea,删除(实际上是移除)module之后,如何重新添加 idea，里面的删除，不是真的删除，只是移除，如果想要重新添加，操作过程ctrl+alt+shift+s,进入project structure，然后点击Modules，点击+号，选择import module，然后找到对应的module所在位置，添加进来。 此外还有一种简单的方式，但是忘记了，后面如果想起来再做补充 out存放的是该项目下所有Module(模块)的编译结果。 target存放的是单个Module的编译结果。 如果为某个Module指定了编译结果的路径，则不会再输出到out文件夹中了。 你在Project Structure中的Project选项卡中可以设置Project compiler output的目录。 在Modules中选择某一个模块后，在右侧的Paths选项卡中可以设置该模块的Compiler output目录。 Move Module to Group分组重启丢失 解决： Settings - Build,Execution,Deployment – Build Tools - Maven - Importing Create module groups for multi-module Maven projects 取消此项 Create module groups for multi-module Maven projects 选中无法创建分组的，显示多个模块项目。 Create IntelliJ IDEA modules for aggregator projects(with ‘pom’ packaging) 会移除父模块 上述两个都选中显示分组，分组下显示多个模块 IDEA工具将所有的class打包成jar文件，方法如下： 选择菜单File-&gt;Project Structure，将弹出Project Structure的设置对话框。 选择左边的Artifacts后点击上方的“+”按钮点击“+”，选择“Jar”，选择Empty或From modules with dependencies，后者会把在项目中用到的Jar包解压开，当成项目的一部分，打包到最后的Jar包中。但是这样会有一个问题，即，如果项目中引用的Jar包有签名过，最后打包成的Jar包运行时会抛出错误： “java.lang.SecurityException: Invalid signature file digest for Manifest main attributes”，因此，选择的是Empty，然后在“Output Layout”中，把自己要打包的文件、文件夹添加进去。对于外部引用的包，全部放在lib目录下，因此，在Class Path中，把依赖的jar包添加进去，例如：lib/javax.servlet-3.0.0.v201112011016.jar lib/jetty-all-9.1.5.v20140505.jar lib/json-simple-1.1.1.jar 设置好Main Class，这就不用多说了。点击OK。 回到IDEA，选择Build -&gt; Build Artifacts，成功生成Jar包。生成的Jar包位于上图设置的Output directory。 使用命令java -jar xxxxx.jar来执行jar包。 在弹出的框中选择jar-&gt;from moduls with dependencies… 选择要启动的类，然后 确定 应用之后选择菜单Build-&gt;Build Artifacts,选择Build或者Rebuild后即可生成，生成的jar文件位于工程项目目录的out/artifacts下。 IDEA工具指定jdk的Language level 在Java项目中必不可少的是我们要指定一个jdk。在指定jdk的同时，还可以指定jdk的Language level，这个有点像我们工程最低支持版本。比如Language level 设置了5.0 只是就不能出现使用6.0／7.0特性的代码。 因为这些特性在5.0的环境下是无法编译的。或者可以理解ide会安装Language level指定的jdk版本来对我们的代码进行编译，以及错误检查。 在IntelliJ中有两个地方设置这个参数。 针对整个工程，或者说是工程默认的。 针对模块的，这里才是正在生效的设置。 如果设置Use project language level 就是延用project的设置。 此处可以重新指定。project设置就失效。这个设置需要重新载入项目。","categories":[{"name":"Tools","slug":"Tools","permalink":"https://bobit.github.io/categories/Tools/"}],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://bobit.github.io/tags/IDEA/"}]},{"title":"Java并发编程总结","slug":"并发编程/Java并发编程总结","date":"2014-11-13T10:24:18.000Z","updated":"2018-12-21T12:57:12.533Z","comments":true,"path":"posts/1d1988c1.html","link":"","permalink":"https://bobit.github.io/posts/1d1988c1.html","excerpt":"","text":"多线程的基本知识 进程与线程的介绍 程序运行时在内存中分配自己独立的运行空间，就是进程 线程：它是位于进程中，负责当前进程中的某个具备独立运行资格的空间。 进程是负责整个程序的运行，而线程是程序中具体的某个独立功能的运行。一个进程中至少应该有一个线程。 多线程的介绍 在多任务，多用户的系统中。每天都会产生许多进程。 多线程：在一个进程中，我们同时开启多个线程，让多个线程同时去完成某些任务（功能）。 (比如后台服务系统，就可以用多个线程同时响应多个客户的请求) 多线程的目的：提高程序的运行效率。 多线程的运行原理：cpu在线程中做时间片的切换（多线程可以提高程序的运行效率，但不能无限制的开线程） 实现线程的两种方式 1、继承Thread的方式 2、声明实现 Runnable 接口的方式 JAVA同步 synchronized关键字 #### 加同步格式： synchronized( 需要一个任意的对象（锁） ){ 代码块中放操作共享数据的代码} #### 释放锁 synchronized是java中的一个关键字，也就是说是Java语言内置的特性。如果一个代码块被synchronized修饰了，当一个线程获取了对应的锁，并执行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁只会有两种情况： 1.获取锁的线程执行完了该代码块，然后线程释放对锁的占有 2.线程执行发生异常，此时JVM会让线程自动释放锁。 #### synchronized缺点 所以synchronized等待线程能无期限地等待下去：这是一个致命的缺点，所以引进了Lock解决这个问题。 lock lock和synchronized的区别 1）Lock不是Java语言内置的，synchronized是Java语言的关键字，因此是内置特性。Lock是一个类，通过这个类可以实现同步访问； 2）Lock和synchronized有一点非常大的不同，采用synchronized不需要用户去手动释放锁，当synchronized方法或者synchronized代码块执行完之后，系统会自动让线程释放对锁的占用；而Lock则必须要用户去手动释放锁，如果没有主动释放锁，就有可能导致出现死锁现象。 关于 Lock和synchronized的选择 1）Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现； 2）synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁； 3）Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断； 4）通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 5）Lock可以提高多个线程进行读操作的效率。 在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。 Lock接口中每个方法的使用： lock()、tryLock()、tryLock(long time, TimeUnit unit)、lockInterruptibly()是用来获取锁的。 unLock()方法是用来释放锁的。 四个获取锁方法的区别： lock()方法是平常使用得最多的一个方法，就是用来获取锁。如果锁已被其他线程获取，则进行等待。 由于在前面讲到如果采用Lock，必须主动去释放锁，并且在发生异常时，不会自动释放锁。因此一般来说，使用Lock必须在try{}catch{}块中进行，并且将释放锁的操作放在finally块中进行，以保证锁一定被被释放，防止死锁的发生。 tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。 tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。 lockInterruptibly()方法比较特殊，当通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。也就使说，当两个线程同时通过lock.lockInterruptibly()想获取某个锁时，假若此时线程A获取到了锁，而线程B只有等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。 注意，当一个线程获取了锁之后，是不会被interrupt()方法中断的。 因此当通过lockInterruptibly()方法获取某个锁时，如果不能获取到，只有进行等待的情况下，是可以响应中断的。 而用synchronized修饰的话，当一个线程处于等待某个锁的状态，是无法被中断的，只有一直等待下去。ReentrantLock 直接使用lock接口的话，我们需要实现很多方法，不太方便，ReentrantLock是唯一实现了Lock接口的类，并且ReentrantLock提供了更多的方法，ReentrantLock，意思是“可重入锁”。","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://bobit.github.io/categories/并发编程/"}],"tags":[{"name":"并发","slug":"并发","permalink":"https://bobit.github.io/tags/并发/"},{"name":"concurrent","slug":"concurrent","permalink":"https://bobit.github.io/tags/concurrent/"}]},{"title":"Maven学习总结","slug":"团队协作/Maven学习总结","date":"2014-10-13T14:17:17.000Z","updated":"2018-12-21T12:57:49.712Z","comments":true,"path":"posts/17b0d7a3.html","link":"","permalink":"https://bobit.github.io/posts/17b0d7a3.html","excerpt":"","text":"Maven内置变量说明 123456789$&#123;basedir&#125; 项目根目录(即pom.xml文件所在目录)$&#123;project.build.directory&#125; 构建目录，缺省为target目录$&#123;project.build.outputDirectory&#125; 构建过程输出目录，缺省为target/classes$&#123;project.build.finalName&#125; 产出物名称，缺省为$&#123;project.artifactId&#125;-$&#123;project.version&#125;$&#123;project.packaging&#125; 打包类型，缺省为jar$&#123;project.xxx&#125; 当前pom文件的任意节点的内容$&#123;env.xxx&#125; 获取系统环境变量。例如,&quot;env.PATH&quot;指代了$path环境变量（在Windows上是%PATH%）。$&#123;settings.xxx&#125; 指代了settings.xml中对应元素的值。例如：&lt;settings&gt;&lt;offline&gt;false&lt;/offline&gt;&lt;/settings&gt;通过 $&#123;settings.offline&#125;获得offline的值。Java System Properties: 所有可通过java.lang.System.getProperties()访问的属性都能在POM中使用，例如 $&#123;JAVA_HOME&#125;。 上传第三方jar包 示例 mvn deploy:deploy-file -DgroupId=com.oracle -DartifactId=ojdbc8 -Dversion=12.2.0.1.0 -Dpackaging=jar -Dfile=D:\\ojdbc8.jar -Durl=http://192.168.80.202:8081/nexus/content/repositories/thirdparty/ -DrepositoryId=nexus-releases mvn deploy:deploy-file -DgroupId=postgresql -DartifactId=postgresql -Dversion=9.2-1002.jdbc4 -Dpackaging=jar -Dfile=D:\\postgresql-9.2-1002.jdbc4.jar -Durl=http://1.94.58.101:8081/repository/thirdparty-releases/ -DrepositoryId=thirdparty-releases mvn deploy:deploy-file -DgroupId=qrcode -DartifactId=qrcode -Dversion=3.0 -Dpackaging=jar -Dfile=D:\\qrcode.jar -Durl=http://192.168.80.202:8081/nexus/content/repositories/thirdparty/ -DrepositoryId=nexus-releases 安装jar包到本地仓库 示例 mvn install:install-file -DgroupId=com.microsoft.sqlserver -DartifactId=sqljdbc4 -Dversion=4.0 -Dpackaging=jar -Dfile=E:\\sqljdbc4.jar mvn install:install-file -DgroupId=QRCode -DartifactId=QRCode -Dversion=3.0 -Dpackaging=jar -Dfile=E:\\QRCode.jar 示例解释 -DgroupId=包名 -DartifactId=项目名 -Dversion=版本号 -Dpackaging=jar -Dfile=*.jar 验证 到本地仓库查看安装是否成功 在自己项目中添加jar依赖 pom.xml文件中添加 12345&lt;dependency&gt;&lt;groupId&gt;QRCode&lt;/groupId&gt;&lt;artifactId&gt;QRCode&lt;/artifactId&gt;&lt;version&gt;3.0&lt;/version&gt;&lt;/dependency&gt; 查看maven中是否添加成功","categories":[{"name":"Maven","slug":"Maven","permalink":"https://bobit.github.io/categories/Maven/"}],"tags":[{"name":"maven","slug":"maven","permalink":"https://bobit.github.io/tags/maven/"}]},{"title":"Java序列化","slug":"并发编程/Java序列化","date":"2013-11-13T14:25:17.000Z","updated":"2018-12-21T12:57:08.213Z","comments":true,"path":"posts/9cd1a944.html","link":"","permalink":"https://bobit.github.io/posts/9cd1a944.html","excerpt":"","text":"概念 序列化（串行化）（Serilization）：把对象转换为字节序列的过程称为对象的序列化。 反序列化（并行化）（Deserialization）：把字节序列恢复为对象的过程称为对象的反序列化。 对象的序列化主要有两种用途 1）把对象的字节序列持久化到数据库、文件系统。 2）在网络上传送对象的字节序列。 白话 序列化就是把存在于内存的对象数据转化成可以保存成硬盘文件的形式去存储，也就是把内存中对象数据变成硬盘文件；反序列化就是把序列化后的硬盘文件加载到内存,重新变成对象数据。 实现 在java中要想使一个java对象可以实现序列化与反序列化,必须让该类实现java.io.Serializable接口 java.io.Serializable接口定义如下: 123publicinterface Serializable &#123;&#125;123 从上述定义中可以看到该接口中未定义任何方法,主要实现如下； b) 序列化主要依赖java.io.ObjectOutputStream类,该类对java.io.FileOutputStream进一步做了封装,这里主要使用ObjectOutputStream类的writeObject()方法实现序列化功能 c) 反序列化主要依赖java.io.ObjectInputStream类,该类对java.io.InputStream进一步做了封装,这里主要使用ObjectInputStream类的readObject()方法实现序列化功能 最基本的序列化：实现java.io.Serializable接口，通过文件流的方式将对象持久化到磁盘。 最基本的反序列化：读取之前序列化之后的文件，恢复成对象 序列化框架 Java原生序列化、XML、JSON、Hessian、protobuf、Avro、Kryo、msgpack、Thrift等 DEMO","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://bobit.github.io/categories/并发编程/"}],"tags":[{"name":"克隆","slug":"克隆","permalink":"https://bobit.github.io/tags/克隆/"},{"name":"序列化","slug":"序列化","permalink":"https://bobit.github.io/tags/序列化/"},{"name":"Serializable","slug":"Serializable","permalink":"https://bobit.github.io/tags/Serializable/"}]},{"title":"Java克隆与序列化","slug":"并发编程/Java克隆与序列化","date":"2013-11-13T14:22:17.000Z","updated":"2018-12-21T12:57:20.395Z","comments":true,"path":"posts/8fc1e45b.html","link":"","permalink":"https://bobit.github.io/posts/8fc1e45b.html","excerpt":"","text":"最近不止一次遇见深浅克隆（深复制，浅复制）的问题，除了印象中有个clone方法外一脸懵逼！！！ 克隆（复制）在Java中是一种常见的操作，目的是快速获取一个对象副本。克隆分为深克隆和浅克隆。 概念 ⑴浅复制（浅克隆） 被复制对象的所有变量都含有与原来的对象相同的值，而所有的对其他对象的引用仍然指向原来的对象。换言之，浅复制仅仅复制所考虑的对象，而不复制它所引用的对象。 ⑵深复制（深克隆） 被复制对象的所有变量都含有与原来的对象相同的值，除去那些引用其他对象的变量。那些引用其他对象的变量将指向被复制过的新对象，而不再是原有的那些被引用的对象。换言之，深复制把要复制的对象所引用的对象都复制了一遍。 总之深浅克隆都会在堆中新分配一块区域，区别在于对象属性引用的对象是否需要进行克隆（递归性的）。 Java的clone()方法 ⑴clone方法将对象复制了一份并返回给调用者。一般而言，clone（）方法满足： ①对任何的对象x，都有x.clone() !=x//克隆对象与原对象不是同一个对象 ②对任何的对象x，都有x.clone().getClass()= =x.getClass()//克隆对象与原对象的类型一样 ③如果对象x的equals()方法定义恰当，那么x.clone().equals(x)应该成立。 ⑵Java中对象的克隆 ①为了获取对象的一份拷贝，我们可以利用Object类的clone()方法。 ②在派生类中覆盖基类的clone()方法，并声明为public。 ③在派生类的clone()方法中，调用super.clone()。 ④在派生类中实现Cloneable接口。 深克隆与序列化 1.对于深克隆而言，如果类有很多引用类型的域，那么重写clone()方法依次复制各个域也很麻烦。如果引用类型的域也是由引用类型组成的，则应该考虑使用序列化的方式实现深克隆。 2.序列化可以将任意对象写入流中，根据流的类型不同，可以将对象写入到文件中，也可以将对象写入到字节数组中。克隆对象时一般不需要先进行保存，因此将使用字节数组。在写入完成后，再将其读出就可以实现克隆了。使用序列化可以不用考虑引用类型的域，编写clone()方法相对简单，但要求引用类型也实现Serializable接口。 使用序列化实现克隆的注意事项 (1)对于任何一个序列化的对象，都要求其实现Serializable接口 (2)如果该类的域中有引用类型，则要求该引用类型也实现Serializable接口，依此类推。 (3)序列化方式实现克隆会比直接克隆各个引用类型域慢 选择适当的克隆方式 如果类的各个域是基本类型或不可变类型，则可以使用浅克隆，否则使用深克隆。如果类的域比较复杂，可以使用序列化的方式实现，否则应该使用复制域的方式实现深克隆。 DEMO","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://bobit.github.io/categories/并发编程/"}],"tags":[{"name":"克隆","slug":"克隆","permalink":"https://bobit.github.io/tags/克隆/"},{"name":"序列化","slug":"序列化","permalink":"https://bobit.github.io/tags/序列化/"}]},{"title":"Linux学习-vim","slug":"Linux/linux学习-vim","date":"2013-11-13T04:38:35.000Z","updated":"2018-12-21T09:38:45.712Z","comments":true,"path":"posts/e15c8e0b.html","link":"","permalink":"https://bobit.github.io/posts/e15c8e0b.html","excerpt":"","text":"vi 和vim 的区别 它们都是多模式编辑器，不同的是vim 是vi的升级版本，它不仅兼容vi的所有指令，而且还有一些新的特性在里面。 vim的这些优势主要体现在以下几个方面： 1、多级撤消 我们知道在vi里，按 u只能撤消上次命令，而在vim里可以无限制的撤消。 2、易用性 vi只能运行于unix中，而vim不仅可以运行于unix,windows ,mac等多操作平台。 3、语法加亮 vim可以用不同的颜色来加亮你的代码。 4、可视化操作 就是说vim不仅可以在终端运行，也可以运行于x window、 mac os、 windows。 5、对vi的完全兼容 某些情况下，你可以把vim当成vi来使用。 vi和vim都是Linux中的编辑器，不同的是vim比较高级，可以视为vi的升级版本。vi使用于文本编辑，但是vim更适用于coding。 vi有3个模式 插入模式：在此模式下可以输入字符，按ESC将回到命令模式。 命令模式：可以移动光标、删除字符等。 低行模式：可以保存文件、退出vi、设置vi、查找等功能(低行模式也可以看作是命令模式里的)。 打开文件、保存、关闭文件 命令模式下使用 vi filename //打开filename文件 :w //保存文件 :w test.md //保存至vpser.net文件 :q //退出编辑器，如果文件已修改请使用下面的命令 :q! //退出编辑器，且不保存 :wq //退出编辑器，且保存文件 插入文本或行 vi命令模式下使用，执行下面命令后将进入插入模式，按ESC键可退出插入模式 a //在当前光标位置的右边添加文本 i //在当前光标位置的左边添加文本 A //在当前行的末尾位置添加文本 I //在当前行的开始处添加文本(非空字符的行首) O //在当前行的上面新建一行 o //在当前行的下面新建一行 R //替换(覆盖)当前光标位置及后面的若干文本 J //合并光标所在行及下一行为一行(依然在命令模式)","categories":[{"name":"Linux","slug":"Linux","permalink":"https://bobit.github.io/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://bobit.github.io/tags/linux/"}]},{"title":"Java常用的数据结构","slug":"并发编程/Java常用的数据结构","date":"2010-11-13T14:23:17.000Z","updated":"2018-12-21T12:57:16.705Z","comments":true,"path":"posts/8d45e6b1.html","link":"","permalink":"https://bobit.github.io/posts/8d45e6b1.html","excerpt":"","text":"定义 数据元素相互之间的关系称为结构。有四类基本结构：集合、线性结构、树形结构、图状结构; 集合结构:除了同属于一种类型外，别无其它关系 线性结构:元素之间存在一对一关系常见类型有: 数组,链表,队列,栈,它们之间在操作上有所区别.例如:链表可在任意位置插入或删除元素,而队列在队尾插入元素,队头删除元素,栈只能在栈顶进行插入,删除操作. 树形结构:元素之间存在一对多关系,常见类型有:树(有许多特例:二叉树、平衡二叉树、查找树等) 图形结构:元素之间存在多对多关系,图形结构中每个结点的前驱结点数和后续结点多个数可以任意 Java中常用的数据结构 主要分为Collection和Map两个主要接口（接口只提供方法，并不提供实现），而程序中最终使用的数据结构是继承自这些接口的数据结构类。 JAVA的容器—List,Map,Set Collection ├List │├LinkedList │├ArrayList │└Vector │ └Stack └Set Map ├Hashtable ├HashMap └WeakHashMap DataStructure Collection Map 几个常用类的区别 1．ArrayList: 元素单个，效率高，多用于查询 2．Vector: 元素单个，线程安全，多用于查询 3．LinkedList:元素单个，多用于插入和删除 4．HashMap: 元素成对，元素可为空 5．HashTable: 元素成对，线程安全，元素不可为空 Vector、ArrayList和LinkedList 大多数情况下，从性能上来说ArrayList最好，但是当集合内的元素需要频繁插入、删除时LinkedList会有比较好的表现，但是它们三个性能都比不上数组，另外Vector是线程同步的。 所以： 如果能用数组的时候(元素类型固定，数组长度固定)，请尽量使用数组来代替List； 如果没有频繁的删除插入操作，又不用考虑多线程问题，优先选择ArrayList； 如果在多线程条件下使用，可以考虑Vector； 如果需要频繁地删除插入，LinkedList就有了用武之地； 如果你什么都不知道，用ArrayList没错。 Collections和Arrays 在Java集合类框架里有两个类叫做Collections（注意，不是Collection！）和Arrays，这是JCF里面功能强大的工具，但初学者往往会忽视。按JCF文档的说法，这两个类提供了封装器实现（Wrapper Implementations）、数据结构算法和数组相关的应用。 想必大家不会忘记“折半查找”、“排序”等经典算法吧，Collections类提供了丰富的静态方法帮助我们轻松完成这些在数据结构课上烦人的工作： binarySearch：折半查找。 sort：排序，这里是一种类似于快速排序的方法，效率仍然是O(n * log n)，但却是一种稳定的排序方法。 reverse：将线性表进行逆序操作，这个可是从前数据结构的经典考题哦！ rotate：以某个元素为轴心将线性表“旋转”。 swap：交换一个线性表中两个元素的位置。 …… Collections还有一个重要功能就是“封装器”（Wrapper），它提供了一些方法可以把一个集合转换成一个特殊的集合，如下： unmodifiableXXX：转换成只读集合，这里XXX代表六种基本集合接口：Collection、List、Map、Set、SortedMap和SortedSet。如果你对只读集合进行插入删除操作，将会抛出UnsupportedOperationException异常。 synchronizedXXX：转换成同步集合。 singleton：创建一个仅有一个元素的集合，这里singleton生成的是单元素Set， singletonList和singletonMap分别生成单元素的List和Map。 空集：由Collections的静态属性EMPTY_SET、EMPTY_LIST和EMPTY_MAP表示。","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://bobit.github.io/categories/并发编程/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bobit.github.io/tags/Java/"}]}]}